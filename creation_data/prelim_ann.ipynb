{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import requests\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import random\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Concatenate, Input, concatenate, Dropout\n",
    "from keras.optimizers import Adagrad\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbagen_class = pickle.load(open(\"../data/all_perturbagen_class.pkl\", \"rb\"))\n",
    "perturbagens = list(perturbagen_class.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/full_geneexp_phase2_1004.csv\")\n",
    "def getcellline(x):\n",
    "    cellline = x.split(\"_\")[1]\n",
    "    return cellline\n",
    "df['celline'] = df['signature'].apply(getcellline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"atc_level_one\"] = [val[0] for val in list(df[\"atc\"])]\n",
    "imp_columns = ['target', 'atc', 'celline', 'atc_level_one']+list(df.columns[7:985])\n",
    "df = df[imp_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>atc</th>\n",
       "      <th>celline</th>\n",
       "      <th>atc_level_one</th>\n",
       "      <th>780</th>\n",
       "      <th>7849</th>\n",
       "      <th>6193</th>\n",
       "      <th>23</th>\n",
       "      <th>9552</th>\n",
       "      <th>387</th>\n",
       "      <th>...</th>\n",
       "      <th>54681</th>\n",
       "      <th>11000</th>\n",
       "      <th>6915</th>\n",
       "      <th>6253</th>\n",
       "      <th>7264</th>\n",
       "      <th>5467</th>\n",
       "      <th>2767</th>\n",
       "      <th>23038</th>\n",
       "      <th>57048</th>\n",
       "      <th>79716</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRD-K70330367</td>\n",
       "      <td>N04BB01</td>\n",
       "      <td>YAPC</td>\n",
       "      <td>N</td>\n",
       "      <td>-1.153825</td>\n",
       "      <td>-0.050292</td>\n",
       "      <td>-0.517787</td>\n",
       "      <td>0.244794</td>\n",
       "      <td>-0.399110</td>\n",
       "      <td>0.317308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440725</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>-0.282635</td>\n",
       "      <td>0.666874</td>\n",
       "      <td>-0.319930</td>\n",
       "      <td>-0.131123</td>\n",
       "      <td>-0.213662</td>\n",
       "      <td>-1.007887</td>\n",
       "      <td>-0.182830</td>\n",
       "      <td>0.524592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRD-K70330367</td>\n",
       "      <td>N04BB01</td>\n",
       "      <td>YAPC</td>\n",
       "      <td>N</td>\n",
       "      <td>-0.150379</td>\n",
       "      <td>0.557618</td>\n",
       "      <td>-0.106715</td>\n",
       "      <td>-0.680913</td>\n",
       "      <td>-0.356638</td>\n",
       "      <td>0.821385</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017656</td>\n",
       "      <td>2.434079</td>\n",
       "      <td>-0.580103</td>\n",
       "      <td>-0.610206</td>\n",
       "      <td>0.188383</td>\n",
       "      <td>-0.309202</td>\n",
       "      <td>0.056737</td>\n",
       "      <td>-0.003205</td>\n",
       "      <td>-0.434692</td>\n",
       "      <td>-0.177766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRD-K70330367</td>\n",
       "      <td>N04BB01</td>\n",
       "      <td>HA1E</td>\n",
       "      <td>N</td>\n",
       "      <td>0.038450</td>\n",
       "      <td>0.620755</td>\n",
       "      <td>-0.324466</td>\n",
       "      <td>0.136990</td>\n",
       "      <td>0.141210</td>\n",
       "      <td>-0.112033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224989</td>\n",
       "      <td>0.076725</td>\n",
       "      <td>-0.925917</td>\n",
       "      <td>0.711872</td>\n",
       "      <td>-0.341481</td>\n",
       "      <td>0.437485</td>\n",
       "      <td>-0.052817</td>\n",
       "      <td>-0.376699</td>\n",
       "      <td>-0.047295</td>\n",
       "      <td>-0.215700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRD-K70330367</td>\n",
       "      <td>N04BB01</td>\n",
       "      <td>PC3</td>\n",
       "      <td>N</td>\n",
       "      <td>2.363550</td>\n",
       "      <td>-0.061650</td>\n",
       "      <td>0.691550</td>\n",
       "      <td>0.524950</td>\n",
       "      <td>-0.593000</td>\n",
       "      <td>0.109150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212650</td>\n",
       "      <td>0.114100</td>\n",
       "      <td>-0.307550</td>\n",
       "      <td>-1.156950</td>\n",
       "      <td>0.508250</td>\n",
       "      <td>-0.230200</td>\n",
       "      <td>-0.314000</td>\n",
       "      <td>-1.208450</td>\n",
       "      <td>-0.630500</td>\n",
       "      <td>-0.447650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRD-K70330367</td>\n",
       "      <td>N04BB01</td>\n",
       "      <td>PC3</td>\n",
       "      <td>N</td>\n",
       "      <td>-0.512800</td>\n",
       "      <td>-0.442350</td>\n",
       "      <td>0.697400</td>\n",
       "      <td>0.108150</td>\n",
       "      <td>-0.552350</td>\n",
       "      <td>0.938150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358500</td>\n",
       "      <td>-0.641800</td>\n",
       "      <td>-0.603150</td>\n",
       "      <td>-0.792450</td>\n",
       "      <td>0.384800</td>\n",
       "      <td>-0.458000</td>\n",
       "      <td>-0.074800</td>\n",
       "      <td>-0.196750</td>\n",
       "      <td>-0.669750</td>\n",
       "      <td>0.074850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 982 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          target      atc celline atc_level_one       780      7849      6193  \\\n",
       "0  BRD-K70330367  N04BB01    YAPC             N -1.153825 -0.050292 -0.517787   \n",
       "1  BRD-K70330367  N04BB01    YAPC             N -0.150379  0.557618 -0.106715   \n",
       "2  BRD-K70330367  N04BB01    HA1E             N  0.038450  0.620755 -0.324466   \n",
       "3  BRD-K70330367  N04BB01     PC3             N  2.363550 -0.061650  0.691550   \n",
       "4  BRD-K70330367  N04BB01     PC3             N -0.512800 -0.442350  0.697400   \n",
       "\n",
       "         23      9552       387    ...        54681     11000      6915  \\\n",
       "0  0.244794 -0.399110  0.317308    ...     0.440725  0.115513 -0.282635   \n",
       "1 -0.680913 -0.356638  0.821385    ...    -0.017656  2.434079 -0.580103   \n",
       "2  0.136990  0.141210 -0.112033    ...     0.224989  0.076725 -0.925917   \n",
       "3  0.524950 -0.593000  0.109150    ...     0.212650  0.114100 -0.307550   \n",
       "4  0.108150 -0.552350  0.938150    ...     0.358500 -0.641800 -0.603150   \n",
       "\n",
       "       6253      7264      5467      2767     23038     57048     79716  \n",
       "0  0.666874 -0.319930 -0.131123 -0.213662 -1.007887 -0.182830  0.524592  \n",
       "1 -0.610206  0.188383 -0.309202  0.056737 -0.003205 -0.434692 -0.177766  \n",
       "2  0.711872 -0.341481  0.437485 -0.052817 -0.376699 -0.047295 -0.215700  \n",
       "3 -1.156950  0.508250 -0.230200 -0.314000 -1.208450 -0.630500 -0.447650  \n",
       "4 -0.792450  0.384800 -0.458000 -0.074800 -0.196750 -0.669750  0.074850  \n",
       "\n",
       "[5 rows x 982 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "atc_level_vals = np.unique(df.atc_level_one)\n",
    "cell_lines = [k for k,_ in Counter(df.celline).most_common(7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.celline.isin(cell_lines)]\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df['atc_level_one'])\n",
    "\n",
    "df['atc_level_one'] = le.transform(df['atc_level_one'])\n",
    "\n",
    "pert_train, pert_test = train_test_split(np.unique(df.target), test_size=0.3)\n",
    "\n",
    "df_train = df[df.target.isin(pert_train)]\n",
    "df_test = df[df.target.isin(pert_test)]\n",
    "\n",
    "df_cell_line_train = {}\n",
    "for cell_line in cell_lines:\n",
    "    df_cell_line_train[cell_line] = df_train[df_train.celline==cell_line]\n",
    "    \n",
    "df_cell_line_test = {}\n",
    "for cell_line in cell_lines:\n",
    "    df_cell_line_test[cell_line] = df_test[df_test.celline==cell_line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kavya/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oe = OneHotEncoder()\n",
    "oe.fit(le.transform(atc_level_vals).reshape(len(atc_level_vals), 1))\n",
    "oe.transform(np.array([0]).reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network:\n",
    "    def __init__(self):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(25, activation='selu', input_dim=978))\n",
    "        self.model.add(Dense(14, activation='softmax'))\n",
    "        self.model.compile(optimizer='adagrad',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4614, 14)\n",
      "Epoch 1/20\n",
      "4614/4614 [==============================] - 1s 210us/step - loss: 2.4647 - acc: 0.2575\n",
      "Epoch 2/20\n",
      "4614/4614 [==============================] - 0s 73us/step - loss: 1.8250 - acc: 0.4094\n",
      "Epoch 3/20\n",
      "4614/4614 [==============================] - 0s 74us/step - loss: 1.6418 - acc: 0.4694\n",
      "Epoch 4/20\n",
      "4614/4614 [==============================] - 0s 74us/step - loss: 1.5195 - acc: 0.5117\n",
      "Epoch 5/20\n",
      "4614/4614 [==============================] - 0s 73us/step - loss: 1.4208 - acc: 0.5485\n",
      "Epoch 6/20\n",
      "4614/4614 [==============================] - 0s 73us/step - loss: 1.3427 - acc: 0.5774\n",
      "Epoch 7/20\n",
      "4614/4614 [==============================] - 0s 75us/step - loss: 1.2747 - acc: 0.6016\n",
      "Epoch 8/20\n",
      "4614/4614 [==============================] - 0s 101us/step - loss: 1.2161 - acc: 0.6207\n",
      "Epoch 9/20\n",
      "4614/4614 [==============================] - 0s 85us/step - loss: 1.1653 - acc: 0.6400\n",
      "Epoch 10/20\n",
      "4614/4614 [==============================] - 0s 73us/step - loss: 1.1200 - acc: 0.6513\n",
      "Epoch 11/20\n",
      "4614/4614 [==============================] - 0s 76us/step - loss: 1.0798 - acc: 0.6619\n",
      "Epoch 12/20\n",
      "4614/4614 [==============================] - 0s 75us/step - loss: 1.0430 - acc: 0.6699\n",
      "Epoch 13/20\n",
      "4614/4614 [==============================] - 0s 75us/step - loss: 1.0087 - acc: 0.6805\n",
      "Epoch 14/20\n",
      "4614/4614 [==============================] - 0s 75us/step - loss: 0.9784 - acc: 0.6896\n",
      "Epoch 15/20\n",
      "4614/4614 [==============================] - 0s 81us/step - loss: 0.9495 - acc: 0.7035\n",
      "Epoch 16/20\n",
      "4614/4614 [==============================] - 0s 88us/step - loss: 0.9235 - acc: 0.7122\n",
      "Epoch 17/20\n",
      "4614/4614 [==============================] - 0s 75us/step - loss: 0.8989 - acc: 0.7176\n",
      "Epoch 18/20\n",
      "4614/4614 [==============================] - 0s 75us/step - loss: 0.8748 - acc: 0.7252\n",
      "Epoch 19/20\n",
      "4614/4614 [==============================] - 0s 74us/step - loss: 0.8532 - acc: 0.7347\n",
      "Epoch 20/20\n",
      "4614/4614 [==============================] - 0s 75us/step - loss: 0.8324 - acc: 0.7443\n",
      "0.21924603174603174\n",
      "(4548, 14)\n",
      "Epoch 1/20\n",
      "4548/4548 [==============================] - 1s 218us/step - loss: 2.4847 - acc: 0.2513\n",
      "Epoch 2/20\n",
      "4548/4548 [==============================] - 0s 76us/step - loss: 1.8373 - acc: 0.3997\n",
      "Epoch 3/20\n",
      "4548/4548 [==============================] - 0s 75us/step - loss: 1.6620 - acc: 0.4516\n",
      "Epoch 4/20\n",
      "4548/4548 [==============================] - 0s 75us/step - loss: 1.5410 - acc: 0.4985\n",
      "Epoch 5/20\n",
      "4548/4548 [==============================] - 0s 74us/step - loss: 1.4485 - acc: 0.5244\n",
      "Epoch 6/20\n",
      "4548/4548 [==============================] - 0s 74us/step - loss: 1.3725 - acc: 0.5556\n",
      "Epoch 7/20\n",
      "4548/4548 [==============================] - 0s 85us/step - loss: 1.3107 - acc: 0.5798\n",
      "Epoch 8/20\n",
      "4548/4548 [==============================] - 0s 98us/step - loss: 1.2549 - acc: 0.6014\n",
      "Epoch 9/20\n",
      "4548/4548 [==============================] - 0s 78us/step - loss: 1.2060 - acc: 0.6205\n",
      "Epoch 10/20\n",
      "4548/4548 [==============================] - 0s 77us/step - loss: 1.1619 - acc: 0.6350\n",
      "Epoch 11/20\n",
      "4548/4548 [==============================] - 0s 100us/step - loss: 1.1228 - acc: 0.6484\n",
      "Epoch 12/20\n",
      "4548/4548 [==============================] - 0s 82us/step - loss: 1.0880 - acc: 0.6559\n",
      "Epoch 13/20\n",
      "4548/4548 [==============================] - 0s 78us/step - loss: 1.0544 - acc: 0.6697\n",
      "Epoch 14/20\n",
      "4548/4548 [==============================] - 0s 81us/step - loss: 1.0237 - acc: 0.6748\n",
      "Epoch 15/20\n",
      "4548/4548 [==============================] - 0s 80us/step - loss: 0.9952 - acc: 0.6865\n",
      "Epoch 16/20\n",
      "4548/4548 [==============================] - 0s 77us/step - loss: 0.9704 - acc: 0.6966\n",
      "Epoch 17/20\n",
      "4548/4548 [==============================] - 0s 77us/step - loss: 0.9443 - acc: 0.7062\n",
      "Epoch 18/20\n",
      "4548/4548 [==============================] - 0s 94us/step - loss: 0.9225 - acc: 0.7131\n",
      "Epoch 19/20\n",
      "4548/4548 [==============================] - 0s 83us/step - loss: 0.9028 - acc: 0.7194\n",
      "Epoch 20/20\n",
      "4548/4548 [==============================] - 0s 77us/step - loss: 0.8810 - acc: 0.7249\n",
      "0.1942043721403152\n",
      "(4534, 14)\n",
      "Epoch 1/20\n",
      "4534/4534 [==============================] - 1s 220us/step - loss: 2.5092 - acc: 0.2457\n",
      "Epoch 2/20\n",
      "4534/4534 [==============================] - 0s 75us/step - loss: 1.8324 - acc: 0.4034\n",
      "Epoch 3/20\n",
      "4534/4534 [==============================] - 0s 82us/step - loss: 1.6538 - acc: 0.4612\n",
      "Epoch 4/20\n",
      "4534/4534 [==============================] - 0s 80us/step - loss: 1.5314 - acc: 0.5040\n",
      "Epoch 5/20\n",
      "4534/4534 [==============================] - 0s 78us/step - loss: 1.4412 - acc: 0.5351\n",
      "Epoch 6/20\n",
      "4534/4534 [==============================] - 0s 90us/step - loss: 1.3652 - acc: 0.5635\n",
      "Epoch 7/20\n",
      "4534/4534 [==============================] - 0s 79us/step - loss: 1.3013 - acc: 0.5909\n",
      "Epoch 8/20\n",
      "4534/4534 [==============================] - 0s 78us/step - loss: 1.2472 - acc: 0.6120\n",
      "Epoch 9/20\n",
      "4534/4534 [==============================] - 0s 79us/step - loss: 1.1978 - acc: 0.6262\n",
      "Epoch 10/20\n",
      "4534/4534 [==============================] - 0s 80us/step - loss: 1.1541 - acc: 0.6418\n",
      "Epoch 11/20\n",
      "4534/4534 [==============================] - 0s 79us/step - loss: 1.1145 - acc: 0.6586\n",
      "Epoch 12/20\n",
      "4534/4534 [==============================] - 1s 110us/step - loss: 1.0790 - acc: 0.6652\n",
      "Epoch 13/20\n",
      "4534/4534 [==============================] - 1s 113us/step - loss: 1.0456 - acc: 0.6767\n",
      "Epoch 14/20\n",
      "4534/4534 [==============================] - 0s 86us/step - loss: 1.0150 - acc: 0.6884\n",
      "Epoch 15/20\n",
      "4534/4534 [==============================] - 0s 88us/step - loss: 0.9876 - acc: 0.7016\n",
      "Epoch 16/20\n",
      "4534/4534 [==============================] - 0s 79us/step - loss: 0.9610 - acc: 0.7075\n",
      "Epoch 17/20\n",
      "4534/4534 [==============================] - 0s 87us/step - loss: 0.9346 - acc: 0.7186\n",
      "Epoch 18/20\n",
      "4534/4534 [==============================] - 0s 77us/step - loss: 0.9115 - acc: 0.7230\n",
      "Epoch 19/20\n",
      "4534/4534 [==============================] - 0s 101us/step - loss: 0.8909 - acc: 0.7300\n",
      "Epoch 20/20\n",
      "4534/4534 [==============================] - 0s 82us/step - loss: 0.8700 - acc: 0.7386\n",
      "0.19553072625698323\n",
      "(4498, 14)\n",
      "Epoch 1/20\n",
      "4498/4498 [==============================] - 1s 296us/step - loss: 2.5529 - acc: 0.2448\n",
      "Epoch 2/20\n",
      "4498/4498 [==============================] - 0s 77us/step - loss: 1.8555 - acc: 0.3771\n",
      "Epoch 3/20\n",
      "4498/4498 [==============================] - 0s 97us/step - loss: 1.6708 - acc: 0.4455\n",
      "Epoch 4/20\n",
      "4498/4498 [==============================] - 0s 77us/step - loss: 1.5460 - acc: 0.4931\n",
      "Epoch 5/20\n",
      "4498/4498 [==============================] - 0s 75us/step - loss: 1.4506 - acc: 0.5273\n",
      "Epoch 6/20\n",
      "4498/4498 [==============================] - 0s 77us/step - loss: 1.3701 - acc: 0.5591\n",
      "Epoch 7/20\n",
      "4498/4498 [==============================] - 0s 76us/step - loss: 1.3021 - acc: 0.5776\n",
      "Epoch 8/20\n",
      "4498/4498 [==============================] - 0s 75us/step - loss: 1.2428 - acc: 0.6007\n",
      "Epoch 9/20\n",
      "4498/4498 [==============================] - 0s 100us/step - loss: 1.1896 - acc: 0.6218\n",
      "Epoch 10/20\n",
      "4498/4498 [==============================] - 0s 79us/step - loss: 1.1426 - acc: 0.6410\n",
      "Epoch 11/20\n",
      "4498/4498 [==============================] - 0s 77us/step - loss: 1.1005 - acc: 0.6527\n",
      "Epoch 12/20\n",
      "4498/4498 [==============================] - 0s 87us/step - loss: 1.0632 - acc: 0.6654\n",
      "Epoch 13/20\n",
      "4498/4498 [==============================] - 0s 86us/step - loss: 1.0262 - acc: 0.6783\n",
      "Epoch 14/20\n",
      "4498/4498 [==============================] - 0s 75us/step - loss: 0.9956 - acc: 0.6881\n",
      "Epoch 15/20\n",
      "4498/4498 [==============================] - 0s 78us/step - loss: 0.9635 - acc: 0.7032\n",
      "Epoch 16/20\n",
      "4498/4498 [==============================] - 0s 75us/step - loss: 0.9358 - acc: 0.7099\n",
      "Epoch 17/20\n",
      "4498/4498 [==============================] - 0s 75us/step - loss: 0.9106 - acc: 0.7185\n",
      "Epoch 18/20\n",
      "4498/4498 [==============================] - 0s 74us/step - loss: 0.8857 - acc: 0.7285\n",
      "Epoch 19/20\n",
      "4498/4498 [==============================] - 0s 79us/step - loss: 0.8630 - acc: 0.7394\n",
      "Epoch 20/20\n",
      "4498/4498 [==============================] - 1s 113us/step - loss: 0.8419 - acc: 0.7430\n",
      "0.18665977249224405\n",
      "(4480, 14)\n",
      "Epoch 1/20\n",
      "4480/4480 [==============================] - 1s 238us/step - loss: 2.5137 - acc: 0.2455\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4480/4480 [==============================] - 0s 76us/step - loss: 1.8357 - acc: 0.3984\n",
      "Epoch 3/20\n",
      "4480/4480 [==============================] - 0s 72us/step - loss: 1.6628 - acc: 0.4616\n",
      "Epoch 4/20\n",
      "4480/4480 [==============================] - 0s 73us/step - loss: 1.5426 - acc: 0.5067\n",
      "Epoch 5/20\n",
      "4480/4480 [==============================] - 0s 73us/step - loss: 1.4511 - acc: 0.5335\n",
      "Epoch 6/20\n",
      "4480/4480 [==============================] - 0s 77us/step - loss: 1.3729 - acc: 0.5645\n",
      "Epoch 7/20\n",
      "4480/4480 [==============================] - 0s 97us/step - loss: 1.3077 - acc: 0.5826\n",
      "Epoch 8/20\n",
      "4480/4480 [==============================] - 0s 75us/step - loss: 1.2502 - acc: 0.6056\n",
      "Epoch 9/20\n",
      "4480/4480 [==============================] - 0s 85us/step - loss: 1.1992 - acc: 0.6176\n",
      "Epoch 10/20\n",
      "4480/4480 [==============================] - 0s 87us/step - loss: 1.1524 - acc: 0.6355\n",
      "Epoch 11/20\n",
      "4480/4480 [==============================] - 0s 74us/step - loss: 1.1105 - acc: 0.6525\n",
      "Epoch 12/20\n",
      "4480/4480 [==============================] - 0s 88us/step - loss: 1.0710 - acc: 0.6636\n",
      "Epoch 13/20\n",
      "4480/4480 [==============================] - 0s 75us/step - loss: 1.0363 - acc: 0.6741\n",
      "Epoch 14/20\n",
      "4480/4480 [==============================] - 0s 77us/step - loss: 1.0032 - acc: 0.6929\n",
      "Epoch 15/20\n",
      "4480/4480 [==============================] - 0s 73us/step - loss: 0.9724 - acc: 0.7022\n",
      "Epoch 16/20\n",
      "4480/4480 [==============================] - 0s 75us/step - loss: 0.9450 - acc: 0.7089\n",
      "Epoch 17/20\n",
      "4480/4480 [==============================] - 0s 75us/step - loss: 0.9182 - acc: 0.7183\n",
      "Epoch 18/20\n",
      "4480/4480 [==============================] - 0s 75us/step - loss: 0.8934 - acc: 0.7299\n",
      "Epoch 19/20\n",
      "4480/4480 [==============================] - 0s 102us/step - loss: 0.8703 - acc: 0.7359\n",
      "Epoch 20/20\n",
      "4480/4480 [==============================] - 0s 80us/step - loss: 0.8473 - acc: 0.7442\n",
      "0.20113753877973112\n",
      "(4374, 14)\n",
      "Epoch 1/20\n",
      "4374/4374 [==============================] - 1s 264us/step - loss: 2.5406 - acc: 0.2369\n",
      "Epoch 2/20\n",
      "4374/4374 [==============================] - 0s 109us/step - loss: 1.8587 - acc: 0.3829\n",
      "Epoch 3/20\n",
      "4374/4374 [==============================] - 0s 82us/step - loss: 1.6792 - acc: 0.4408\n",
      "Epoch 4/20\n",
      "4374/4374 [==============================] - 0s 81us/step - loss: 1.5569 - acc: 0.4909\n",
      "Epoch 5/20\n",
      "4374/4374 [==============================] - 0s 82us/step - loss: 1.4615 - acc: 0.5288\n",
      "Epoch 6/20\n",
      "4374/4374 [==============================] - 0s 82us/step - loss: 1.3853 - acc: 0.5485\n",
      "Epoch 7/20\n",
      "4374/4374 [==============================] - 0s 78us/step - loss: 1.3217 - acc: 0.5764\n",
      "Epoch 8/20\n",
      "4374/4374 [==============================] - 0s 78us/step - loss: 1.2620 - acc: 0.5905\n",
      "Epoch 9/20\n",
      "4374/4374 [==============================] - 1s 118us/step - loss: 1.2116 - acc: 0.6150\n",
      "Epoch 10/20\n",
      "4374/4374 [==============================] - 0s 78us/step - loss: 1.1643 - acc: 0.6244\n",
      "Epoch 11/20\n",
      "4374/4374 [==============================] - 0s 92us/step - loss: 1.1241 - acc: 0.6404\n",
      "Epoch 12/20\n",
      "4374/4374 [==============================] - 0s 77us/step - loss: 1.0865 - acc: 0.6507\n",
      "Epoch 13/20\n",
      "4374/4374 [==============================] - 0s 79us/step - loss: 1.0523 - acc: 0.6600\n",
      "Epoch 14/20\n",
      "4374/4374 [==============================] - 0s 84us/step - loss: 1.0199 - acc: 0.6738\n",
      "Epoch 15/20\n",
      "4374/4374 [==============================] - 0s 83us/step - loss: 0.9901 - acc: 0.6861\n",
      "Epoch 16/20\n",
      "4374/4374 [==============================] - 0s 95us/step - loss: 0.9620 - acc: 0.6941\n",
      "Epoch 17/20\n",
      "4374/4374 [==============================] - 0s 104us/step - loss: 0.9350 - acc: 0.7030\n",
      "Epoch 18/20\n",
      "4374/4374 [==============================] - 0s 107us/step - loss: 0.9115 - acc: 0.7140\n",
      "Epoch 19/20\n",
      "4374/4374 [==============================] - 0s 102us/step - loss: 0.8883 - acc: 0.7215\n",
      "Epoch 20/20\n",
      "4374/4374 [==============================] - 0s 87us/step - loss: 0.8670 - acc: 0.7284\n",
      "0.14921171171171171\n",
      "(4374, 14)\n",
      "Epoch 1/20\n",
      "4374/4374 [==============================] - 1s 281us/step - loss: 2.5041 - acc: 0.2387\n",
      "Epoch 2/20\n",
      "4374/4374 [==============================] - 0s 80us/step - loss: 1.8638 - acc: 0.3786\n",
      "Epoch 3/20\n",
      "4374/4374 [==============================] - 0s 79us/step - loss: 1.6953 - acc: 0.4351\n",
      "Epoch 4/20\n",
      "4374/4374 [==============================] - 0s 95us/step - loss: 1.5746 - acc: 0.4831\n",
      "Epoch 5/20\n",
      "4374/4374 [==============================] - 0s 88us/step - loss: 1.4845 - acc: 0.5206\n",
      "Epoch 6/20\n",
      "4374/4374 [==============================] - 0s 93us/step - loss: 1.4081 - acc: 0.5450\n",
      "Epoch 7/20\n",
      "4374/4374 [==============================] - 0s 81us/step - loss: 1.3454 - acc: 0.5713\n",
      "Epoch 8/20\n",
      "4374/4374 [==============================] - 0s 82us/step - loss: 1.2865 - acc: 0.5878\n",
      "Epoch 9/20\n",
      "4374/4374 [==============================] - 0s 91us/step - loss: 1.2363 - acc: 0.6045\n",
      "Epoch 10/20\n",
      "4374/4374 [==============================] - 0s 75us/step - loss: 1.1909 - acc: 0.6214\n",
      "Epoch 11/20\n",
      "4374/4374 [==============================] - 0s 78us/step - loss: 1.1507 - acc: 0.6305\n",
      "Epoch 12/20\n",
      "4374/4374 [==============================] - 1s 115us/step - loss: 1.1118 - acc: 0.6417\n",
      "Epoch 13/20\n",
      "4374/4374 [==============================] - 0s 102us/step - loss: 1.0780 - acc: 0.6557\n",
      "Epoch 14/20\n",
      "4374/4374 [==============================] - 0s 81us/step - loss: 1.0457 - acc: 0.6694\n",
      "Epoch 15/20\n",
      "4374/4374 [==============================] - 0s 78us/step - loss: 1.0155 - acc: 0.6859\n",
      "Epoch 16/20\n",
      "4374/4374 [==============================] - 0s 76us/step - loss: 0.9863 - acc: 0.6948\n",
      "Epoch 17/20\n",
      "4374/4374 [==============================] - 0s 79us/step - loss: 0.9593 - acc: 0.7023\n",
      "Epoch 18/20\n",
      "4374/4374 [==============================] - 0s 86us/step - loss: 0.9352 - acc: 0.7122\n",
      "Epoch 19/20\n",
      "4374/4374 [==============================] - 0s 82us/step - loss: 0.9117 - acc: 0.7206\n",
      "Epoch 20/20\n",
      "4374/4374 [==============================] - 0s 97us/step - loss: 0.8904 - acc: 0.7254\n",
      "0.16176470588235295\n"
     ]
    }
   ],
   "source": [
    "network_models = {}\n",
    "\n",
    "for cell_line in cell_lines:\n",
    "    X = df_cell_line_train[cell_line][df.columns[4:]]\n",
    "    y = oe.transform(np.array(df_cell_line_train[cell_line]['atc_level_one']).reshape(-1, 1)).toarray()\n",
    "    print(y.shape)\n",
    "    \n",
    "    network_models[cell_line] = network()\n",
    "    network_models[cell_line].fit(X, y) \n",
    "    \n",
    "    y_pred = network_models[cell_line].predict(df_cell_line_test[cell_line][df.columns[4:]])\n",
    "    y_true = oe.transform(np.array(df_cell_line_test[cell_line]['atc_level_one']).reshape(-1, 1)).toarray()\n",
    "    print(accuracy_score(df_cell_line_test[cell_line]['atc_level_one'], np.argmax(y_pred, axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cell_line = []\n",
    "pred = []\n",
    "for pert in pert_test:\n",
    "    predictions = []\n",
    "    all_predictions = []\n",
    "    for cell_line in cell_lines:\n",
    "        mini_df = df_cell_line_test[cell_line][df_cell_line_test[cell_line]['target']==pert]\n",
    "        if mini_df.shape[0]==0:\n",
    "            continue\n",
    "        answers = []\n",
    "        for index in mini_df.index:\n",
    "            answers+=(list(np.argmax(network_models[cell_line].predict(np.array(\n",
    "                mini_df[df.columns[4:]].loc[index]).reshape(1, -1)), axis=1)))\n",
    "            all_predictions.append(answers[-1])\n",
    "        predictions.append(Counter(answers).most_common(1)[0][0])\n",
    "    pred.append(Counter(all_predictions).most_common(1)[0][0])\n",
    "    pred_cell_line.append(Counter(predictions).most_common(1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3021276595744681"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [np.array(df_test[df_test['target']==pert]['atc_level_one'])[0] for pert in pert_test]\n",
    "accuracy_score(y_true, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class denseNetwork:\n",
    "    def __init__(self, d=6, k=40):\n",
    "        self.d = d\n",
    "        self.k = k\n",
    "        \n",
    "        _input = Input(shape=(978, ))\n",
    "        Inputs = [_input]\n",
    "        for layer in range(d-1):\n",
    "            _dense = Dense(k, activation='selu', kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l1(0.01))(_input)\n",
    "            _dense = Dropout(rate=0.9)(_dense)\n",
    "            _input = Input(shape=(978, ))\n",
    "            Inputs.append(_input)\n",
    "            _input = concatenate([_dense, _input])\n",
    "\n",
    "        merge_output = Dense(14, activation='softmax')(_input)\n",
    "\n",
    "        self.model = Model(inputs=Inputs, outputs=merge_output)\n",
    "        ada_grad = Adagrad(lr=0.1, epsilon=1e-08, decay=0.0)\n",
    "        self.model.compile(optimizer=ada_grad, loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict([X for _ in range(self.d)])\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.model.fit([X for _ in range(self.d)], y, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4614, 14)\n",
      "Epoch 1/20\n",
      "4614/4614 [==============================] - 4s 892us/step - loss: 33.5388 - acc: 0.2510\n",
      "Epoch 2/20\n",
      "4614/4614 [==============================] - 1s 150us/step - loss: 24.3940 - acc: 0.4254\n",
      "Epoch 3/20\n",
      "4614/4614 [==============================] - 1s 137us/step - loss: 18.3365 - acc: 0.4950\n",
      "Epoch 4/20\n",
      "4614/4614 [==============================] - 1s 166us/step - loss: 14.8871 - acc: 0.5429\n",
      "Epoch 5/20\n",
      "4614/4614 [==============================] - 1s 164us/step - loss: 12.8940 - acc: 0.5821\n",
      "Epoch 6/20\n",
      "4614/4614 [==============================] - 1s 165us/step - loss: 11.5593 - acc: 0.6129\n",
      "Epoch 7/20\n",
      "4614/4614 [==============================] - 1s 171us/step - loss: 10.6779 - acc: 0.6335\n",
      "Epoch 8/20\n",
      "4614/4614 [==============================] - 1s 166us/step - loss: 9.9816 - acc: 0.6437\n",
      "Epoch 9/20\n",
      "4614/4614 [==============================] - 1s 166us/step - loss: 9.4640 - acc: 0.6656\n",
      "Epoch 10/20\n",
      "4614/4614 [==============================] - 1s 163us/step - loss: 9.0457 - acc: 0.6747\n",
      "Epoch 11/20\n",
      "4614/4614 [==============================] - 1s 185us/step - loss: 8.6966 - acc: 0.7035\n",
      "Epoch 12/20\n",
      "4614/4614 [==============================] - 1s 164us/step - loss: 8.4274 - acc: 0.6970\n",
      "Epoch 13/20\n",
      "4614/4614 [==============================] - 1s 165us/step - loss: 8.2038 - acc: 0.7117\n",
      "Epoch 14/20\n",
      "4614/4614 [==============================] - 1s 166us/step - loss: 7.9293 - acc: 0.7091\n",
      "Epoch 15/20\n",
      "4614/4614 [==============================] - 1s 165us/step - loss: 7.7339 - acc: 0.7241\n",
      "Epoch 16/20\n",
      "4614/4614 [==============================] - 1s 165us/step - loss: 7.4582 - acc: 0.7293\n",
      "Epoch 17/20\n",
      "4614/4614 [==============================] - 1s 165us/step - loss: 7.3131 - acc: 0.7280\n",
      "Epoch 18/20\n",
      "4614/4614 [==============================] - 1s 166us/step - loss: 7.1487 - acc: 0.7336\n",
      "Epoch 19/20\n",
      "4614/4614 [==============================] - 1s 167us/step - loss: 6.9972 - acc: 0.7430\n",
      "Epoch 20/20\n",
      "4614/4614 [==============================] - 1s 165us/step - loss: 6.8906 - acc: 0.7503\n",
      "0.1949404761904762\n",
      "(4548, 14)\n",
      "Epoch 1/20\n",
      "4548/4548 [==============================] - 4s 923us/step - loss: 33.9041 - acc: 0.2430\n",
      "Epoch 2/20\n",
      "4548/4548 [==============================] - 1s 169us/step - loss: 24.6563 - acc: 0.4169\n",
      "Epoch 3/20\n",
      "4548/4548 [==============================] - 1s 169us/step - loss: 18.8143 - acc: 0.4846\n",
      "Epoch 4/20\n",
      "4548/4548 [==============================] - 1s 166us/step - loss: 15.2986 - acc: 0.5365\n",
      "Epoch 5/20\n",
      "4548/4548 [==============================] - 1s 168us/step - loss: 13.2348 - acc: 0.5750\n",
      "Epoch 6/20\n",
      "4548/4548 [==============================] - 1s 167us/step - loss: 11.9785 - acc: 0.5992\n",
      "Epoch 7/20\n",
      "4548/4548 [==============================] - 1s 170us/step - loss: 11.0606 - acc: 0.6220\n",
      "Epoch 8/20\n",
      "4548/4548 [==============================] - 1s 169us/step - loss: 10.3655 - acc: 0.6271\n",
      "Epoch 9/20\n",
      "4548/4548 [==============================] - 1s 168us/step - loss: 9.7877 - acc: 0.6530\n",
      "Epoch 10/20\n",
      "4548/4548 [==============================] - 1s 169us/step - loss: 9.3163 - acc: 0.6618\n",
      "Epoch 11/20\n",
      "4548/4548 [==============================] - 1s 166us/step - loss: 8.8503 - acc: 0.6741\n",
      "Epoch 12/20\n",
      "4548/4548 [==============================] - 1s 170us/step - loss: 8.6138 - acc: 0.6858\n",
      "Epoch 13/20\n",
      "4548/4548 [==============================] - 1s 167us/step - loss: 8.3062 - acc: 0.6900\n",
      "Epoch 14/20\n",
      "4548/4548 [==============================] - 1s 169us/step - loss: 8.0300 - acc: 0.7146\n",
      "Epoch 15/20\n",
      "4548/4548 [==============================] - 1s 168us/step - loss: 7.7951 - acc: 0.7120\n",
      "Epoch 16/20\n",
      "4548/4548 [==============================] - 1s 167us/step - loss: 7.6347 - acc: 0.7157\n",
      "Epoch 17/20\n",
      "4548/4548 [==============================] - 1s 169us/step - loss: 7.3905 - acc: 0.7238\n",
      "Epoch 18/20\n",
      "4548/4548 [==============================] - 1s 169us/step - loss: 7.2592 - acc: 0.7276\n",
      "Epoch 19/20\n",
      "4548/4548 [==============================] - 1s 170us/step - loss: 7.0853 - acc: 0.7313\n",
      "Epoch 20/20\n",
      "4548/4548 [==============================] - 1s 167us/step - loss: 6.9821 - acc: 0.7304\n",
      "0.1784443314692425\n",
      "(4534, 14)\n",
      "Epoch 1/20\n",
      "4534/4534 [==============================] - 4s 945us/step - loss: 33.4282 - acc: 0.2585\n",
      "Epoch 2/20\n",
      "4534/4534 [==============================] - 1s 171us/step - loss: 24.3597 - acc: 0.4164\n",
      "Epoch 3/20\n",
      "4534/4534 [==============================] - 1s 240us/step - loss: 18.2513 - acc: 0.5055\n",
      "Epoch 4/20\n",
      "4534/4534 [==============================] - 1s 206us/step - loss: 14.7856 - acc: 0.5461\n",
      "Epoch 5/20\n",
      "4534/4534 [==============================] - 1s 171us/step - loss: 12.9794 - acc: 0.5851\n",
      "Epoch 6/20\n",
      "4534/4534 [==============================] - 1s 170us/step - loss: 11.6799 - acc: 0.6096\n",
      "Epoch 7/20\n",
      "4534/4534 [==============================] - 1s 168us/step - loss: 10.8704 - acc: 0.6312\n",
      "Epoch 8/20\n",
      "4534/4534 [==============================] - 1s 168us/step - loss: 10.1929 - acc: 0.6539\n",
      "Epoch 9/20\n",
      "4534/4534 [==============================] - 1s 169us/step - loss: 9.6461 - acc: 0.6663\n",
      "Epoch 10/20\n",
      "4534/4534 [==============================] - 1s 178us/step - loss: 9.2006 - acc: 0.6811\n",
      "Epoch 11/20\n",
      "4534/4534 [==============================] - 1s 185us/step - loss: 8.7941 - acc: 0.6961\n",
      "Epoch 12/20\n",
      "4534/4534 [==============================] - 1s 170us/step - loss: 8.5068 - acc: 0.7022\n",
      "Epoch 13/20\n",
      "4534/4534 [==============================] - 1s 171us/step - loss: 8.2788 - acc: 0.7062\n",
      "Epoch 14/20\n",
      "4534/4534 [==============================] - 1s 170us/step - loss: 8.0590 - acc: 0.7172\n",
      "Epoch 15/20\n",
      "4534/4534 [==============================] - 1s 171us/step - loss: 7.8409 - acc: 0.7212\n",
      "Epoch 16/20\n",
      "4534/4534 [==============================] - 1s 169us/step - loss: 7.6761 - acc: 0.7305\n",
      "Epoch 17/20\n",
      "4534/4534 [==============================] - 1s 173us/step - loss: 7.5077 - acc: 0.7340\n",
      "Epoch 18/20\n",
      "4534/4534 [==============================] - 1s 171us/step - loss: 7.3639 - acc: 0.7382\n",
      "Epoch 19/20\n",
      "4534/4534 [==============================] - 1s 169us/step - loss: 7.1929 - acc: 0.7424\n",
      "Epoch 20/20\n",
      "4534/4534 [==============================] - 1s 170us/step - loss: 7.0868 - acc: 0.7472\n",
      "0.18638902996444895\n",
      "(4498, 14)\n",
      "Epoch 1/20\n",
      "4498/4498 [==============================] - 4s 987us/step - loss: 33.6980 - acc: 0.2452\n",
      "Epoch 2/20\n",
      "4498/4498 [==============================] - 1s 203us/step - loss: 24.8842 - acc: 0.4220\n",
      "Epoch 3/20\n",
      "4498/4498 [==============================] - 1s 174us/step - loss: 18.9529 - acc: 0.4989\n",
      "Epoch 4/20\n",
      "4498/4498 [==============================] - 1s 170us/step - loss: 15.4597 - acc: 0.5502\n",
      "Epoch 5/20\n",
      "4498/4498 [==============================] - 1s 173us/step - loss: 13.3758 - acc: 0.5851\n",
      "Epoch 6/20\n",
      "4498/4498 [==============================] - 1s 171us/step - loss: 12.1879 - acc: 0.6067\n",
      "Epoch 7/20\n",
      "4498/4498 [==============================] - 1s 170us/step - loss: 11.2249 - acc: 0.6341\n",
      "Epoch 8/20\n",
      "4498/4498 [==============================] - 1s 170us/step - loss: 10.5117 - acc: 0.6547\n",
      "Epoch 9/20\n",
      "4498/4498 [==============================] - 1s 172us/step - loss: 9.8840 - acc: 0.6681\n",
      "Epoch 10/20\n",
      "4498/4498 [==============================] - 1s 173us/step - loss: 9.4404 - acc: 0.6767\n",
      "Epoch 11/20\n",
      "4498/4498 [==============================] - 1s 171us/step - loss: 9.0878 - acc: 0.6847\n",
      "Epoch 12/20\n",
      "4498/4498 [==============================] - 1s 168us/step - loss: 8.7891 - acc: 0.6930\n",
      "Epoch 13/20\n",
      "4498/4498 [==============================] - 1s 188us/step - loss: 8.4663 - acc: 0.7034\n",
      "Epoch 14/20\n",
      "4498/4498 [==============================] - 1s 191us/step - loss: 8.1839 - acc: 0.7148\n",
      "Epoch 15/20\n",
      "4498/4498 [==============================] - 1s 172us/step - loss: 8.0417 - acc: 0.7170\n",
      "Epoch 16/20\n",
      "4498/4498 [==============================] - 1s 170us/step - loss: 7.7268 - acc: 0.7254\n",
      "Epoch 17/20\n",
      "4498/4498 [==============================] - 1s 172us/step - loss: 7.5714 - acc: 0.7312\n",
      "Epoch 18/20\n",
      "4498/4498 [==============================] - 1s 172us/step - loss: 7.4401 - acc: 0.7357\n",
      "Epoch 19/20\n",
      "4498/4498 [==============================] - 1s 175us/step - loss: 7.2788 - acc: 0.7368\n",
      "Epoch 20/20\n",
      "4498/4498 [==============================] - 1s 171us/step - loss: 7.1800 - acc: 0.7428\n",
      "0.1778697001034126\n",
      "(4480, 14)\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4480/4480 [==============================] - 4s 982us/step - loss: 33.5029 - acc: 0.2469\n",
      "Epoch 2/20\n",
      "4480/4480 [==============================] - 1s 164us/step - loss: 23.8411 - acc: 0.4143\n",
      "Epoch 3/20\n",
      "4480/4480 [==============================] - 1s 163us/step - loss: 17.7271 - acc: 0.5047\n",
      "Epoch 4/20\n",
      "4480/4480 [==============================] - 1s 163us/step - loss: 14.5995 - acc: 0.5480\n",
      "Epoch 5/20\n",
      "4480/4480 [==============================] - 1s 164us/step - loss: 12.7652 - acc: 0.5817\n",
      "Epoch 6/20\n",
      "4480/4480 [==============================] - 1s 162us/step - loss: 11.5174 - acc: 0.6161\n",
      "Epoch 7/20\n",
      "4480/4480 [==============================] - 1s 163us/step - loss: 10.7262 - acc: 0.6263\n",
      "Epoch 8/20\n",
      "4480/4480 [==============================] - 1s 160us/step - loss: 10.0518 - acc: 0.6437\n",
      "Epoch 9/20\n",
      "4480/4480 [==============================] - 1s 160us/step - loss: 9.4849 - acc: 0.6621\n",
      "Epoch 10/20\n",
      "4480/4480 [==============================] - 1s 162us/step - loss: 9.0827 - acc: 0.6746\n",
      "Epoch 11/20\n",
      "4480/4480 [==============================] - 1s 163us/step - loss: 8.6967 - acc: 0.6960\n",
      "Epoch 12/20\n",
      "4480/4480 [==============================] - 1s 162us/step - loss: 8.3696 - acc: 0.6962\n",
      "Epoch 13/20\n",
      "4480/4480 [==============================] - 1s 161us/step - loss: 8.0489 - acc: 0.7074\n",
      "Epoch 14/20\n",
      "4480/4480 [==============================] - 1s 163us/step - loss: 7.8717 - acc: 0.7134\n",
      "Epoch 15/20\n",
      "4480/4480 [==============================] - 1s 164us/step - loss: 7.7736 - acc: 0.7241\n",
      "Epoch 16/20\n",
      "4480/4480 [==============================] - 1s 162us/step - loss: 7.5136 - acc: 0.7275\n",
      "Epoch 17/20\n",
      "4480/4480 [==============================] - 1s 164us/step - loss: 7.2837 - acc: 0.7306\n",
      "Epoch 18/20\n",
      "4480/4480 [==============================] - 1s 164us/step - loss: 7.1907 - acc: 0.7373\n",
      "Epoch 19/20\n",
      "4480/4480 [==============================] - 1s 164us/step - loss: 7.0284 - acc: 0.7397\n",
      "Epoch 20/20\n",
      "4480/4480 [==============================] - 1s 162us/step - loss: 6.8622 - acc: 0.7426\n",
      "0.1892450879007239\n",
      "(4374, 14)\n",
      "Epoch 1/20\n",
      "4374/4374 [==============================] - 4s 1ms/step - loss: 34.0584 - acc: 0.2270\n",
      "Epoch 2/20\n",
      "4374/4374 [==============================] - 1s 162us/step - loss: 25.1931 - acc: 0.4005\n",
      "Epoch 3/20\n",
      "4374/4374 [==============================] - 1s 162us/step - loss: 18.8725 - acc: 0.4918\n",
      "Epoch 4/20\n",
      "4374/4374 [==============================] - 1s 165us/step - loss: 15.3499 - acc: 0.5487\n",
      "Epoch 5/20\n",
      "4374/4374 [==============================] - 1s 163us/step - loss: 13.3559 - acc: 0.5841\n",
      "Epoch 6/20\n",
      "4374/4374 [==============================] - 1s 163us/step - loss: 12.0492 - acc: 0.6072\n",
      "Epoch 7/20\n",
      "4374/4374 [==============================] - 1s 163us/step - loss: 11.0498 - acc: 0.6335\n",
      "Epoch 8/20\n",
      "4374/4374 [==============================] - 1s 162us/step - loss: 10.3881 - acc: 0.6536\n",
      "Epoch 9/20\n",
      "4374/4374 [==============================] - 1s 162us/step - loss: 9.7843 - acc: 0.6621\n",
      "Epoch 10/20\n",
      "4374/4374 [==============================] - 1s 163us/step - loss: 9.3342 - acc: 0.6806\n",
      "Epoch 11/20\n",
      "4374/4374 [==============================] - 1s 162us/step - loss: 8.9837 - acc: 0.6918\n",
      "Epoch 12/20\n",
      "4374/4374 [==============================] - 1s 161us/step - loss: 8.6070 - acc: 0.7021\n",
      "Epoch 13/20\n",
      "4374/4374 [==============================] - 1s 162us/step - loss: 8.3033 - acc: 0.7119\n",
      "Epoch 14/20\n",
      "4374/4374 [==============================] - 1s 161us/step - loss: 8.0149 - acc: 0.7172\n",
      "Epoch 15/20\n",
      "4374/4374 [==============================] - 1s 164us/step - loss: 7.8670 - acc: 0.7211\n",
      "Epoch 16/20\n",
      "4374/4374 [==============================] - 1s 163us/step - loss: 7.6098 - acc: 0.7284\n",
      "Epoch 17/20\n",
      "4374/4374 [==============================] - 1s 162us/step - loss: 7.4720 - acc: 0.7359\n",
      "Epoch 18/20\n",
      "4374/4374 [==============================] - 1s 199us/step - loss: 7.3036 - acc: 0.7405\n",
      "Epoch 19/20\n",
      "4374/4374 [==============================] - 1s 217us/step - loss: 7.1570 - acc: 0.7465\n",
      "Epoch 20/20\n",
      "4374/4374 [==============================] - 1s 205us/step - loss: 6.9869 - acc: 0.7554\n",
      "0.15371621621621623\n",
      "(4374, 14)\n",
      "Epoch 1/20\n",
      "4374/4374 [==============================] - 5s 1ms/step - loss: 34.1334 - acc: 0.2423\n",
      "Epoch 2/20\n",
      "4374/4374 [==============================] - 1s 168us/step - loss: 25.0652 - acc: 0.4161\n",
      "Epoch 3/20\n",
      "4374/4374 [==============================] - 1s 169us/step - loss: 19.2153 - acc: 0.4806\n",
      "Epoch 4/20\n",
      "4374/4374 [==============================] - 1s 170us/step - loss: 15.8347 - acc: 0.5279\n",
      "Epoch 5/20\n",
      "4374/4374 [==============================] - 1s 170us/step - loss: 13.7741 - acc: 0.5711\n",
      "Epoch 6/20\n",
      "4374/4374 [==============================] - 1s 171us/step - loss: 12.5684 - acc: 0.6001\n",
      "Epoch 7/20\n",
      "4374/4374 [==============================] - 1s 168us/step - loss: 11.4911 - acc: 0.6189\n",
      "Epoch 8/20\n",
      "4374/4374 [==============================] - 1s 170us/step - loss: 10.7908 - acc: 0.6399\n",
      "Epoch 9/20\n",
      "4374/4374 [==============================] - 1s 193us/step - loss: 10.1861 - acc: 0.6443\n",
      "Epoch 10/20\n",
      "4374/4374 [==============================] - 1s 177us/step - loss: 9.7281 - acc: 0.6651\n",
      "Epoch 11/20\n",
      "4374/4374 [==============================] - 1s 202us/step - loss: 9.3085 - acc: 0.6872\n",
      "Epoch 12/20\n",
      "4374/4374 [==============================] - 1s 239us/step - loss: 8.9520 - acc: 0.6840\n",
      "Epoch 13/20\n",
      "4374/4374 [==============================] - 1s 259us/step - loss: 8.6060 - acc: 0.6971\n",
      "Epoch 14/20\n",
      "4374/4374 [==============================] - 1s 170us/step - loss: 8.3399 - acc: 0.7110\n",
      "Epoch 15/20\n",
      "4374/4374 [==============================] - 1s 189us/step - loss: 8.0711 - acc: 0.7110\n",
      "Epoch 16/20\n",
      "4374/4374 [==============================] - 1s 176us/step - loss: 7.7911 - acc: 0.7165\n",
      "Epoch 17/20\n",
      "4374/4374 [==============================] - 1s 180us/step - loss: 7.6226 - acc: 0.7295\n",
      "Epoch 18/20\n",
      "4374/4374 [==============================] - 1s 172us/step - loss: 7.4875 - acc: 0.7396\n",
      "Epoch 19/20\n",
      "4374/4374 [==============================] - 1s 186us/step - loss: 7.2808 - acc: 0.7421\n",
      "Epoch 20/20\n",
      "4374/4374 [==============================] - 1s 167us/step - loss: 7.2016 - acc: 0.7444\n",
      "0.14649321266968326\n"
     ]
    }
   ],
   "source": [
    "denseNetwork_models = {}\n",
    "\n",
    "for cell_line in cell_lines:\n",
    "    X = df_cell_line_train[cell_line][df.columns[4:]]\n",
    "    y = oe.transform(np.array(df_cell_line_train[cell_line]['atc_level_one']).reshape(-1, 1)).toarray()\n",
    "    print(y.shape)\n",
    "    \n",
    "    denseNetwork_models[cell_line] = denseNetwork(3, 20)\n",
    "    denseNetwork_models[cell_line].fit(X, y) \n",
    "    \n",
    "    y_pred = denseNetwork_models[cell_line].predict(df_cell_line_test[cell_line][df.columns[4:]])\n",
    "    y_true = oe.transform(np.array(df_cell_line_test[cell_line]['atc_level_one']).reshape(-1, 1)).toarray()\n",
    "    print(accuracy_score(df_cell_line_test[cell_line]['atc_level_one'], np.argmax(y_pred, axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cell_line = []\n",
    "pred = []\n",
    "for pert in pert_test:\n",
    "    predictions = []\n",
    "    all_predictions = []\n",
    "    for cell_line in cell_lines:\n",
    "        mini_df = df_cell_line_test[cell_line][df_cell_line_test[cell_line]['target']==pert]\n",
    "        if mini_df.shape[0]==0:\n",
    "            continue\n",
    "        answers = []\n",
    "        for index in mini_df.index:\n",
    "            answers+=(list(np.argmax(denseNetwork_models[cell_line].predict(np.array(\n",
    "                mini_df[df.columns[4:]].loc[index]).reshape(1, -1)), axis=1)))\n",
    "            all_predictions.append(answers[-1])\n",
    "        predictions.append(Counter(answers).most_common(1)[0][0])\n",
    "    pred.append(Counter(all_predictions).most_common(1)[0][0])\n",
    "    pred_cell_line.append(Counter(predictions).most_common(1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2936170212765957"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [np.array(df_test[df_test['target']==pert]['atc_level_one'])[0] for pert in pert_test]\n",
    "accuracy_score(y_true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
