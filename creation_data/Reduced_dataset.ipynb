{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import requests\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import random\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbagen_class = pickle.load(open(\"../data/all_perturbagen_class.pkl\", \"rb\"))\n",
    "perturbagens = list(perturbagen_class.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/full_geneexp_phase2_1004.csv\")\n",
    "def getcellline(x):\n",
    "    cellline = x.split(\"_\")[1]\n",
    "    return cellline\n",
    "df['celline'] = df['signature'].apply(getcellline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"atc_level_one\"] = [val[0] for val in list(df[\"atc\"])]\n",
    "imp_columns = ['target', 'atc', 'celline', 'atc_level_one']+list(df.columns[7:985])\n",
    "df = df[imp_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>atc</th>\n",
       "      <th>celline</th>\n",
       "      <th>atc_level_one</th>\n",
       "      <th>780</th>\n",
       "      <th>7849</th>\n",
       "      <th>6193</th>\n",
       "      <th>23</th>\n",
       "      <th>9552</th>\n",
       "      <th>387</th>\n",
       "      <th>...</th>\n",
       "      <th>54681</th>\n",
       "      <th>11000</th>\n",
       "      <th>6915</th>\n",
       "      <th>6253</th>\n",
       "      <th>7264</th>\n",
       "      <th>5467</th>\n",
       "      <th>2767</th>\n",
       "      <th>23038</th>\n",
       "      <th>57048</th>\n",
       "      <th>79716</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRD-K70330367</td>\n",
       "      <td>N04BB01</td>\n",
       "      <td>YAPC</td>\n",
       "      <td>N</td>\n",
       "      <td>-1.153825</td>\n",
       "      <td>-0.050292</td>\n",
       "      <td>-0.517787</td>\n",
       "      <td>0.244794</td>\n",
       "      <td>-0.399110</td>\n",
       "      <td>0.317308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440725</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>-0.282635</td>\n",
       "      <td>0.666874</td>\n",
       "      <td>-0.319930</td>\n",
       "      <td>-0.131123</td>\n",
       "      <td>-0.213662</td>\n",
       "      <td>-1.007887</td>\n",
       "      <td>-0.182830</td>\n",
       "      <td>0.524592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRD-K70330367</td>\n",
       "      <td>N04BB01</td>\n",
       "      <td>YAPC</td>\n",
       "      <td>N</td>\n",
       "      <td>-0.150379</td>\n",
       "      <td>0.557618</td>\n",
       "      <td>-0.106715</td>\n",
       "      <td>-0.680913</td>\n",
       "      <td>-0.356638</td>\n",
       "      <td>0.821385</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017656</td>\n",
       "      <td>2.434079</td>\n",
       "      <td>-0.580103</td>\n",
       "      <td>-0.610206</td>\n",
       "      <td>0.188383</td>\n",
       "      <td>-0.309202</td>\n",
       "      <td>0.056737</td>\n",
       "      <td>-0.003205</td>\n",
       "      <td>-0.434692</td>\n",
       "      <td>-0.177766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRD-K70330367</td>\n",
       "      <td>N04BB01</td>\n",
       "      <td>HA1E</td>\n",
       "      <td>N</td>\n",
       "      <td>0.038450</td>\n",
       "      <td>0.620755</td>\n",
       "      <td>-0.324466</td>\n",
       "      <td>0.136990</td>\n",
       "      <td>0.141210</td>\n",
       "      <td>-0.112033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224989</td>\n",
       "      <td>0.076725</td>\n",
       "      <td>-0.925917</td>\n",
       "      <td>0.711872</td>\n",
       "      <td>-0.341481</td>\n",
       "      <td>0.437485</td>\n",
       "      <td>-0.052817</td>\n",
       "      <td>-0.376699</td>\n",
       "      <td>-0.047295</td>\n",
       "      <td>-0.215700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRD-K70330367</td>\n",
       "      <td>N04BB01</td>\n",
       "      <td>PC3</td>\n",
       "      <td>N</td>\n",
       "      <td>2.363550</td>\n",
       "      <td>-0.061650</td>\n",
       "      <td>0.691550</td>\n",
       "      <td>0.524950</td>\n",
       "      <td>-0.593000</td>\n",
       "      <td>0.109150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212650</td>\n",
       "      <td>0.114100</td>\n",
       "      <td>-0.307550</td>\n",
       "      <td>-1.156950</td>\n",
       "      <td>0.508250</td>\n",
       "      <td>-0.230200</td>\n",
       "      <td>-0.314000</td>\n",
       "      <td>-1.208450</td>\n",
       "      <td>-0.630500</td>\n",
       "      <td>-0.447650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRD-K70330367</td>\n",
       "      <td>N04BB01</td>\n",
       "      <td>PC3</td>\n",
       "      <td>N</td>\n",
       "      <td>-0.512800</td>\n",
       "      <td>-0.442350</td>\n",
       "      <td>0.697400</td>\n",
       "      <td>0.108150</td>\n",
       "      <td>-0.552350</td>\n",
       "      <td>0.938150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358500</td>\n",
       "      <td>-0.641800</td>\n",
       "      <td>-0.603150</td>\n",
       "      <td>-0.792450</td>\n",
       "      <td>0.384800</td>\n",
       "      <td>-0.458000</td>\n",
       "      <td>-0.074800</td>\n",
       "      <td>-0.196750</td>\n",
       "      <td>-0.669750</td>\n",
       "      <td>0.074850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 982 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          target      atc celline atc_level_one       780      7849      6193  \\\n",
       "0  BRD-K70330367  N04BB01    YAPC             N -1.153825 -0.050292 -0.517787   \n",
       "1  BRD-K70330367  N04BB01    YAPC             N -0.150379  0.557618 -0.106715   \n",
       "2  BRD-K70330367  N04BB01    HA1E             N  0.038450  0.620755 -0.324466   \n",
       "3  BRD-K70330367  N04BB01     PC3             N  2.363550 -0.061650  0.691550   \n",
       "4  BRD-K70330367  N04BB01     PC3             N -0.512800 -0.442350  0.697400   \n",
       "\n",
       "         23      9552       387    ...        54681     11000      6915  \\\n",
       "0  0.244794 -0.399110  0.317308    ...     0.440725  0.115513 -0.282635   \n",
       "1 -0.680913 -0.356638  0.821385    ...    -0.017656  2.434079 -0.580103   \n",
       "2  0.136990  0.141210 -0.112033    ...     0.224989  0.076725 -0.925917   \n",
       "3  0.524950 -0.593000  0.109150    ...     0.212650  0.114100 -0.307550   \n",
       "4  0.108150 -0.552350  0.938150    ...     0.358500 -0.641800 -0.603150   \n",
       "\n",
       "       6253      7264      5467      2767     23038     57048     79716  \n",
       "0  0.666874 -0.319930 -0.131123 -0.213662 -1.007887 -0.182830  0.524592  \n",
       "1 -0.610206  0.188383 -0.309202  0.056737 -0.003205 -0.434692 -0.177766  \n",
       "2  0.711872 -0.341481  0.437485 -0.052817 -0.376699 -0.047295 -0.215700  \n",
       "3 -1.156950  0.508250 -0.230200 -0.314000 -1.208450 -0.630500 -0.447650  \n",
       "4 -0.792450  0.384800 -0.458000 -0.074800 -0.196750 -0.669750  0.074850  \n",
       "\n",
       "[5 rows x 982 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "atc_level_vals = np.unique(df.atc_level_one)\n",
    "cell_lines = [k for k,_ in Counter(df.celline).most_common(7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.celline.isin(cell_lines)]\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df['atc_level_one'])\n",
    "\n",
    "df['atc_level_one'] = le.transform(df['atc_level_one'])\n",
    "\n",
    "pert_train, pert_test = train_test_split(np.unique(df.target), test_size=0.3)\n",
    "\n",
    "df_train = df[df.target.isin(pert_train)]\n",
    "df_test = df[df.target.isin(pert_test)]\n",
    "\n",
    "df_cell_line_train = {}\n",
    "for cell_line in cell_lines:\n",
    "    df_cell_line_train[cell_line] = df_train[df_train.celline==cell_line]\n",
    "    \n",
    "df_cell_line_test = {}\n",
    "for cell_line in cell_lines:\n",
    "    df_cell_line_test[cell_line] = df_test[df_test.celline==cell_line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kavya/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oe = OneHotEncoder()\n",
    "oe.fit(le.transform(atc_level_vals).reshape(len(atc_level_vals), 1))\n",
    "oe.transform(np.array([0]).reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network:\n",
    "    def __init__(self):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(25, activation='selu', input_dim=978))\n",
    "        self.model.add(Dense(14, activation='softmax'))\n",
    "        self.model.compile(optimizer='adagrad',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4614, 14)\n",
      "Epoch 1/20\n",
      "4614/4614 [==============================] - 1s 210us/step - loss: 2.4647 - acc: 0.2575\n",
      "Epoch 2/20\n",
      "4614/4614 [==============================] - 0s 73us/step - loss: 1.8250 - acc: 0.4094\n",
      "Epoch 3/20\n",
      "4614/4614 [==============================] - 0s 74us/step - loss: 1.6418 - acc: 0.4694\n",
      "Epoch 4/20\n",
      "4614/4614 [==============================] - 0s 74us/step - loss: 1.5195 - acc: 0.5117\n",
      "Epoch 5/20\n",
      "4614/4614 [==============================] - 0s 73us/step - loss: 1.4208 - acc: 0.5485\n",
      "Epoch 6/20\n",
      "4614/4614 [==============================] - 0s 73us/step - loss: 1.3427 - acc: 0.5774\n",
      "Epoch 7/20\n",
      "4614/4614 [==============================] - 0s 75us/step - loss: 1.2747 - acc: 0.6016\n",
      "Epoch 8/20\n",
      "4614/4614 [==============================] - 0s 101us/step - loss: 1.2161 - acc: 0.6207\n",
      "Epoch 9/20\n",
      "4614/4614 [==============================] - 0s 85us/step - loss: 1.1653 - acc: 0.6400\n",
      "Epoch 10/20\n",
      "4614/4614 [==============================] - 0s 73us/step - loss: 1.1200 - acc: 0.6513\n",
      "Epoch 11/20\n",
      "4614/4614 [==============================] - 0s 76us/step - loss: 1.0798 - acc: 0.6619\n",
      "Epoch 12/20\n",
      "4614/4614 [==============================] - 0s 75us/step - loss: 1.0430 - acc: 0.6699\n",
      "Epoch 13/20\n",
      "4614/4614 [==============================] - 0s 75us/step - loss: 1.0087 - acc: 0.6805\n",
      "Epoch 14/20\n",
      "4614/4614 [==============================] - 0s 75us/step - loss: 0.9784 - acc: 0.6896\n",
      "Epoch 15/20\n",
      "4614/4614 [==============================] - 0s 81us/step - loss: 0.9495 - acc: 0.7035\n",
      "Epoch 16/20\n",
      "4614/4614 [==============================] - 0s 88us/step - loss: 0.9235 - acc: 0.7122\n",
      "Epoch 17/20\n",
      "4614/4614 [==============================] - 0s 75us/step - loss: 0.8989 - acc: 0.7176\n",
      "Epoch 18/20\n",
      "4614/4614 [==============================] - 0s 75us/step - loss: 0.8748 - acc: 0.7252\n",
      "Epoch 19/20\n",
      "4614/4614 [==============================] - 0s 74us/step - loss: 0.8532 - acc: 0.7347\n",
      "Epoch 20/20\n",
      "4614/4614 [==============================] - 0s 75us/step - loss: 0.8324 - acc: 0.7443\n",
      "0.21924603174603174\n",
      "(4548, 14)\n",
      "Epoch 1/20\n",
      "4548/4548 [==============================] - 1s 218us/step - loss: 2.4847 - acc: 0.2513\n",
      "Epoch 2/20\n",
      "4548/4548 [==============================] - 0s 76us/step - loss: 1.8373 - acc: 0.3997\n",
      "Epoch 3/20\n",
      "4548/4548 [==============================] - 0s 75us/step - loss: 1.6620 - acc: 0.4516\n",
      "Epoch 4/20\n",
      "4548/4548 [==============================] - 0s 75us/step - loss: 1.5410 - acc: 0.4985\n",
      "Epoch 5/20\n",
      "4548/4548 [==============================] - 0s 74us/step - loss: 1.4485 - acc: 0.5244\n",
      "Epoch 6/20\n",
      "4548/4548 [==============================] - 0s 74us/step - loss: 1.3725 - acc: 0.5556\n",
      "Epoch 7/20\n",
      "4548/4548 [==============================] - 0s 85us/step - loss: 1.3107 - acc: 0.5798\n",
      "Epoch 8/20\n",
      "4548/4548 [==============================] - 0s 98us/step - loss: 1.2549 - acc: 0.6014\n",
      "Epoch 9/20\n",
      "4548/4548 [==============================] - 0s 78us/step - loss: 1.2060 - acc: 0.6205\n",
      "Epoch 10/20\n",
      "4548/4548 [==============================] - 0s 77us/step - loss: 1.1619 - acc: 0.6350\n",
      "Epoch 11/20\n",
      "4548/4548 [==============================] - 0s 100us/step - loss: 1.1228 - acc: 0.6484\n",
      "Epoch 12/20\n",
      "4548/4548 [==============================] - 0s 82us/step - loss: 1.0880 - acc: 0.6559\n",
      "Epoch 13/20\n",
      "4548/4548 [==============================] - 0s 78us/step - loss: 1.0544 - acc: 0.6697\n",
      "Epoch 14/20\n",
      "4548/4548 [==============================] - 0s 81us/step - loss: 1.0237 - acc: 0.6748\n",
      "Epoch 15/20\n",
      "4548/4548 [==============================] - 0s 80us/step - loss: 0.9952 - acc: 0.6865\n",
      "Epoch 16/20\n",
      "4548/4548 [==============================] - 0s 77us/step - loss: 0.9704 - acc: 0.6966\n",
      "Epoch 17/20\n",
      "4548/4548 [==============================] - 0s 77us/step - loss: 0.9443 - acc: 0.7062\n",
      "Epoch 18/20\n",
      "4548/4548 [==============================] - 0s 94us/step - loss: 0.9225 - acc: 0.7131\n",
      "Epoch 19/20\n",
      "4548/4548 [==============================] - 0s 83us/step - loss: 0.9028 - acc: 0.7194\n",
      "Epoch 20/20\n",
      "4548/4548 [==============================] - 0s 77us/step - loss: 0.8810 - acc: 0.7249\n",
      "0.1942043721403152\n",
      "(4534, 14)\n",
      "Epoch 1/20\n",
      "4534/4534 [==============================] - 1s 220us/step - loss: 2.5092 - acc: 0.2457\n",
      "Epoch 2/20\n",
      "4534/4534 [==============================] - 0s 75us/step - loss: 1.8324 - acc: 0.4034\n",
      "Epoch 3/20\n",
      "4534/4534 [==============================] - 0s 82us/step - loss: 1.6538 - acc: 0.4612\n",
      "Epoch 4/20\n",
      "4534/4534 [==============================] - 0s 80us/step - loss: 1.5314 - acc: 0.5040\n",
      "Epoch 5/20\n",
      "4534/4534 [==============================] - 0s 78us/step - loss: 1.4412 - acc: 0.5351\n",
      "Epoch 6/20\n",
      "4534/4534 [==============================] - 0s 90us/step - loss: 1.3652 - acc: 0.5635\n",
      "Epoch 7/20\n",
      "4534/4534 [==============================] - 0s 79us/step - loss: 1.3013 - acc: 0.5909\n",
      "Epoch 8/20\n",
      "4534/4534 [==============================] - 0s 78us/step - loss: 1.2472 - acc: 0.6120\n",
      "Epoch 9/20\n",
      "4534/4534 [==============================] - 0s 79us/step - loss: 1.1978 - acc: 0.6262\n",
      "Epoch 10/20\n",
      "4534/4534 [==============================] - 0s 80us/step - loss: 1.1541 - acc: 0.6418\n",
      "Epoch 11/20\n",
      "4534/4534 [==============================] - 0s 79us/step - loss: 1.1145 - acc: 0.6586\n",
      "Epoch 12/20\n",
      "4534/4534 [==============================] - 1s 110us/step - loss: 1.0790 - acc: 0.6652\n",
      "Epoch 13/20\n",
      "4534/4534 [==============================] - 1s 113us/step - loss: 1.0456 - acc: 0.6767\n",
      "Epoch 14/20\n",
      "4534/4534 [==============================] - 0s 86us/step - loss: 1.0150 - acc: 0.6884\n",
      "Epoch 15/20\n",
      "4534/4534 [==============================] - 0s 88us/step - loss: 0.9876 - acc: 0.7016\n",
      "Epoch 16/20\n",
      "4534/4534 [==============================] - 0s 79us/step - loss: 0.9610 - acc: 0.7075\n",
      "Epoch 17/20\n",
      "4534/4534 [==============================] - 0s 87us/step - loss: 0.9346 - acc: 0.7186\n",
      "Epoch 18/20\n",
      "4534/4534 [==============================] - 0s 77us/step - loss: 0.9115 - acc: 0.7230\n",
      "Epoch 19/20\n",
      "4534/4534 [==============================] - 0s 101us/step - loss: 0.8909 - acc: 0.7300\n",
      "Epoch 20/20\n",
      "4534/4534 [==============================] - 0s 82us/step - loss: 0.8700 - acc: 0.7386\n",
      "0.19553072625698323\n",
      "(4498, 14)\n",
      "Epoch 1/20\n",
      "4498/4498 [==============================] - 1s 296us/step - loss: 2.5529 - acc: 0.2448\n",
      "Epoch 2/20\n",
      "4498/4498 [==============================] - 0s 77us/step - loss: 1.8555 - acc: 0.3771\n",
      "Epoch 3/20\n",
      "4498/4498 [==============================] - 0s 97us/step - loss: 1.6708 - acc: 0.4455\n",
      "Epoch 4/20\n",
      "4498/4498 [==============================] - 0s 77us/step - loss: 1.5460 - acc: 0.4931\n",
      "Epoch 5/20\n",
      "4498/4498 [==============================] - 0s 75us/step - loss: 1.4506 - acc: 0.5273\n",
      "Epoch 6/20\n",
      "4498/4498 [==============================] - 0s 77us/step - loss: 1.3701 - acc: 0.5591\n",
      "Epoch 7/20\n",
      "4498/4498 [==============================] - 0s 76us/step - loss: 1.3021 - acc: 0.5776\n",
      "Epoch 8/20\n",
      "4498/4498 [==============================] - 0s 75us/step - loss: 1.2428 - acc: 0.6007\n",
      "Epoch 9/20\n",
      "4498/4498 [==============================] - 0s 100us/step - loss: 1.1896 - acc: 0.6218\n",
      "Epoch 10/20\n",
      "4498/4498 [==============================] - 0s 79us/step - loss: 1.1426 - acc: 0.6410\n",
      "Epoch 11/20\n",
      "4498/4498 [==============================] - 0s 77us/step - loss: 1.1005 - acc: 0.6527\n",
      "Epoch 12/20\n",
      "4498/4498 [==============================] - 0s 87us/step - loss: 1.0632 - acc: 0.6654\n",
      "Epoch 13/20\n",
      "4498/4498 [==============================] - 0s 86us/step - loss: 1.0262 - acc: 0.6783\n",
      "Epoch 14/20\n",
      "4498/4498 [==============================] - 0s 75us/step - loss: 0.9956 - acc: 0.6881\n",
      "Epoch 15/20\n",
      "4498/4498 [==============================] - 0s 78us/step - loss: 0.9635 - acc: 0.7032\n",
      "Epoch 16/20\n",
      "4498/4498 [==============================] - 0s 75us/step - loss: 0.9358 - acc: 0.7099\n",
      "Epoch 17/20\n",
      "4498/4498 [==============================] - 0s 75us/step - loss: 0.9106 - acc: 0.7185\n",
      "Epoch 18/20\n",
      "4498/4498 [==============================] - 0s 74us/step - loss: 0.8857 - acc: 0.7285\n",
      "Epoch 19/20\n",
      "4498/4498 [==============================] - 0s 79us/step - loss: 0.8630 - acc: 0.7394\n",
      "Epoch 20/20\n",
      "4498/4498 [==============================] - 1s 113us/step - loss: 0.8419 - acc: 0.7430\n",
      "0.18665977249224405\n",
      "(4480, 14)\n",
      "Epoch 1/20\n",
      "4480/4480 [==============================] - 1s 238us/step - loss: 2.5137 - acc: 0.2455\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4480/4480 [==============================] - 0s 76us/step - loss: 1.8357 - acc: 0.3984\n",
      "Epoch 3/20\n",
      "4480/4480 [==============================] - 0s 72us/step - loss: 1.6628 - acc: 0.4616\n",
      "Epoch 4/20\n",
      "4480/4480 [==============================] - 0s 73us/step - loss: 1.5426 - acc: 0.5067\n",
      "Epoch 5/20\n",
      "4480/4480 [==============================] - 0s 73us/step - loss: 1.4511 - acc: 0.5335\n",
      "Epoch 6/20\n",
      "4480/4480 [==============================] - 0s 77us/step - loss: 1.3729 - acc: 0.5645\n",
      "Epoch 7/20\n",
      "4480/4480 [==============================] - 0s 97us/step - loss: 1.3077 - acc: 0.5826\n",
      "Epoch 8/20\n",
      "4480/4480 [==============================] - 0s 75us/step - loss: 1.2502 - acc: 0.6056\n",
      "Epoch 9/20\n",
      "4480/4480 [==============================] - 0s 85us/step - loss: 1.1992 - acc: 0.6176\n",
      "Epoch 10/20\n",
      "4480/4480 [==============================] - 0s 87us/step - loss: 1.1524 - acc: 0.6355\n",
      "Epoch 11/20\n",
      "4480/4480 [==============================] - 0s 74us/step - loss: 1.1105 - acc: 0.6525\n",
      "Epoch 12/20\n",
      "4480/4480 [==============================] - 0s 88us/step - loss: 1.0710 - acc: 0.6636\n",
      "Epoch 13/20\n",
      "4480/4480 [==============================] - 0s 75us/step - loss: 1.0363 - acc: 0.6741\n",
      "Epoch 14/20\n",
      "4480/4480 [==============================] - 0s 77us/step - loss: 1.0032 - acc: 0.6929\n",
      "Epoch 15/20\n",
      "4480/4480 [==============================] - 0s 73us/step - loss: 0.9724 - acc: 0.7022\n",
      "Epoch 16/20\n",
      "4480/4480 [==============================] - 0s 75us/step - loss: 0.9450 - acc: 0.7089\n",
      "Epoch 17/20\n",
      "4480/4480 [==============================] - 0s 75us/step - loss: 0.9182 - acc: 0.7183\n",
      "Epoch 18/20\n",
      "4480/4480 [==============================] - 0s 75us/step - loss: 0.8934 - acc: 0.7299\n",
      "Epoch 19/20\n",
      "4480/4480 [==============================] - 0s 102us/step - loss: 0.8703 - acc: 0.7359\n",
      "Epoch 20/20\n",
      "4480/4480 [==============================] - 0s 80us/step - loss: 0.8473 - acc: 0.7442\n",
      "0.20113753877973112\n",
      "(4374, 14)\n",
      "Epoch 1/20\n",
      "4374/4374 [==============================] - 1s 264us/step - loss: 2.5406 - acc: 0.2369\n",
      "Epoch 2/20\n",
      "4374/4374 [==============================] - 0s 109us/step - loss: 1.8587 - acc: 0.3829\n",
      "Epoch 3/20\n",
      "4374/4374 [==============================] - 0s 82us/step - loss: 1.6792 - acc: 0.4408\n",
      "Epoch 4/20\n",
      "4374/4374 [==============================] - 0s 81us/step - loss: 1.5569 - acc: 0.4909\n",
      "Epoch 5/20\n",
      "4374/4374 [==============================] - 0s 82us/step - loss: 1.4615 - acc: 0.5288\n",
      "Epoch 6/20\n",
      "4374/4374 [==============================] - 0s 82us/step - loss: 1.3853 - acc: 0.5485\n",
      "Epoch 7/20\n",
      "4374/4374 [==============================] - 0s 78us/step - loss: 1.3217 - acc: 0.5764\n",
      "Epoch 8/20\n",
      "4374/4374 [==============================] - 0s 78us/step - loss: 1.2620 - acc: 0.5905\n",
      "Epoch 9/20\n",
      "4374/4374 [==============================] - 1s 118us/step - loss: 1.2116 - acc: 0.6150\n",
      "Epoch 10/20\n",
      "4374/4374 [==============================] - 0s 78us/step - loss: 1.1643 - acc: 0.6244\n",
      "Epoch 11/20\n",
      "4374/4374 [==============================] - 0s 92us/step - loss: 1.1241 - acc: 0.6404\n",
      "Epoch 12/20\n",
      "4374/4374 [==============================] - 0s 77us/step - loss: 1.0865 - acc: 0.6507\n",
      "Epoch 13/20\n",
      "4374/4374 [==============================] - 0s 79us/step - loss: 1.0523 - acc: 0.6600\n",
      "Epoch 14/20\n",
      "4374/4374 [==============================] - 0s 84us/step - loss: 1.0199 - acc: 0.6738\n",
      "Epoch 15/20\n",
      "4374/4374 [==============================] - 0s 83us/step - loss: 0.9901 - acc: 0.6861\n",
      "Epoch 16/20\n",
      "4374/4374 [==============================] - 0s 95us/step - loss: 0.9620 - acc: 0.6941\n",
      "Epoch 17/20\n",
      "4374/4374 [==============================] - 0s 104us/step - loss: 0.9350 - acc: 0.7030\n",
      "Epoch 18/20\n",
      "4374/4374 [==============================] - 0s 107us/step - loss: 0.9115 - acc: 0.7140\n",
      "Epoch 19/20\n",
      "4374/4374 [==============================] - 0s 102us/step - loss: 0.8883 - acc: 0.7215\n",
      "Epoch 20/20\n",
      "4374/4374 [==============================] - 0s 87us/step - loss: 0.8670 - acc: 0.7284\n",
      "0.14921171171171171\n",
      "(4374, 14)\n",
      "Epoch 1/20\n",
      "4374/4374 [==============================] - 1s 281us/step - loss: 2.5041 - acc: 0.2387\n",
      "Epoch 2/20\n",
      "4374/4374 [==============================] - 0s 80us/step - loss: 1.8638 - acc: 0.3786\n",
      "Epoch 3/20\n",
      "4374/4374 [==============================] - 0s 79us/step - loss: 1.6953 - acc: 0.4351\n",
      "Epoch 4/20\n",
      "4374/4374 [==============================] - 0s 95us/step - loss: 1.5746 - acc: 0.4831\n",
      "Epoch 5/20\n",
      "4374/4374 [==============================] - 0s 88us/step - loss: 1.4845 - acc: 0.5206\n",
      "Epoch 6/20\n",
      "4374/4374 [==============================] - 0s 93us/step - loss: 1.4081 - acc: 0.5450\n",
      "Epoch 7/20\n",
      "4374/4374 [==============================] - 0s 81us/step - loss: 1.3454 - acc: 0.5713\n",
      "Epoch 8/20\n",
      "4374/4374 [==============================] - 0s 82us/step - loss: 1.2865 - acc: 0.5878\n",
      "Epoch 9/20\n",
      "4374/4374 [==============================] - 0s 91us/step - loss: 1.2363 - acc: 0.6045\n",
      "Epoch 10/20\n",
      "4374/4374 [==============================] - 0s 75us/step - loss: 1.1909 - acc: 0.6214\n",
      "Epoch 11/20\n",
      "4374/4374 [==============================] - 0s 78us/step - loss: 1.1507 - acc: 0.6305\n",
      "Epoch 12/20\n",
      "4374/4374 [==============================] - 1s 115us/step - loss: 1.1118 - acc: 0.6417\n",
      "Epoch 13/20\n",
      "4374/4374 [==============================] - 0s 102us/step - loss: 1.0780 - acc: 0.6557\n",
      "Epoch 14/20\n",
      "4374/4374 [==============================] - 0s 81us/step - loss: 1.0457 - acc: 0.6694\n",
      "Epoch 15/20\n",
      "4374/4374 [==============================] - 0s 78us/step - loss: 1.0155 - acc: 0.6859\n",
      "Epoch 16/20\n",
      "4374/4374 [==============================] - 0s 76us/step - loss: 0.9863 - acc: 0.6948\n",
      "Epoch 17/20\n",
      "4374/4374 [==============================] - 0s 79us/step - loss: 0.9593 - acc: 0.7023\n",
      "Epoch 18/20\n",
      "4374/4374 [==============================] - 0s 86us/step - loss: 0.9352 - acc: 0.7122\n",
      "Epoch 19/20\n",
      "4374/4374 [==============================] - 0s 82us/step - loss: 0.9117 - acc: 0.7206\n",
      "Epoch 20/20\n",
      "4374/4374 [==============================] - 0s 97us/step - loss: 0.8904 - acc: 0.7254\n",
      "0.16176470588235295\n"
     ]
    }
   ],
   "source": [
    "network_models = {}\n",
    "\n",
    "for cell_line in cell_lines:\n",
    "    X = df_cell_line_train[cell_line][df.columns[4:]]\n",
    "    y = oe.transform(np.array(df_cell_line_train[cell_line]['atc_level_one']).reshape(-1, 1)).toarray()\n",
    "    print(y.shape)\n",
    "    \n",
    "    network_models[cell_line] = network()\n",
    "    network_models[cell_line].fit(X, y) \n",
    "    \n",
    "    y_pred = network_models[cell_line].predict(df_cell_line_test[cell_line][df.columns[4:]])\n",
    "    y_true = oe.transform(np.array(df_cell_line_test[cell_line]['atc_level_one']).reshape(-1, 1)).toarray()\n",
    "    print(accuracy_score(df_cell_line_test[cell_line]['atc_level_one'], np.argmax(y_pred, axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cell_line = []\n",
    "pred = []\n",
    "for pert in pert_test:\n",
    "    predictions = []\n",
    "    all_predictions = []\n",
    "    for cell_line in cell_lines:\n",
    "        mini_df = df_cell_line_test[cell_line][df_cell_line_test[cell_line]['target']==pert]\n",
    "        if mini_df.shape[0]==0:\n",
    "            continue\n",
    "        answers = []\n",
    "        for index in mini_df.index:\n",
    "            answers+=(list(np.argmax(network_models[cell_line].predict(np.array(\n",
    "                mini_df[df.columns[4:]].loc[index]).reshape(1, -1)), axis=1)))\n",
    "            all_predictions.append(answers[-1])\n",
    "        predictions.append(Counter(answers).most_common(1)[0][0])\n",
    "    pred.append(Counter(all_predictions).most_common(1)[0][0])\n",
    "    pred_cell_line.append(Counter(predictions).most_common(1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3021276595744681"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [np.array(df_test[df_test['target']==pert]['atc_level_one'])[0] for pert in pert_test]\n",
    "accuracy_score(y_true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
