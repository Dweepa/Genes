{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import sys\n",
    "import matplotlib.pyplot as plt1 \n",
    "import numpy as np\n",
    "from IPython.display import Audio, display\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Conv2D, Lambda, Dense, Flatten,MaxPooling2D, concatenate, Conv1D,Conv2D, Flatten, Reshape, Embedding, GRU, SpatialDropout1D, LSTM, Dropout, BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "from itertools import permutations\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "from scipy.stats import trim_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>inchi_key</th>\n",
       "      <th>atc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>NC12CC3CC(CC(C3)C1)C2</td>\n",
       "      <td>amantadine</td>\n",
       "      <td>BRD-K70330367</td>\n",
       "      <td>DKNWSYNQZKUICI-UHFFFAOYSA-N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>CS(=O)(=O)OCCCCOS(C)(=O)=O</td>\n",
       "      <td>busulfan</td>\n",
       "      <td>BRD-K23204545</td>\n",
       "      <td>COVZYZSDYWQREU-UHFFFAOYSA-N</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>CCCC(C)(COC(N)=O)COC(=O)NC(C)C</td>\n",
       "      <td>carisoprodol</td>\n",
       "      <td>BRD-A99939097</td>\n",
       "      <td>OFZCIYFFPZCNJE-UHFFFAOYSA-N</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>CCN(CC)C(=O)N1CCN(C)CC1</td>\n",
       "      <td>diethylcarbamazine</td>\n",
       "      <td>BRD-K45542189</td>\n",
       "      <td>RCKMWOKWVGPNJF-UHFFFAOYSA-N</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>CCN(CC)C(=S)SSC(=S)N(CC)CC</td>\n",
       "      <td>disulfiram</td>\n",
       "      <td>BRD-K32744045</td>\n",
       "      <td>AUZONCFQVSMFAP-UHFFFAOYSA-N</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             smiles                name             id  \\\n",
       "75            NC12CC3CC(CC(C3)C1)C2          amantadine  BRD-K70330367   \n",
       "291      CS(=O)(=O)OCCCCOS(C)(=O)=O            busulfan  BRD-K23204545   \n",
       "322  CCCC(C)(COC(N)=O)COC(=O)NC(C)C        carisoprodol  BRD-A99939097   \n",
       "491         CCN(CC)C(=O)N1CCN(C)CC1  diethylcarbamazine  BRD-K45542189   \n",
       "510      CCN(CC)C(=S)SSC(=S)N(CC)CC          disulfiram  BRD-K32744045   \n",
       "\n",
       "                       inchi_key atc  \n",
       "75   DKNWSYNQZKUICI-UHFFFAOYSA-N   N  \n",
       "291  COVZYZSDYWQREU-UHFFFAOYSA-N   L  \n",
       "322  OFZCIYFFPZCNJE-UHFFFAOYSA-N   M  \n",
       "491  RCKMWOKWVGPNJF-UHFFFAOYSA-N   P  \n",
       "510  AUZONCFQVSMFAP-UHFFFAOYSA-N   P  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full = pd.read_csv(\"../data/drug_class_identification/all3.csv\")\n",
    "full = full.dropna()\n",
    "full['atc'] = full['atc'].apply(lambda x : x[0])\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define our own plot function\n",
    "def scatter(x, y, subtitle=None):\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(y)\n",
    "\n",
    "    # We choose a color palette with seaborn.\n",
    "    palette = np.array(sns.color_palette(\"hls\", 3))\n",
    "\n",
    "    # We create a scatter plot.\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40,\n",
    "                    c=palette[labels.astype(np.int)])\n",
    "    plt.xlim(-25, 25)\n",
    "    plt.ylim(-25, 25)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "\n",
    "    # We add the labels for each digit.\n",
    "    txts = []\n",
    "    for i in range(3):\n",
    "        # Position of each label.\n",
    "        xtext, ytext = trim_mean(x[labels == i, :], axis=0, proportiontocut=0.2)\n",
    "        letter = le.inverse_transform([i])[0]\n",
    "        txt = ax.text(xtext, ytext, str(letter), fontsize=24)\n",
    "        txt.set_path_effects([\n",
    "            PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "            PathEffects.Normal()])\n",
    "        txts.append(txt)\n",
    "        \n",
    "    if subtitle != None:\n",
    "        plt.suptitle(subtitle)\n",
    "        \n",
    "    plt.savefig(subtitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2170, 17)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snn = pd.read_csv('EMB_triplet_3_500_16_0.9_5-50')\n",
    "snn['id'] = snn['pert_id']\n",
    "snn1 = snn.groupby(['id']).mean()\n",
    "snn1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>e1</th>\n",
       "      <th>e2</th>\n",
       "      <th>e3</th>\n",
       "      <th>e4</th>\n",
       "      <th>e5</th>\n",
       "      <th>e6</th>\n",
       "      <th>e7</th>\n",
       "      <th>e8</th>\n",
       "      <th>e9</th>\n",
       "      <th>e10</th>\n",
       "      <th>e11</th>\n",
       "      <th>e12</th>\n",
       "      <th>e13</th>\n",
       "      <th>e14</th>\n",
       "      <th>e15</th>\n",
       "      <th>e16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BRD-A00147595</th>\n",
       "      <td>20.5</td>\n",
       "      <td>-0.051912</td>\n",
       "      <td>-0.046225</td>\n",
       "      <td>-0.079341</td>\n",
       "      <td>0.010777</td>\n",
       "      <td>0.199179</td>\n",
       "      <td>0.063099</td>\n",
       "      <td>-0.008241</td>\n",
       "      <td>-0.000671</td>\n",
       "      <td>0.207154</td>\n",
       "      <td>-0.132532</td>\n",
       "      <td>-0.337864</td>\n",
       "      <td>-0.068388</td>\n",
       "      <td>0.055600</td>\n",
       "      <td>0.015693</td>\n",
       "      <td>0.483786</td>\n",
       "      <td>0.033555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRD-A00218260</th>\n",
       "      <td>62.5</td>\n",
       "      <td>-0.007211</td>\n",
       "      <td>-0.019740</td>\n",
       "      <td>-0.087918</td>\n",
       "      <td>0.043078</td>\n",
       "      <td>0.186389</td>\n",
       "      <td>0.050391</td>\n",
       "      <td>-0.042841</td>\n",
       "      <td>-0.038788</td>\n",
       "      <td>0.219889</td>\n",
       "      <td>-0.129041</td>\n",
       "      <td>-0.340753</td>\n",
       "      <td>-0.050279</td>\n",
       "      <td>0.034886</td>\n",
       "      <td>0.055037</td>\n",
       "      <td>0.480075</td>\n",
       "      <td>0.092194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRD-A00376169</th>\n",
       "      <td>104.5</td>\n",
       "      <td>-0.035873</td>\n",
       "      <td>-0.038781</td>\n",
       "      <td>-0.071005</td>\n",
       "      <td>0.011709</td>\n",
       "      <td>0.188347</td>\n",
       "      <td>0.062192</td>\n",
       "      <td>-0.015706</td>\n",
       "      <td>-0.001051</td>\n",
       "      <td>0.206982</td>\n",
       "      <td>-0.126873</td>\n",
       "      <td>-0.332761</td>\n",
       "      <td>-0.050283</td>\n",
       "      <td>0.053545</td>\n",
       "      <td>0.025172</td>\n",
       "      <td>0.478171</td>\n",
       "      <td>0.048873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRD-A00546892</th>\n",
       "      <td>146.5</td>\n",
       "      <td>-0.083619</td>\n",
       "      <td>-0.048509</td>\n",
       "      <td>-0.197024</td>\n",
       "      <td>0.099494</td>\n",
       "      <td>0.271578</td>\n",
       "      <td>0.030857</td>\n",
       "      <td>-0.031520</td>\n",
       "      <td>-0.126297</td>\n",
       "      <td>0.232526</td>\n",
       "      <td>-0.192449</td>\n",
       "      <td>-0.365771</td>\n",
       "      <td>-0.211621</td>\n",
       "      <td>0.006241</td>\n",
       "      <td>0.019896</td>\n",
       "      <td>0.507215</td>\n",
       "      <td>0.036830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRD-A00938334</th>\n",
       "      <td>188.5</td>\n",
       "      <td>-0.008202</td>\n",
       "      <td>-0.008061</td>\n",
       "      <td>-0.162835</td>\n",
       "      <td>0.113867</td>\n",
       "      <td>0.216934</td>\n",
       "      <td>0.018615</td>\n",
       "      <td>-0.071992</td>\n",
       "      <td>-0.136495</td>\n",
       "      <td>0.225272</td>\n",
       "      <td>-0.158428</td>\n",
       "      <td>-0.337248</td>\n",
       "      <td>-0.135821</td>\n",
       "      <td>-0.009357</td>\n",
       "      <td>0.072566</td>\n",
       "      <td>0.464084</td>\n",
       "      <td>0.114936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Unnamed: 0        e1        e2        e3        e4        e5  \\\n",
       "id                                                                            \n",
       "BRD-A00147595        20.5 -0.051912 -0.046225 -0.079341  0.010777  0.199179   \n",
       "BRD-A00218260        62.5 -0.007211 -0.019740 -0.087918  0.043078  0.186389   \n",
       "BRD-A00376169       104.5 -0.035873 -0.038781 -0.071005  0.011709  0.188347   \n",
       "BRD-A00546892       146.5 -0.083619 -0.048509 -0.197024  0.099494  0.271578   \n",
       "BRD-A00938334       188.5 -0.008202 -0.008061 -0.162835  0.113867  0.216934   \n",
       "\n",
       "                     e6        e7        e8        e9       e10       e11  \\\n",
       "id                                                                          \n",
       "BRD-A00147595  0.063099 -0.008241 -0.000671  0.207154 -0.132532 -0.337864   \n",
       "BRD-A00218260  0.050391 -0.042841 -0.038788  0.219889 -0.129041 -0.340753   \n",
       "BRD-A00376169  0.062192 -0.015706 -0.001051  0.206982 -0.126873 -0.332761   \n",
       "BRD-A00546892  0.030857 -0.031520 -0.126297  0.232526 -0.192449 -0.365771   \n",
       "BRD-A00938334  0.018615 -0.071992 -0.136495  0.225272 -0.158428 -0.337248   \n",
       "\n",
       "                    e12       e13       e14       e15       e16  \n",
       "id                                                               \n",
       "BRD-A00147595 -0.068388  0.055600  0.015693  0.483786  0.033555  \n",
       "BRD-A00218260 -0.050279  0.034886  0.055037  0.480075  0.092194  \n",
       "BRD-A00376169 -0.050283  0.053545  0.025172  0.478171  0.048873  \n",
       "BRD-A00546892 -0.211621  0.006241  0.019896  0.507215  0.036830  \n",
       "BRD-A00938334 -0.135821 -0.009357  0.072566  0.464084  0.114936  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snn1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_snn = pd.merge(snn, full, how=\"inner\").drop(['id','smiles','name','inchi_key','pert_id','Unnamed: 0'],axis=1).dropna()\n",
    "result_snn = result_snn[result_snn.atc.isin(['C','L','N'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e1</th>\n",
       "      <th>e2</th>\n",
       "      <th>e3</th>\n",
       "      <th>e4</th>\n",
       "      <th>e5</th>\n",
       "      <th>e6</th>\n",
       "      <th>e7</th>\n",
       "      <th>e8</th>\n",
       "      <th>e9</th>\n",
       "      <th>e10</th>\n",
       "      <th>e11</th>\n",
       "      <th>e12</th>\n",
       "      <th>e13</th>\n",
       "      <th>e14</th>\n",
       "      <th>e15</th>\n",
       "      <th>e16</th>\n",
       "      <th>atc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-0.183448</td>\n",
       "      <td>-0.088374</td>\n",
       "      <td>-0.298852</td>\n",
       "      <td>0.141471</td>\n",
       "      <td>0.356243</td>\n",
       "      <td>0.013249</td>\n",
       "      <td>-0.001803</td>\n",
       "      <td>-0.207486</td>\n",
       "      <td>0.229378</td>\n",
       "      <td>-0.251088</td>\n",
       "      <td>-0.377218</td>\n",
       "      <td>-0.378206</td>\n",
       "      <td>-0.015539</td>\n",
       "      <td>-0.035752</td>\n",
       "      <td>0.523691</td>\n",
       "      <td>-0.048028</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>-0.185150</td>\n",
       "      <td>-0.092180</td>\n",
       "      <td>-0.293811</td>\n",
       "      <td>0.133686</td>\n",
       "      <td>0.357638</td>\n",
       "      <td>0.017342</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>-0.192717</td>\n",
       "      <td>0.231722</td>\n",
       "      <td>-0.250480</td>\n",
       "      <td>-0.383006</td>\n",
       "      <td>-0.374091</td>\n",
       "      <td>-0.008439</td>\n",
       "      <td>-0.038505</td>\n",
       "      <td>0.529485</td>\n",
       "      <td>-0.051879</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.255648</td>\n",
       "      <td>0.131313</td>\n",
       "      <td>-0.080232</td>\n",
       "      <td>0.183721</td>\n",
       "      <td>0.105543</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>-0.235274</td>\n",
       "      <td>-0.185011</td>\n",
       "      <td>0.297990</td>\n",
       "      <td>-0.094100</td>\n",
       "      <td>-0.384150</td>\n",
       "      <td>0.106757</td>\n",
       "      <td>-0.053028</td>\n",
       "      <td>0.279614</td>\n",
       "      <td>0.506027</td>\n",
       "      <td>0.427559</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-0.130725</td>\n",
       "      <td>-0.069101</td>\n",
       "      <td>-0.291202</td>\n",
       "      <td>0.150245</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.016205</td>\n",
       "      <td>-0.031880</td>\n",
       "      <td>-0.201702</td>\n",
       "      <td>0.259922</td>\n",
       "      <td>-0.250814</td>\n",
       "      <td>-0.409143</td>\n",
       "      <td>-0.334909</td>\n",
       "      <td>-0.017611</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>0.547097</td>\n",
       "      <td>0.010761</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.240981</td>\n",
       "      <td>0.119331</td>\n",
       "      <td>-0.100761</td>\n",
       "      <td>0.189807</td>\n",
       "      <td>0.118800</td>\n",
       "      <td>-0.001084</td>\n",
       "      <td>-0.229800</td>\n",
       "      <td>-0.190443</td>\n",
       "      <td>0.297566</td>\n",
       "      <td>-0.106891</td>\n",
       "      <td>-0.392855</td>\n",
       "      <td>0.074723</td>\n",
       "      <td>-0.052318</td>\n",
       "      <td>0.271000</td>\n",
       "      <td>0.520312</td>\n",
       "      <td>0.414156</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          e1        e2        e3        e4        e5        e6        e7  \\\n",
       "84 -0.183448 -0.088374 -0.298852  0.141471  0.356243  0.013249 -0.001803   \n",
       "85 -0.185150 -0.092180 -0.293811  0.133686  0.357638  0.017342  0.002558   \n",
       "86  0.255648  0.131313 -0.080232  0.183721  0.105543  0.000734 -0.235274   \n",
       "87 -0.130725 -0.069101 -0.291202  0.150245  0.345000  0.016205 -0.031880   \n",
       "88  0.240981  0.119331 -0.100761  0.189807  0.118800 -0.001084 -0.229800   \n",
       "\n",
       "          e8        e9       e10       e11       e12       e13       e14  \\\n",
       "84 -0.207486  0.229378 -0.251088 -0.377218 -0.378206 -0.015539 -0.035752   \n",
       "85 -0.192717  0.231722 -0.250480 -0.383006 -0.374091 -0.008439 -0.038505   \n",
       "86 -0.185011  0.297990 -0.094100 -0.384150  0.106757 -0.053028  0.279614   \n",
       "87 -0.201702  0.259922 -0.250814 -0.409143 -0.334909 -0.017611  0.002179   \n",
       "88 -0.190443  0.297566 -0.106891 -0.392855  0.074723 -0.052318  0.271000   \n",
       "\n",
       "         e15       e16 atc  \n",
       "84  0.523691 -0.048028   N  \n",
       "85  0.529485 -0.051879   N  \n",
       "86  0.506027  0.427559   N  \n",
       "87  0.547097  0.010761   N  \n",
       "88  0.520312  0.414156   N  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_snn = result_snn['atc']\n",
    "X_snn = result_snn.drop(['atc'],axis=1)\n",
    "X_snn = np.asarray(X_snn)\n",
    "result_snn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_snn.shape\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(y_snn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:2831: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.mean(atmp[sl], axis=axis)\n",
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:2831: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.mean(atmp[sl], axis=axis)\n"
     ]
    }
   ],
   "source": [
    "x_train_snn, x_test_snn, y_train_snn, y_test_snn = train_test_split(X_snn,labels)\n",
    "\n",
    "x_train_flat_snn = x_train_snn.reshape(-1,16)\n",
    "x_test_flat_snn = x_test_snn.reshape(-1,16)\n",
    "\n",
    "tsne = TSNE()\n",
    "train_tsne_embeds_snn = tsne.fit_transform(x_train_flat_snn[:1000])\n",
    "scatter(train_tsne_embeds_snn, y_train_snn[:1000], \"Samples from Training Data LINCS (Triplet) Before\")\n",
    "\n",
    "eval_tsne_embeds_snn = tsne.fit_transform(x_test_flat_snn[:1000])\n",
    "scatter(eval_tsne_embeds_snn, y_test_snn[:1000], \"Samples from Validation Data LINCS (Triplet) Before\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseNetwork(op):    \n",
    "        model = Sequential()\n",
    "        model.add(Dense(50, activation='softmax', input_dim=16))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(20, activation='softmax'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(op, activation='softmax'))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                850       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 2,113\n",
      "Trainable params: 2,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = baseNetwork(3)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "18819/18819 [==============================] - 2s 88us/step - loss: 1.0483 - acc: 0.4922\n",
      "Epoch 2/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0353 - acc: 0.5121\n",
      "Epoch 3/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0325 - acc: 0.5121\n",
      "Epoch 4/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0301 - acc: 0.5121\n",
      "Epoch 5/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0261 - acc: 0.5121\n",
      "Epoch 6/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0208 - acc: 0.5121\n",
      "Epoch 7/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0197 - acc: 0.5121\n",
      "Epoch 8/500\n",
      "18819/18819 [==============================] - 1s 75us/step - loss: 1.0165 - acc: 0.5120\n",
      "Epoch 9/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0142 - acc: 0.5122\n",
      "Epoch 10/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0116 - acc: 0.5116\n",
      "Epoch 11/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0124 - acc: 0.5104\n",
      "Epoch 12/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0122 - acc: 0.5119\n",
      "Epoch 13/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0104 - acc: 0.5117\n",
      "Epoch 14/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0073 - acc: 0.5120\n",
      "Epoch 15/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 1.0120 - acc: 0.5121\n",
      "Epoch 16/500\n",
      "18819/18819 [==============================] - 1s 66us/step - loss: 1.0080 - acc: 0.5121\n",
      "Epoch 17/500\n",
      "18819/18819 [==============================] - 1s 77us/step - loss: 1.0089 - acc: 0.5121\n",
      "Epoch 18/500\n",
      "18819/18819 [==============================] - 1s 73us/step - loss: 1.0089 - acc: 0.5121\n",
      "Epoch 19/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0076 - acc: 0.5121\n",
      "Epoch 20/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0063 - acc: 0.5121\n",
      "Epoch 21/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0069 - acc: 0.5121\n",
      "Epoch 22/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0061 - acc: 0.5121\n",
      "Epoch 23/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0065 - acc: 0.5121\n",
      "Epoch 24/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 1.0060 - acc: 0.5121\n",
      "Epoch 25/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 1.0069 - acc: 0.5121\n",
      "Epoch 26/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0054 - acc: 0.5121\n",
      "Epoch 27/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 1.0055 - acc: 0.5121\n",
      "Epoch 28/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0057 - acc: 0.5121\n",
      "Epoch 29/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 1.0039 - acc: 0.5121\n",
      "Epoch 30/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0039 - acc: 0.5121\n",
      "Epoch 31/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0051 - acc: 0.5121\n",
      "Epoch 32/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0041 - acc: 0.5121\n",
      "Epoch 33/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0032 - acc: 0.5121\n",
      "Epoch 34/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 1.0048 - acc: 0.5121\n",
      "Epoch 35/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 1.0040 - acc: 0.5121\n",
      "Epoch 36/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0032 - acc: 0.5121\n",
      "Epoch 37/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0037 - acc: 0.5121\n",
      "Epoch 38/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0030 - acc: 0.5121\n",
      "Epoch 39/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0029 - acc: 0.5121\n",
      "Epoch 40/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 1.0047 - acc: 0.5121\n",
      "Epoch 41/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0030 - acc: 0.5121\n",
      "Epoch 42/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0032 - acc: 0.5121\n",
      "Epoch 43/500\n",
      "18819/18819 [==============================] - 1s 73us/step - loss: 1.0036 - acc: 0.5121\n",
      "Epoch 44/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0036 - acc: 0.5121\n",
      "Epoch 45/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0022 - acc: 0.5121\n",
      "Epoch 46/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0029 - acc: 0.5121\n",
      "Epoch 47/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0039 - acc: 0.5121\n",
      "Epoch 48/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0021 - acc: 0.5121\n",
      "Epoch 49/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 1.0030 - acc: 0.5121\n",
      "Epoch 50/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0038 - acc: 0.5121\n",
      "Epoch 51/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0036 - acc: 0.5121\n",
      "Epoch 52/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0026 - acc: 0.5121\n",
      "Epoch 53/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0035 - acc: 0.5121\n",
      "Epoch 54/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0021 - acc: 0.5121\n",
      "Epoch 55/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0013 - acc: 0.5121\n",
      "Epoch 56/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0032 - acc: 0.5121\n",
      "Epoch 57/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0029 - acc: 0.5121\n",
      "Epoch 58/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0020 - acc: 0.5121\n",
      "Epoch 59/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0023 - acc: 0.5121\n",
      "Epoch 60/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0026 - acc: 0.5121\n",
      "Epoch 61/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0017 - acc: 0.5121\n",
      "Epoch 62/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 1.0022 - acc: 0.5121\n",
      "Epoch 63/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 1.0020 - acc: 0.5121\n",
      "Epoch 64/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0028 - acc: 0.5121\n",
      "Epoch 65/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0019 - acc: 0.5121\n",
      "Epoch 66/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 1.0027 - acc: 0.5121\n",
      "Epoch 67/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0024 - acc: 0.5121\n",
      "Epoch 68/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0030 - acc: 0.5121\n",
      "Epoch 69/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 1.0018 - acc: 0.5121\n",
      "Epoch 70/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 1.0015 - acc: 0.5121\n",
      "Epoch 71/500\n",
      "18819/18819 [==============================] - 1s 67us/step - loss: 1.0016 - acc: 0.5121\n",
      "Epoch 72/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 1.0013 - acc: 0.5121\n",
      "Epoch 73/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 1.0008 - acc: 0.5121\n",
      "Epoch 74/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 1.0017 - acc: 0.5121\n",
      "Epoch 75/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0022 - acc: 0.5121\n",
      "Epoch 76/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0023 - acc: 0.5121\n",
      "Epoch 77/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0023 - acc: 0.5121\n",
      "Epoch 78/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0008 - acc: 0.5121\n",
      "Epoch 79/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0025 - acc: 0.5121\n",
      "Epoch 80/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0025 - acc: 0.5121\n",
      "Epoch 81/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0011 - acc: 0.5121\n",
      "Epoch 82/500\n",
      "18819/18819 [==============================] - 1s 58us/step - loss: 1.0027 - acc: 0.5121\n",
      "Epoch 83/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0018 - acc: 0.5121\n",
      "Epoch 84/500\n",
      "18819/18819 [==============================] - 1s 58us/step - loss: 1.0005 - acc: 0.5121\n",
      "Epoch 85/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0026 - acc: 0.5121\n",
      "Epoch 86/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0000 - acc: 0.5121\n",
      "Epoch 87/500\n",
      "18819/18819 [==============================] - 1s 58us/step - loss: 1.0009 - acc: 0.5121\n",
      "Epoch 88/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0012 - acc: 0.5121\n",
      "Epoch 89/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0018 - acc: 0.5121\n",
      "Epoch 90/500\n",
      "18819/18819 [==============================] - 1s 67us/step - loss: 1.0011 - acc: 0.5121\n",
      "Epoch 91/500\n",
      "18819/18819 [==============================] - 1s 67us/step - loss: 1.0010 - acc: 0.5121\n",
      "Epoch 92/500\n",
      "18819/18819 [==============================] - 1s 69us/step - loss: 1.0023 - acc: 0.5121\n",
      "Epoch 93/500\n",
      "18819/18819 [==============================] - 1s 66us/step - loss: 1.0011 - acc: 0.5121\n",
      "Epoch 94/500\n",
      "18819/18819 [==============================] - 1s 64us/step - loss: 1.0025 - acc: 0.5121\n",
      "Epoch 95/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 1.0007 - acc: 0.5121\n",
      "Epoch 96/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 1.0016 - acc: 0.5121\n",
      "Epoch 97/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0015 - acc: 0.5121\n",
      "Epoch 98/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0012 - acc: 0.5121: 0s - loss: 1\n",
      "Epoch 99/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0011 - acc: 0.5121\n",
      "Epoch 100/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0014 - acc: 0.5121\n",
      "Epoch 101/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0015 - acc: 0.5121\n",
      "Epoch 102/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0031 - acc: 0.5121\n",
      "Epoch 103/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0010 - acc: 0.5121\n",
      "Epoch 104/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0015 - acc: 0.5121\n",
      "Epoch 105/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0013 - acc: 0.5121\n",
      "Epoch 106/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0017 - acc: 0.5121\n",
      "Epoch 107/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0021 - acc: 0.5121\n",
      "Epoch 108/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0013 - acc: 0.5121\n",
      "Epoch 109/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0006 - acc: 0.5121\n",
      "Epoch 110/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0020 - acc: 0.5121\n",
      "Epoch 111/500\n",
      "18819/18819 [==============================] - 1s 64us/step - loss: 1.0004 - acc: 0.5121\n",
      "Epoch 112/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0004 - acc: 0.5121\n",
      "Epoch 113/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0012 - acc: 0.5121\n",
      "Epoch 114/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0017 - acc: 0.5121\n",
      "Epoch 115/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0017 - acc: 0.5121\n",
      "Epoch 116/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0017 - acc: 0.5121\n",
      "Epoch 117/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9991 - acc: 0.5121\n",
      "Epoch 118/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0028 - acc: 0.5121\n",
      "Epoch 119/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0005 - acc: 0.5121\n",
      "Epoch 120/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0013 - acc: 0.5121\n",
      "Epoch 121/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0010 - acc: 0.5121\n",
      "Epoch 122/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9995 - acc: 0.5121\n",
      "Epoch 123/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0012 - acc: 0.5121\n",
      "Epoch 124/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9997 - acc: 0.5121\n",
      "Epoch 125/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0007 - acc: 0.5121\n",
      "Epoch 126/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0017 - acc: 0.5121\n",
      "Epoch 127/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0014 - acc: 0.5121\n",
      "Epoch 128/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0017 - acc: 0.5121\n",
      "Epoch 129/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 1.0019 - acc: 0.5121\n",
      "Epoch 130/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 1.0012 - acc: 0.5121\n",
      "Epoch 131/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0012 - acc: 0.5121\n",
      "Epoch 132/500\n",
      "18819/18819 [==============================] - 1s 65us/step - loss: 0.9995 - acc: 0.5122\n",
      "Epoch 133/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 1.0011 - acc: 0.5119\n",
      "Epoch 134/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 1.0007 - acc: 0.5118\n",
      "Epoch 135/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0010 - acc: 0.5121\n",
      "Epoch 136/500\n",
      "18819/18819 [==============================] - ETA: 0s - loss: 1.0009 - acc: 0.511 - 1s 62us/step - loss: 1.0006 - acc: 0.5117\n",
      "Epoch 137/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0013 - acc: 0.5121\n",
      "Epoch 138/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0012 - acc: 0.5119\n",
      "Epoch 139/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 1.0002 - acc: 0.5118\n",
      "Epoch 140/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9999 - acc: 0.5119\n",
      "Epoch 141/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 1.0003 - acc: 0.5121\n",
      "Epoch 142/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9998 - acc: 0.5121\n",
      "Epoch 143/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0010 - acc: 0.5119\n",
      "Epoch 144/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9991 - acc: 0.5119\n",
      "Epoch 145/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 1.0014 - acc: 0.5121\n",
      "Epoch 146/500\n",
      "18819/18819 [==============================] - 1s 65us/step - loss: 1.0006 - acc: 0.5120\n",
      "Epoch 147/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 1.0000 - acc: 0.5120\n",
      "Epoch 148/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0022 - acc: 0.5121\n",
      "Epoch 149/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0000 - acc: 0.5118\n",
      "Epoch 150/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9999 - acc: 0.5119\n",
      "Epoch 151/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0010 - acc: 0.5123\n",
      "Epoch 152/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0010 - acc: 0.5121\n",
      "Epoch 153/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0002 - acc: 0.5120\n",
      "Epoch 154/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0001 - acc: 0.5120\n",
      "Epoch 155/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 0.9995 - acc: 0.5121\n",
      "Epoch 156/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0010 - acc: 0.5120\n",
      "Epoch 157/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0000 - acc: 0.5119\n",
      "Epoch 158/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0016 - acc: 0.5120\n",
      "Epoch 159/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 0.9999 - acc: 0.5120\n",
      "Epoch 160/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18819/18819 [==============================] - 1s 58us/step - loss: 1.0002 - acc: 0.5121\n",
      "Epoch 161/500\n",
      "18819/18819 [==============================] - 1s 58us/step - loss: 0.9995 - acc: 0.5121\n",
      "Epoch 162/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0007 - acc: 0.5119\n",
      "Epoch 163/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9999 - acc: 0.5120\n",
      "Epoch 164/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0013 - acc: 0.5120\n",
      "Epoch 165/500\n",
      "18819/18819 [==============================] - 1s 58us/step - loss: 1.0001 - acc: 0.5121\n",
      "Epoch 166/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0017 - acc: 0.5121\n",
      "Epoch 167/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0003 - acc: 0.5121\n",
      "Epoch 168/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0010 - acc: 0.5121\n",
      "Epoch 169/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0010 - acc: 0.5121\n",
      "Epoch 170/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0008 - acc: 0.5121\n",
      "Epoch 171/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9993 - acc: 0.5121\n",
      "Epoch 172/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0002 - acc: 0.5123\n",
      "Epoch 173/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0011 - acc: 0.5120\n",
      "Epoch 174/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0008 - acc: 0.5120\n",
      "Epoch 175/500\n",
      "18819/18819 [==============================] - 1s 71us/step - loss: 1.0005 - acc: 0.5120\n",
      "Epoch 176/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0017 - acc: 0.5120\n",
      "Epoch 177/500\n",
      "18819/18819 [==============================] - 1s 58us/step - loss: 0.9999 - acc: 0.5119\n",
      "Epoch 178/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0000 - acc: 0.5120\n",
      "Epoch 179/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0001 - acc: 0.5121\n",
      "Epoch 180/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0001 - acc: 0.5121\n",
      "Epoch 181/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0000 - acc: 0.5121\n",
      "Epoch 182/500\n",
      "18819/18819 [==============================] - 1s 58us/step - loss: 1.0009 - acc: 0.5121\n",
      "Epoch 183/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0002 - acc: 0.5122\n",
      "Epoch 184/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 0.9990 - acc: 0.5121\n",
      "Epoch 185/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0004 - acc: 0.5119\n",
      "Epoch 186/500\n",
      "18819/18819 [==============================] - 1s 58us/step - loss: 1.0000 - acc: 0.5121\n",
      "Epoch 187/500\n",
      "18819/18819 [==============================] - 1s 58us/step - loss: 1.0014 - acc: 0.5121\n",
      "Epoch 188/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9996 - acc: 0.5121\n",
      "Epoch 189/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9996 - acc: 0.5118\n",
      "Epoch 190/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0005 - acc: 0.5118\n",
      "Epoch 191/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 0.9996 - acc: 0.5121\n",
      "Epoch 192/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0006 - acc: 0.5117\n",
      "Epoch 193/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0011 - acc: 0.5121\n",
      "Epoch 194/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0004 - acc: 0.5119\n",
      "Epoch 195/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9994 - acc: 0.5121\n",
      "Epoch 196/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 0.9999 - acc: 0.5119\n",
      "Epoch 197/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 0.9997 - acc: 0.5119\n",
      "Epoch 198/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9986 - acc: 0.5118\n",
      "Epoch 199/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0001 - acc: 0.5119\n",
      "Epoch 200/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9994 - acc: 0.5119\n",
      "Epoch 201/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0002 - acc: 0.5122\n",
      "Epoch 202/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9991 - acc: 0.5118\n",
      "Epoch 203/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0003 - acc: 0.5116\n",
      "Epoch 204/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0002 - acc: 0.5119\n",
      "Epoch 205/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0006 - acc: 0.5119\n",
      "Epoch 206/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9998 - acc: 0.5120\n",
      "Epoch 207/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9997 - acc: 0.5122\n",
      "Epoch 208/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9993 - acc: 0.5120\n",
      "Epoch 209/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9987 - acc: 0.5121\n",
      "Epoch 210/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9999 - acc: 0.5120\n",
      "Epoch 211/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0000 - acc: 0.5120\n",
      "Epoch 212/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0005 - acc: 0.5118\n",
      "Epoch 213/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9987 - acc: 0.5119\n",
      "Epoch 214/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0003 - acc: 0.5119\n",
      "Epoch 215/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 1.0001 - acc: 0.5112\n",
      "Epoch 216/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9999 - acc: 0.5119\n",
      "Epoch 217/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9993 - acc: 0.5117\n",
      "Epoch 218/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0013 - acc: 0.5120\n",
      "Epoch 219/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0003 - acc: 0.5119\n",
      "Epoch 220/500\n",
      "18819/18819 [==============================] - 1s 65us/step - loss: 0.9989 - acc: 0.5120\n",
      "Epoch 221/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9992 - acc: 0.5124\n",
      "Epoch 222/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9996 - acc: 0.5120\n",
      "Epoch 223/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 1.0004 - acc: 0.5118\n",
      "Epoch 224/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9986 - acc: 0.5120\n",
      "Epoch 225/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9999 - acc: 0.5120\n",
      "Epoch 226/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9992 - acc: 0.5121\n",
      "Epoch 227/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 1.0005 - acc: 0.5121\n",
      "Epoch 228/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 0.9986 - acc: 0.5120\n",
      "Epoch 229/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 1.0011 - acc: 0.5120\n",
      "Epoch 230/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9992 - acc: 0.5120\n",
      "Epoch 231/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9995 - acc: 0.5121\n",
      "Epoch 232/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 0.9992 - acc: 0.5119\n",
      "Epoch 233/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9992 - acc: 0.5119\n",
      "Epoch 234/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 1.0001 - acc: 0.5121\n",
      "Epoch 235/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9997 - acc: 0.5120\n",
      "Epoch 236/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9999 - acc: 0.5121\n",
      "Epoch 237/500\n",
      "18819/18819 [==============================] - 1s 64us/step - loss: 1.0008 - acc: 0.5121\n",
      "Epoch 238/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9984 - acc: 0.5119\n",
      "Epoch 239/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18819/18819 [==============================] - 1s 62us/step - loss: 1.0018 - acc: 0.5121\n",
      "Epoch 240/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 0.9995 - acc: 0.5120\n",
      "Epoch 241/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9983 - acc: 0.5120\n",
      "Epoch 242/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9994 - acc: 0.5118\n",
      "Epoch 243/500\n",
      "18819/18819 [==============================] - 1s 65us/step - loss: 1.0010 - acc: 0.5120\n",
      "Epoch 244/500\n",
      "18819/18819 [==============================] - 1s 65us/step - loss: 0.9997 - acc: 0.5120\n",
      "Epoch 245/500\n",
      "18819/18819 [==============================] - 1s 66us/step - loss: 1.0001 - acc: 0.5120\n",
      "Epoch 246/500\n",
      "18819/18819 [==============================] - 1s 64us/step - loss: 1.0010 - acc: 0.5121\n",
      "Epoch 247/500\n",
      "18819/18819 [==============================] - 1s 64us/step - loss: 0.9997 - acc: 0.5121\n",
      "Epoch 248/500\n",
      "18819/18819 [==============================] - 1s 64us/step - loss: 1.0004 - acc: 0.5121\n",
      "Epoch 249/500\n",
      "18819/18819 [==============================] - 1s 66us/step - loss: 0.9995 - acc: 0.5121\n",
      "Epoch 250/500\n",
      "18819/18819 [==============================] - 1s 65us/step - loss: 0.9999 - acc: 0.5119\n",
      "Epoch 251/500\n",
      "18819/18819 [==============================] - 1s 66us/step - loss: 0.9991 - acc: 0.5120\n",
      "Epoch 252/500\n",
      "18819/18819 [==============================] - 1s 64us/step - loss: 0.9995 - acc: 0.5121\n",
      "Epoch 253/500\n",
      "18819/18819 [==============================] - 1s 64us/step - loss: 0.9996 - acc: 0.5120\n",
      "Epoch 254/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0006 - acc: 0.5120\n",
      "Epoch 255/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9984 - acc: 0.5119\n",
      "Epoch 256/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 0.9998 - acc: 0.5118\n",
      "Epoch 257/500\n",
      "18819/18819 [==============================] - 1s 64us/step - loss: 0.9999 - acc: 0.5120\n",
      "Epoch 258/500\n",
      "18819/18819 [==============================] - 1s 64us/step - loss: 0.9990 - acc: 0.5121\n",
      "Epoch 259/500\n",
      "18819/18819 [==============================] - 1s 65us/step - loss: 0.9996 - acc: 0.5118\n",
      "Epoch 260/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9994 - acc: 0.5119\n",
      "Epoch 261/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 0.9984 - acc: 0.5120\n",
      "Epoch 262/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9999 - acc: 0.5117\n",
      "Epoch 263/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9988 - acc: 0.5117\n",
      "Epoch 264/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9981 - acc: 0.5119\n",
      "Epoch 265/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9991 - acc: 0.5124\n",
      "Epoch 266/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9988 - acc: 0.5121\n",
      "Epoch 267/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9989 - acc: 0.5119\n",
      "Epoch 268/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9979 - acc: 0.5121\n",
      "Epoch 269/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9986 - acc: 0.5121\n",
      "Epoch 270/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9994 - acc: 0.5121\n",
      "Epoch 271/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 0.9978 - acc: 0.5119\n",
      "Epoch 272/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9982 - acc: 0.5120\n",
      "Epoch 273/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9985 - acc: 0.5119\n",
      "Epoch 274/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0008 - acc: 0.5119\n",
      "Epoch 275/500\n",
      "18819/18819 [==============================] - 1s 64us/step - loss: 0.9982 - acc: 0.5121\n",
      "Epoch 276/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 1.0006 - acc: 0.5120\n",
      "Epoch 277/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9999 - acc: 0.5120\n",
      "Epoch 278/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9988 - acc: 0.5121\n",
      "Epoch 279/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 0.9974 - acc: 0.5120\n",
      "Epoch 280/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 0.9988 - acc: 0.5122\n",
      "Epoch 281/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9986 - acc: 0.5119\n",
      "Epoch 282/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9982 - acc: 0.5121\n",
      "Epoch 283/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 1.0004 - acc: 0.5119\n",
      "Epoch 284/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9980 - acc: 0.5121\n",
      "Epoch 285/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9976 - acc: 0.5119\n",
      "Epoch 286/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0001 - acc: 0.5119\n",
      "Epoch 287/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9989 - acc: 0.5117\n",
      "Epoch 288/500\n",
      "18819/18819 [==============================] - 1s 64us/step - loss: 0.9970 - acc: 0.5120\n",
      "Epoch 289/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9979 - acc: 0.5119\n",
      "Epoch 290/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 1.0001 - acc: 0.5118: 0s - loss:\n",
      "Epoch 291/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9985 - acc: 0.5120\n",
      "Epoch 292/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 0.9996 - acc: 0.5121\n",
      "Epoch 293/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 0.9991 - acc: 0.5121\n",
      "Epoch 294/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 0.9987 - acc: 0.5120\n",
      "Epoch 295/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9987 - acc: 0.5119\n",
      "Epoch 296/500\n",
      "18819/18819 [==============================] - 1s 64us/step - loss: 0.9989 - acc: 0.5119\n",
      "Epoch 297/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 0.9994 - acc: 0.5122\n",
      "Epoch 298/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9983 - acc: 0.5120\n",
      "Epoch 299/500\n",
      "18819/18819 [==============================] - 1s 64us/step - loss: 0.9993 - acc: 0.5120\n",
      "Epoch 300/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 0.9987 - acc: 0.5120\n",
      "Epoch 301/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9976 - acc: 0.5119\n",
      "Epoch 302/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 0.9989 - acc: 0.5119\n",
      "Epoch 303/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9988 - acc: 0.5120\n",
      "Epoch 304/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9991 - acc: 0.5121\n",
      "Epoch 305/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9993 - acc: 0.5120\n",
      "Epoch 306/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9995 - acc: 0.5119\n",
      "Epoch 307/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9984 - acc: 0.5122\n",
      "Epoch 308/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9994 - acc: 0.5121\n",
      "Epoch 309/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9989 - acc: 0.5118\n",
      "Epoch 310/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 0.9989 - acc: 0.5121\n",
      "Epoch 311/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9991 - acc: 0.5120\n",
      "Epoch 312/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9985 - acc: 0.5120\n",
      "Epoch 313/500\n",
      "18819/18819 [==============================] - 1s 64us/step - loss: 0.9985 - acc: 0.5120\n",
      "Epoch 314/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9986 - acc: 0.5118\n",
      "Epoch 315/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9998 - acc: 0.5121\n",
      "Epoch 316/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9985 - acc: 0.5119\n",
      "Epoch 317/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9982 - acc: 0.5120\n",
      "Epoch 318/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18819/18819 [==============================] - 1s 59us/step - loss: 0.9988 - acc: 0.5121\n",
      "Epoch 319/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9982 - acc: 0.5121\n",
      "Epoch 320/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 0.9983 - acc: 0.5121\n",
      "Epoch 321/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 0.9989 - acc: 0.5121\n",
      "Epoch 322/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 0.9986 - acc: 0.5118\n",
      "Epoch 323/500\n",
      "18819/18819 [==============================] - 1s 64us/step - loss: 0.9979 - acc: 0.5120\n",
      "Epoch 324/500\n",
      "18819/18819 [==============================] - 1s 70us/step - loss: 0.9982 - acc: 0.5119\n",
      "Epoch 325/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 0.9976 - acc: 0.5121\n",
      "Epoch 326/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 1.0006 - acc: 0.5120\n",
      "Epoch 327/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9998 - acc: 0.5118\n",
      "Epoch 328/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9980 - acc: 0.5121\n",
      "Epoch 329/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9979 - acc: 0.5121\n",
      "Epoch 330/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9993 - acc: 0.5120\n",
      "Epoch 331/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 0.9980 - acc: 0.5120\n",
      "Epoch 332/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9985 - acc: 0.5116\n",
      "Epoch 333/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9995 - acc: 0.5120\n",
      "Epoch 334/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9970 - acc: 0.5123\n",
      "Epoch 335/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9987 - acc: 0.5118\n",
      "Epoch 336/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9980 - acc: 0.5119\n",
      "Epoch 337/500\n",
      "18819/18819 [==============================] - 1s 64us/step - loss: 0.9987 - acc: 0.5120\n",
      "Epoch 338/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9976 - acc: 0.5124\n",
      "Epoch 339/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9981 - acc: 0.5119\n",
      "Epoch 340/500\n",
      "18819/18819 [==============================] - 1s 66us/step - loss: 0.9992 - acc: 0.5121\n",
      "Epoch 341/500\n",
      "18819/18819 [==============================] - 1s 64us/step - loss: 0.9982 - acc: 0.5121\n",
      "Epoch 342/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9985 - acc: 0.5121\n",
      "Epoch 343/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9994 - acc: 0.5121\n",
      "Epoch 344/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9997 - acc: 0.5121\n",
      "Epoch 345/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9990 - acc: 0.5120\n",
      "Epoch 346/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9981 - acc: 0.5121\n",
      "Epoch 347/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9987 - acc: 0.5120\n",
      "Epoch 348/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 0.9992 - acc: 0.5121\n",
      "Epoch 349/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 0.9993 - acc: 0.5121\n",
      "Epoch 350/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9983 - acc: 0.5122\n",
      "Epoch 351/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9983 - acc: 0.5119\n",
      "Epoch 352/500\n",
      "18819/18819 [==============================] - 1s 64us/step - loss: 0.9975 - acc: 0.5120\n",
      "Epoch 353/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9991 - acc: 0.5120\n",
      "Epoch 354/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9974 - acc: 0.5121\n",
      "Epoch 355/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9974 - acc: 0.5122\n",
      "Epoch 356/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9990 - acc: 0.5114\n",
      "Epoch 357/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 0.9973 - acc: 0.5122\n",
      "Epoch 358/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9973 - acc: 0.5122\n",
      "Epoch 359/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9981 - acc: 0.5120\n",
      "Epoch 360/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9994 - acc: 0.5122\n",
      "Epoch 361/500\n",
      "18819/18819 [==============================] - 1s 64us/step - loss: 0.9982 - acc: 0.5120\n",
      "Epoch 362/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9994 - acc: 0.5120\n",
      "Epoch 363/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9982 - acc: 0.5120\n",
      "Epoch 364/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9975 - acc: 0.5120\n",
      "Epoch 365/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9977 - acc: 0.5120\n",
      "Epoch 366/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 0.9971 - acc: 0.5121\n",
      "Epoch 367/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9975 - acc: 0.5121\n",
      "Epoch 368/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9963 - acc: 0.5119\n",
      "Epoch 369/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9969 - acc: 0.5121\n",
      "Epoch 370/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9990 - acc: 0.5119\n",
      "Epoch 371/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9991 - acc: 0.5121\n",
      "Epoch 372/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9982 - acc: 0.5121\n",
      "Epoch 373/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9992 - acc: 0.5121\n",
      "Epoch 374/500\n",
      "18819/18819 [==============================] - 1s 67us/step - loss: 0.9973 - acc: 0.5126\n",
      "Epoch 375/500\n",
      "18819/18819 [==============================] - 1s 67us/step - loss: 0.9980 - acc: 0.5115\n",
      "Epoch 376/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9976 - acc: 0.5121\n",
      "Epoch 377/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9973 - acc: 0.5119\n",
      "Epoch 378/500\n",
      "18819/18819 [==============================] - 1s 65us/step - loss: 0.9979 - acc: 0.5125\n",
      "Epoch 379/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9982 - acc: 0.5119\n",
      "Epoch 380/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 0.9964 - acc: 0.5122\n",
      "Epoch 381/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9980 - acc: 0.5119\n",
      "Epoch 382/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 0.9988 - acc: 0.5119\n",
      "Epoch 383/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9988 - acc: 0.5119\n",
      "Epoch 384/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9969 - acc: 0.5120\n",
      "Epoch 385/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 0.9974 - acc: 0.5118\n",
      "Epoch 386/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 0.9973 - acc: 0.5120\n",
      "Epoch 387/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9990 - acc: 0.5122\n",
      "Epoch 388/500\n",
      "18819/18819 [==============================] - 1s 64us/step - loss: 0.9981 - acc: 0.5120\n",
      "Epoch 389/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9981 - acc: 0.5121\n",
      "Epoch 390/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9971 - acc: 0.5121\n",
      "Epoch 391/500\n",
      "18819/18819 [==============================] - 1s 68us/step - loss: 0.9971 - acc: 0.5121\n",
      "Epoch 392/500\n",
      "18819/18819 [==============================] - 2s 120us/step - loss: 0.9995 - acc: 0.5115\n",
      "Epoch 393/500\n",
      "18819/18819 [==============================] - 2s 81us/step - loss: 0.9976 - acc: 0.5121\n",
      "Epoch 394/500\n",
      "18819/18819 [==============================] - 1s 67us/step - loss: 0.9967 - acc: 0.5121\n",
      "Epoch 395/500\n",
      "18819/18819 [==============================] - 2s 84us/step - loss: 0.9991 - acc: 0.5122\n",
      "Epoch 396/500\n",
      "18819/18819 [==============================] - 1s 72us/step - loss: 0.9993 - acc: 0.5122\n",
      "Epoch 397/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18819/18819 [==============================] - 1s 73us/step - loss: 0.9986 - acc: 0.5121\n",
      "Epoch 398/500\n",
      "18819/18819 [==============================] - 1s 70us/step - loss: 0.9991 - acc: 0.5120\n",
      "Epoch 399/500\n",
      "18819/18819 [==============================] - 1s 65us/step - loss: 0.9983 - acc: 0.5121\n",
      "Epoch 400/500\n",
      "18819/18819 [==============================] - 1s 64us/step - loss: 0.9989 - acc: 0.5121\n",
      "Epoch 401/500\n",
      "18819/18819 [==============================] - 1s 65us/step - loss: 0.9980 - acc: 0.5121\n",
      "Epoch 402/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9983 - acc: 0.5120\n",
      "Epoch 403/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 0.9978 - acc: 0.5121\n",
      "Epoch 404/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9956 - acc: 0.5121\n",
      "Epoch 405/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 0.9977 - acc: 0.5121\n",
      "Epoch 406/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9987 - acc: 0.5120\n",
      "Epoch 407/500\n",
      "18819/18819 [==============================] - 1s 64us/step - loss: 0.9969 - acc: 0.5121\n",
      "Epoch 408/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 0.9967 - acc: 0.5121\n",
      "Epoch 409/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9975 - acc: 0.5121\n",
      "Epoch 410/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9970 - acc: 0.5121\n",
      "Epoch 411/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9985 - acc: 0.5121\n",
      "Epoch 412/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 0.9962 - acc: 0.5120\n",
      "Epoch 413/500\n",
      "18819/18819 [==============================] - 1s 62us/step - loss: 0.9986 - acc: 0.5121\n",
      "Epoch 414/500\n",
      "18819/18819 [==============================] - 1s 67us/step - loss: 0.9983 - acc: 0.5121\n",
      "Epoch 415/500\n",
      "18819/18819 [==============================] - 1s 68us/step - loss: 0.9974 - acc: 0.5120\n",
      "Epoch 416/500\n",
      "18819/18819 [==============================] - 1s 68us/step - loss: 0.9978 - acc: 0.5120\n",
      "Epoch 417/500\n",
      "18819/18819 [==============================] - 1s 70us/step - loss: 0.9972 - acc: 0.5121\n",
      "Epoch 418/500\n",
      "18819/18819 [==============================] - 1s 65us/step - loss: 0.9971 - acc: 0.5121\n",
      "Epoch 419/500\n",
      "18819/18819 [==============================] - 1s 70us/step - loss: 0.9968 - acc: 0.5121\n",
      "Epoch 420/500\n",
      "18819/18819 [==============================] - 1s 67us/step - loss: 0.9981 - acc: 0.5121\n",
      "Epoch 421/500\n",
      "18819/18819 [==============================] - 1s 64us/step - loss: 0.9983 - acc: 0.5121\n",
      "Epoch 422/500\n",
      "18819/18819 [==============================] - 1s 75us/step - loss: 0.9971 - acc: 0.5122\n",
      "Epoch 423/500\n",
      "18819/18819 [==============================] - 1s 73us/step - loss: 0.9991 - acc: 0.5120\n",
      "Epoch 424/500\n",
      "18819/18819 [==============================] - 1s 66us/step - loss: 0.9958 - acc: 0.5118\n",
      "Epoch 425/500\n",
      "18819/18819 [==============================] - 1s 65us/step - loss: 0.9963 - acc: 0.5117\n",
      "Epoch 426/500\n",
      "18819/18819 [==============================] - 1s 75us/step - loss: 0.9976 - acc: 0.5119\n",
      "Epoch 427/500\n",
      "18819/18819 [==============================] - 1s 73us/step - loss: 0.9968 - acc: 0.5120\n",
      "Epoch 428/500\n",
      "18819/18819 [==============================] - 1s 73us/step - loss: 0.9980 - acc: 0.5120\n",
      "Epoch 429/500\n",
      "18819/18819 [==============================] - 1s 74us/step - loss: 0.9973 - acc: 0.5120\n",
      "Epoch 430/500\n",
      "18819/18819 [==============================] - 1s 67us/step - loss: 0.9968 - acc: 0.5121\n",
      "Epoch 431/500\n",
      "18819/18819 [==============================] - 1s 69us/step - loss: 0.9969 - acc: 0.5121\n",
      "Epoch 432/500\n",
      "18819/18819 [==============================] - 1s 64us/step - loss: 0.9962 - acc: 0.5121\n",
      "Epoch 433/500\n",
      "18819/18819 [==============================] - 1s 65us/step - loss: 0.9965 - acc: 0.5121\n",
      "Epoch 434/500\n",
      "18819/18819 [==============================] - 1s 68us/step - loss: 0.9970 - acc: 0.5121\n",
      "Epoch 435/500\n",
      "18819/18819 [==============================] - 1s 73us/step - loss: 0.9962 - acc: 0.5121\n",
      "Epoch 436/500\n",
      "18819/18819 [==============================] - 1s 70us/step - loss: 0.9977 - acc: 0.5121\n",
      "Epoch 437/500\n",
      "18819/18819 [==============================] - 1s 77us/step - loss: 0.9976 - acc: 0.5121: 1s \n",
      "Epoch 438/500\n",
      "18819/18819 [==============================] - 2s 92us/step - loss: 0.9972 - acc: 0.5118\n",
      "Epoch 439/500\n",
      "18819/18819 [==============================] - 1s 69us/step - loss: 0.9961 - acc: 0.5119\n",
      "Epoch 440/500\n",
      "18819/18819 [==============================] - 2s 90us/step - loss: 0.9977 - acc: 0.5121\n",
      "Epoch 441/500\n",
      "18819/18819 [==============================] - 2s 101us/step - loss: 0.9963 - acc: 0.5121\n",
      "Epoch 442/500\n",
      "18819/18819 [==============================] - 2s 90us/step - loss: 0.9974 - acc: 0.5121\n",
      "Epoch 443/500\n",
      "18819/18819 [==============================] - 2s 114us/step - loss: 0.9979 - acc: 0.5121\n",
      "Epoch 444/500\n",
      "18819/18819 [==============================] - 2s 130us/step - loss: 0.9977 - acc: 0.5121 1s -\n",
      "Epoch 445/500\n",
      "18819/18819 [==============================] - 1s 78us/step - loss: 0.9966 - acc: 0.5124\n",
      "Epoch 446/500\n",
      "18819/18819 [==============================] - 1s 66us/step - loss: 0.9975 - acc: 0.5120\n",
      "Epoch 447/500\n",
      "18819/18819 [==============================] - 1s 65us/step - loss: 0.9981 - acc: 0.5121\n",
      "Epoch 448/500\n",
      "18819/18819 [==============================] - 1s 66us/step - loss: 0.9974 - acc: 0.5121\n",
      "Epoch 449/500\n",
      "18819/18819 [==============================] - 1s 68us/step - loss: 0.9964 - acc: 0.5121\n",
      "Epoch 450/500\n",
      "18819/18819 [==============================] - 1s 70us/step - loss: 0.9983 - acc: 0.5121\n",
      "Epoch 451/500\n",
      "18819/18819 [==============================] - 1s 68us/step - loss: 0.9976 - acc: 0.5121\n",
      "Epoch 452/500\n",
      "18819/18819 [==============================] - 1s 69us/step - loss: 0.9971 - acc: 0.5121\n",
      "Epoch 453/500\n",
      "18819/18819 [==============================] - 1s 66us/step - loss: 0.9974 - acc: 0.5121\n",
      "Epoch 454/500\n",
      "18819/18819 [==============================] - 1s 68us/step - loss: 0.9968 - acc: 0.5121\n",
      "Epoch 455/500\n",
      "18819/18819 [==============================] - 1s 67us/step - loss: 0.9984 - acc: 0.5121\n",
      "Epoch 456/500\n",
      "18819/18819 [==============================] - 1s 66us/step - loss: 0.9967 - acc: 0.5121\n",
      "Epoch 457/500\n",
      "18819/18819 [==============================] - 1s 66us/step - loss: 0.9972 - acc: 0.5121\n",
      "Epoch 458/500\n",
      "18819/18819 [==============================] - 1s 67us/step - loss: 0.9969 - acc: 0.5121\n",
      "Epoch 459/500\n",
      "18819/18819 [==============================] - 1s 68us/step - loss: 0.9956 - acc: 0.5120\n",
      "Epoch 460/500\n",
      "18819/18819 [==============================] - 1s 68us/step - loss: 0.9961 - acc: 0.5121\n",
      "Epoch 461/500\n",
      "18819/18819 [==============================] - 1s 66us/step - loss: 0.9961 - acc: 0.5121\n",
      "Epoch 462/500\n",
      "18819/18819 [==============================] - 1s 66us/step - loss: 0.9967 - acc: 0.5118\n",
      "Epoch 463/500\n",
      "18819/18819 [==============================] - 1s 66us/step - loss: 0.9971 - acc: 0.5120\n",
      "Epoch 464/500\n",
      "18819/18819 [==============================] - 1s 66us/step - loss: 0.9956 - acc: 0.5118\n",
      "Epoch 465/500\n",
      "18819/18819 [==============================] - 1s 67us/step - loss: 0.9978 - acc: 0.5121\n",
      "Epoch 466/500\n",
      "18819/18819 [==============================] - 1s 65us/step - loss: 0.9979 - acc: 0.5121\n",
      "Epoch 467/500\n",
      "18819/18819 [==============================] - 1s 67us/step - loss: 0.9980 - acc: 0.5121\n",
      "Epoch 468/500\n",
      "18819/18819 [==============================] - 1s 68us/step - loss: 0.9980 - acc: 0.5120\n",
      "Epoch 469/500\n",
      "18819/18819 [==============================] - 1s 69us/step - loss: 0.9971 - acc: 0.5118\n",
      "Epoch 470/500\n",
      "18819/18819 [==============================] - 1s 66us/step - loss: 0.9976 - acc: 0.5118\n",
      "Epoch 471/500\n",
      "18819/18819 [==============================] - 1s 67us/step - loss: 0.9971 - acc: 0.5120\n",
      "Epoch 472/500\n",
      "18819/18819 [==============================] - 1s 65us/step - loss: 0.9980 - acc: 0.5121\n",
      "Epoch 473/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9972 - acc: 0.5121\n",
      "Epoch 474/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9973 - acc: 0.5120\n",
      "Epoch 475/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 0.9954 - acc: 0.5120\n",
      "Epoch 476/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18819/18819 [==============================] - 1s 59us/step - loss: 0.9970 - acc: 0.5118\n",
      "Epoch 477/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9958 - acc: 0.5121\n",
      "Epoch 478/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9964 - acc: 0.5120\n",
      "Epoch 479/500\n",
      "18819/18819 [==============================] - 1s 58us/step - loss: 0.9965 - acc: 0.5121\n",
      "Epoch 480/500\n",
      "18819/18819 [==============================] - 1s 58us/step - loss: 0.9966 - acc: 0.5118\n",
      "Epoch 481/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 0.9971 - acc: 0.5121\n",
      "Epoch 482/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9973 - acc: 0.5121: 0s - loss: 1.0053 -\n",
      "Epoch 483/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9958 - acc: 0.5121\n",
      "Epoch 484/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9948 - acc: 0.5120\n",
      "Epoch 485/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 0.9959 - acc: 0.5121\n",
      "Epoch 486/500\n",
      "18819/18819 [==============================] - 1s 58us/step - loss: 0.9974 - acc: 0.5121\n",
      "Epoch 487/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 0.9960 - acc: 0.5121\n",
      "Epoch 488/500\n",
      "18819/18819 [==============================] - 1s 58us/step - loss: 0.9971 - acc: 0.5121\n",
      "Epoch 489/500\n",
      "18819/18819 [==============================] - 1s 58us/step - loss: 0.9970 - acc: 0.5121\n",
      "Epoch 490/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 0.9974 - acc: 0.5121\n",
      "Epoch 491/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 0.9962 - acc: 0.5121\n",
      "Epoch 492/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9968 - acc: 0.5120\n",
      "Epoch 493/500\n",
      "18819/18819 [==============================] - 1s 60us/step - loss: 0.9961 - acc: 0.5121\n",
      "Epoch 494/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 0.9966 - acc: 0.5121\n",
      "Epoch 495/500\n",
      "18819/18819 [==============================] - 1s 61us/step - loss: 0.9962 - acc: 0.5121\n",
      "Epoch 496/500\n",
      "18819/18819 [==============================] - 1s 59us/step - loss: 0.9979 - acc: 0.5121\n",
      "Epoch 497/500\n",
      "18819/18819 [==============================] - 1s 63us/step - loss: 0.9973 - acc: 0.5120\n",
      "Epoch 498/500\n",
      "18819/18819 [==============================] - 1s 58us/step - loss: 0.9968 - acc: 0.5120\n",
      "Epoch 499/500\n",
      "18819/18819 [==============================] - 1s 70us/step - loss: 0.9976 - acc: 0.5121\n",
      "Epoch 500/500\n",
      "18819/18819 [==============================] - 1s 55us/step - loss: 0.9966 - acc: 0.5120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2c0adcf8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_snn,y_train_snn, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6274/6274 [==============================] - 0s 49us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9959419040038474, 0.503984698756774]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_snn, y_test_snn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "inp = model.input                                           # input placeholder\n",
    "outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
    "functor = K.function([inp, K.learning_phase()], outputs ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_outs_train = functor([x_train_snn, 1.])\n",
    "layer_outs_test = functor([x_test_snn, 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:2831: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.mean(atmp[sl], axis=axis)\n",
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:2831: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.mean(atmp[sl], axis=axis)\n"
     ]
    }
   ],
   "source": [
    "x_train_flat_snn = np.asarray(layer_outs_train[4]).reshape(-1,10)\n",
    "x_test_flat_snn = np.asarray(layer_outs_test[4]).reshape(-1,10)\n",
    "\n",
    "tsne = TSNE()\n",
    "train_tsne_embeds_snn = tsne.fit_transform(x_train_flat_snn[:1000])\n",
    "scatter(train_tsne_embeds_snn, y_train_snn[:1000], \"Samples from Training Data LINCS (Triplet) after\")\n",
    "\n",
    "eval_tsne_embeds_snn = tsne.fit_transform(x_test_flat_snn[:1000])\n",
    "scatter(eval_tsne_embeds_snn, y_test_snn[:1000], \"Samples from Validation Data LINCS (Triplet) after\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
