{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import sys\n",
    "import matplotlib.pyplot as plt1 \n",
    "import numpy as np\n",
    "from IPython.display import Audio, display\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Conv2D, Lambda, Dense, Flatten,MaxPooling2D, concatenate, Conv1D,Conv2D, Flatten, Reshape, Embedding, GRU, SpatialDropout1D, LSTM, Dropout, BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "from itertools import permutations\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "from scipy.stats import trim_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def done():\n",
    "    framerate = 44100\n",
    "    duration=0.6\n",
    "    freq=300\n",
    "    t = np.linspace(0,duration,framerate*duration)\n",
    "    data = np.sin(2*np.pi*freq*t)\n",
    "    display(Audio(data, rate=framerate, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>inchi_key</th>\n",
       "      <th>atc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>NC12CC3CC(CC(C3)C1)C2</td>\n",
       "      <td>amantadine</td>\n",
       "      <td>BRD-K70330367</td>\n",
       "      <td>DKNWSYNQZKUICI-UHFFFAOYSA-N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>CS(=O)(=O)OCCCCOS(C)(=O)=O</td>\n",
       "      <td>busulfan</td>\n",
       "      <td>BRD-K23204545</td>\n",
       "      <td>COVZYZSDYWQREU-UHFFFAOYSA-N</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>CCCC(C)(COC(N)=O)COC(=O)NC(C)C</td>\n",
       "      <td>carisoprodol</td>\n",
       "      <td>BRD-A99939097</td>\n",
       "      <td>OFZCIYFFPZCNJE-UHFFFAOYSA-N</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>CCN(CC)C(=O)N1CCN(C)CC1</td>\n",
       "      <td>diethylcarbamazine</td>\n",
       "      <td>BRD-K45542189</td>\n",
       "      <td>RCKMWOKWVGPNJF-UHFFFAOYSA-N</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>CCN(CC)C(=S)SSC(=S)N(CC)CC</td>\n",
       "      <td>disulfiram</td>\n",
       "      <td>BRD-K32744045</td>\n",
       "      <td>AUZONCFQVSMFAP-UHFFFAOYSA-N</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             smiles                name             id  \\\n",
       "75            NC12CC3CC(CC(C3)C1)C2          amantadine  BRD-K70330367   \n",
       "291      CS(=O)(=O)OCCCCOS(C)(=O)=O            busulfan  BRD-K23204545   \n",
       "322  CCCC(C)(COC(N)=O)COC(=O)NC(C)C        carisoprodol  BRD-A99939097   \n",
       "491         CCN(CC)C(=O)N1CCN(C)CC1  diethylcarbamazine  BRD-K45542189   \n",
       "510      CCN(CC)C(=S)SSC(=S)N(CC)CC          disulfiram  BRD-K32744045   \n",
       "\n",
       "                       inchi_key atc  \n",
       "75   DKNWSYNQZKUICI-UHFFFAOYSA-N   N  \n",
       "291  COVZYZSDYWQREU-UHFFFAOYSA-N   L  \n",
       "322  OFZCIYFFPZCNJE-UHFFFAOYSA-N   M  \n",
       "491  RCKMWOKWVGPNJF-UHFFFAOYSA-N   P  \n",
       "510  AUZONCFQVSMFAP-UHFFFAOYSA-N   P  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full = pd.read_csv(\"../data/drug_class_identification/all3.csv\")\n",
    "full = full.dropna()\n",
    "full['atc'] = full['atc'].apply(lambda x : x[0])\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = full[\"smiles\"]\n",
    "y = full['atc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVocabulary(sample):\n",
    "    vocabulary = set()\n",
    "    for word in sample:\n",
    "        for character in word:\n",
    "            vocabulary.add(character)\n",
    "    return (vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = getVocabulary(X)\n",
    "token_index = dict(zip(characters, range(1, len(characters) + 1)))\n",
    "\n",
    "samples = X.tolist()\n",
    "max_length = 70\n",
    "results = np.zeros((len(samples), max_length, max(token_index.values()) + 1))\n",
    "for i, sample in enumerate(samples):\n",
    "    for j, character in enumerate(sample[:max_length]):\n",
    "        index = token_index.get(character)\n",
    "        results[i, j, index] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1004, 70, 31)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.asarray(results)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define our own plot function\n",
    "def scatter(x, y, subtitle=None):\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(y)\n",
    "\n",
    "    # We choose a color palette with seaborn.\n",
    "    palette = np.array(sns.color_palette(\"hls\", 14))\n",
    "\n",
    "    # We create a scatter plot.\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40,\n",
    "                    c=palette[labels.astype(np.int)])\n",
    "    plt.xlim(-25, 25)\n",
    "    plt.ylim(-25, 25)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "\n",
    "    # We add the labels for each digit.\n",
    "    txts = []\n",
    "    for i in range(14):\n",
    "        # Position of each label.\n",
    "        xtext, ytext = trim_mean(x[labels == i, :], axis=0, proportiontocut=0.2)\n",
    "        letter = le.inverse_transform([i])[0]\n",
    "        txt = ax.text(xtext, ytext, str(letter), fontsize=24)\n",
    "        txt.set_path_effects([\n",
    "            PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "            PathEffects.Normal()])\n",
    "        txts.append(txt)\n",
    "        \n",
    "    if subtitle != None:\n",
    "        plt.suptitle(subtitle)\n",
    "        \n",
    "    plt.savefig(subtitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:2831: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.mean(atmp[sl], axis=axis)\n",
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:2831: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.mean(atmp[sl], axis=axis)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test,y_train,y_test = train_test_split(X,y)\n",
    "\n",
    "x_train_flat = x_train.reshape(-1,70*31)\n",
    "x_test_flat = x_test.reshape(-1,70*31)\n",
    "\n",
    "tsne = TSNE()\n",
    "train_tsne_embeds = tsne.fit_transform(x_train_flat[:512])\n",
    "scatter(train_tsne_embeds, y_train[:512], \"Samples from Training Data\")\n",
    "\n",
    "eval_tsne_embeds = tsne.fit_transform(x_test_flat[:512])\n",
    "scatter(eval_tsne_embeds, y_test[:512], \"Samples from Validation Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred.shape =  Tensor(\"merged_layer/concat:0\", shape=(?, 42), dtype=float32)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor_input (InputLayer)       (None, 70, 31, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_input (InputLayer)     (None, 70, 31, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_input (InputLayer)     (None, 70, 31, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 14)           43004       anchor_input[0][0]               \n",
      "                                                                 positive_input[0][0]             \n",
      "                                                                 negative_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "merged_layer (Concatenate)      (None, 42)           0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "                                                                 sequential_1[3][0]               \n",
      "==================================================================================================\n",
      "Total params: 43,004\n",
      "Trainable params: 42,964\n",
      "Non-trainable params: 40\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.4):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss function\n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor data\n",
    "            positive -- the encodings for the positive data (similar to anchor)\n",
    "            negative -- the encodings for the negative data (different from anchor)\n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    print('y_pred.shape = ',y_pred)\n",
    "    \n",
    "    total_lenght = y_pred.shape.as_list()[-1]\n",
    "#     print('total_lenght=',  total_lenght)\n",
    "#     total_lenght =12\n",
    "    \n",
    "    anchor = y_pred[:,0:int(total_lenght*1/3)]\n",
    "    positive = y_pred[:,int(total_lenght*1/3):int(total_lenght*2/3)]\n",
    "    negative = y_pred[:,int(total_lenght*2/3):int(total_lenght*3/3)]\n",
    "\n",
    "    # distance between the anchor and the positive\n",
    "    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n",
    "\n",
    "    # distance between the anchor and the negative\n",
    "    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n",
    "\n",
    "    # compute loss\n",
    "    basic_loss = pos_dist-neg_dist+alpha\n",
    "    loss = K.maximum(basic_loss,0.0)\n",
    " \n",
    "    return loss\n",
    "\n",
    "def baseNetwork():    \n",
    "        model = Sequential()\n",
    "        model.add(Reshape((70, 31), input_shape=(1004,None, None)))\n",
    "        model.add(Conv1D(20,10,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv1D(20,5,activation='relu'))\n",
    "        model.add(Conv1D(20,3,activation='relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(30, activation='relu'))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(14, activation='softmax'))\n",
    "        return model\n",
    "    \n",
    "anchor_input = Input((70,31,1, ), name='anchor_input')\n",
    "positive_input = Input((70,31,1, ), name='positive_input')\n",
    "negative_input = Input((70,31,1, ), name='negative_input')\n",
    "\n",
    "# Shared embedding layer for positive and negative items\n",
    "Shared_DNN = baseNetwork()\n",
    "\n",
    "\n",
    "encoded_anchor = Shared_DNN(anchor_input)\n",
    "encoded_positive = Shared_DNN(positive_input)\n",
    "encoded_negative = Shared_DNN(negative_input)\n",
    "\n",
    "\n",
    "merged_vector = concatenate([encoded_anchor, encoded_positive, encoded_negative], axis=-1, name='merged_layer')\n",
    "\n",
    "model = Model(inputs=[anchor_input,positive_input, negative_input], outputs=merged_vector)\n",
    "model.compile(loss=triplet_loss, optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTriplet(x,y,testsize=0.2,ap_pairs=10,an_pairs=10):\n",
    "    data_xy = tuple([x,y])\n",
    "\n",
    "    trainsize = 1-testsize\n",
    "\n",
    "    triplet_train_pairs = []\n",
    "    triplet_test_pairs = []\n",
    "    for data_class in sorted(set(data_xy[1])):\n",
    "\n",
    "        same_class_idx = np.where((data_xy[1] == data_class))[0]\n",
    "        diff_class_idx = np.where(data_xy[1] != data_class)[0]\n",
    "        A_P_pairs = random.sample(list(permutations(same_class_idx,2)),k=ap_pairs) #Generating Anchor-Positive pairs\n",
    "        Neg_idx = random.sample(list(diff_class_idx),k=an_pairs)\n",
    "        \n",
    "\n",
    "        #train\n",
    "        A_P_len = len(A_P_pairs)\n",
    "        Neg_len = len(Neg_idx)\n",
    "        for ap in A_P_pairs[:int(A_P_len*trainsize)]:\n",
    "            Anchor = data_xy[0][ap[0]]\n",
    "            Positive = data_xy[0][ap[1]]\n",
    "            for n in Neg_idx:\n",
    "                Negative = data_xy[0][n]\n",
    "                triplet_train_pairs.append([Anchor,Positive,Negative])               \n",
    "        #test\n",
    "        for ap in A_P_pairs[int(A_P_len*trainsize):]:\n",
    "            Anchor = data_xy[0][ap[0]]\n",
    "            Positive = data_xy[0][ap[1]]\n",
    "            for n in Neg_idx:\n",
    "                Negative = data_xy[0][n]\n",
    "                triplet_test_pairs.append([Anchor,Positive,Negative])    \n",
    "                \n",
    "    return np.array(triplet_train_pairs), np.array(triplet_test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = generateTriplet(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1120 samples, validate on 280 samples\n",
      "Epoch 1/50\n",
      "1120/1120 [==============================] - 3s 2ms/step - loss: 0.3516 - val_loss: 0.3161\n",
      "Epoch 2/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.2474 - val_loss: 0.2687\n",
      "Epoch 3/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.1883 - val_loss: 0.2377\n",
      "Epoch 4/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.1396 - val_loss: 0.2257\n",
      "Epoch 5/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.1131 - val_loss: 0.2543\n",
      "Epoch 6/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0965 - val_loss: 0.2343\n",
      "Epoch 7/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0833 - val_loss: 0.2153\n",
      "Epoch 8/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0761 - val_loss: 0.2300\n",
      "Epoch 9/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0666 - val_loss: 0.2336\n",
      "Epoch 10/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0646 - val_loss: 0.2034\n",
      "Epoch 11/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0572 - val_loss: 0.2617\n",
      "Epoch 12/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0501 - val_loss: 0.2290\n",
      "Epoch 13/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0455 - val_loss: 0.2277\n",
      "Epoch 14/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0393 - val_loss: 0.2517\n",
      "Epoch 15/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0420 - val_loss: 0.2245\n",
      "Epoch 16/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0389 - val_loss: 0.2628\n",
      "Epoch 17/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0372 - val_loss: 0.2334\n",
      "Epoch 18/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0321 - val_loss: 0.2585\n",
      "Epoch 19/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0333 - val_loss: 0.2520\n",
      "Epoch 20/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0300 - val_loss: 0.2567\n",
      "Epoch 21/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0325 - val_loss: 0.2361\n",
      "Epoch 22/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0294 - val_loss: 0.2499\n",
      "Epoch 23/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0285 - val_loss: 0.2528\n",
      "Epoch 24/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0250 - val_loss: 0.2609\n",
      "Epoch 25/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0265 - val_loss: 0.2834\n",
      "Epoch 26/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0257 - val_loss: 0.2484\n",
      "Epoch 27/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0285 - val_loss: 0.2462\n",
      "Epoch 28/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0278 - val_loss: 0.2692\n",
      "Epoch 29/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0268 - val_loss: 0.2442\n",
      "Epoch 30/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0243 - val_loss: 0.2413\n",
      "Epoch 31/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0258 - val_loss: 0.2336\n",
      "Epoch 32/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0227 - val_loss: 0.2467\n",
      "Epoch 33/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0255 - val_loss: 0.2530\n",
      "Epoch 34/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0252 - val_loss: 0.2412\n",
      "Epoch 35/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0245 - val_loss: 0.2248\n",
      "Epoch 36/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0255 - val_loss: 0.2378\n",
      "Epoch 37/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0246 - val_loss: 0.2700\n",
      "Epoch 38/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0210 - val_loss: 0.2778\n",
      "Epoch 39/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0167 - val_loss: 0.2810\n",
      "Epoch 40/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0247 - val_loss: 0.2670\n",
      "Epoch 41/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0218 - val_loss: 0.2903\n",
      "Epoch 42/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0230 - val_loss: 0.3199\n",
      "Epoch 43/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0225 - val_loss: 0.2816\n",
      "Epoch 44/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0196 - val_loss: 0.2679\n",
      "Epoch 45/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0220 - val_loss: 0.3022\n",
      "Epoch 46/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0204 - val_loss: 0.2620\n",
      "Epoch 47/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0228 - val_loss: 0.2557\n",
      "Epoch 48/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0201 - val_loss: 0.3082\n",
      "Epoch 49/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0233 - val_loss: 0.3147\n",
      "Epoch 50/50\n",
      "1120/1120 [==============================] - 1s 1ms/step - loss: 0.0218 - val_loss: 0.2909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10d427898>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Anchor = X_train[:,0,:].reshape(-1,70,31,1)\n",
    "Positive = X_train[:,1,:].reshape(-1,70,31,1)\n",
    "Negative = X_train[:,2,:].reshape(-1,70,31,1)\n",
    "Anchor_test = X_test[:,0,:].reshape(-1,70,31,1)\n",
    "Positive_test = X_test[:,1,:].reshape(-1,70,31,1)\n",
    "Negative_test = X_test[:,2,:].reshape(-1,70,31,1)\n",
    "\n",
    "Y_dummy = np.empty((Anchor.shape[0],300))\n",
    "Y_dummy2 = np.empty((Anchor_test.shape[0],1))\n",
    "\n",
    "model.fit([Anchor,Positive,Negative],y=Y_dummy,validation_data=([Anchor_test,Positive_test,Negative_test],Y_dummy2), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = Model(inputs=anchor_input, outputs=encoded_anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsne = TSNE()\n",
    "X_train_trm = trained_model.predict(x_train[:512].reshape(-1,70,31,1))\n",
    "X_test_trm = trained_model.predict(x_test[:512].reshape(-1,70,31,1))\n",
    "train_tsne_embeds = tsne.fit_transform(X_train_trm)\n",
    "eval_tsne_embeds = tsne.fit_transform(X_test_trm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:2831: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.mean(atmp[sl], axis=axis)\n"
     ]
    }
   ],
   "source": [
    "scatter(train_tsne_embeds, y_train[:512], \"Training Data After TNN\")\n",
    "scatter(eval_tsne_embeds, y_test[:512], \"Validation Data After TNN\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
