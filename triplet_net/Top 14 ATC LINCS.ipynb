{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import sys\n",
    "import matplotlib.pyplot as plt1 \n",
    "import numpy as np\n",
    "from IPython.display import Audio, display\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Conv2D, Lambda, Dense, Flatten,MaxPooling2D, concatenate, Conv1D,Conv2D, Flatten, Reshape, Embedding, GRU, SpatialDropout1D, LSTM, Dropout, BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "from itertools import permutations\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "from scipy.stats import trim_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(\"../../CubeBio/Data/full\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['id']=data['target']\n",
    "data=data.drop(['target'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118050, 979)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>inchi_key</th>\n",
       "      <th>atc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>NC12CC3CC(CC(C3)C1)C2</td>\n",
       "      <td>amantadine</td>\n",
       "      <td>BRD-K70330367</td>\n",
       "      <td>DKNWSYNQZKUICI-UHFFFAOYSA-N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>CS(=O)(=O)OCCCCOS(C)(=O)=O</td>\n",
       "      <td>busulfan</td>\n",
       "      <td>BRD-K23204545</td>\n",
       "      <td>COVZYZSDYWQREU-UHFFFAOYSA-N</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>CCCC(C)(COC(N)=O)COC(=O)NC(C)C</td>\n",
       "      <td>carisoprodol</td>\n",
       "      <td>BRD-A99939097</td>\n",
       "      <td>OFZCIYFFPZCNJE-UHFFFAOYSA-N</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>CCN(CC)C(=O)N1CCN(C)CC1</td>\n",
       "      <td>diethylcarbamazine</td>\n",
       "      <td>BRD-K45542189</td>\n",
       "      <td>RCKMWOKWVGPNJF-UHFFFAOYSA-N</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>CCN(CC)C(=S)SSC(=S)N(CC)CC</td>\n",
       "      <td>disulfiram</td>\n",
       "      <td>BRD-K32744045</td>\n",
       "      <td>AUZONCFQVSMFAP-UHFFFAOYSA-N</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             smiles                name             id  \\\n",
       "75            NC12CC3CC(CC(C3)C1)C2          amantadine  BRD-K70330367   \n",
       "291      CS(=O)(=O)OCCCCOS(C)(=O)=O            busulfan  BRD-K23204545   \n",
       "322  CCCC(C)(COC(N)=O)COC(=O)NC(C)C        carisoprodol  BRD-A99939097   \n",
       "491         CCN(CC)C(=O)N1CCN(C)CC1  diethylcarbamazine  BRD-K45542189   \n",
       "510      CCN(CC)C(=S)SSC(=S)N(CC)CC          disulfiram  BRD-K32744045   \n",
       "\n",
       "                       inchi_key atc  \n",
       "75   DKNWSYNQZKUICI-UHFFFAOYSA-N   N  \n",
       "291  COVZYZSDYWQREU-UHFFFAOYSA-N   L  \n",
       "322  OFZCIYFFPZCNJE-UHFFFAOYSA-N   M  \n",
       "491  RCKMWOKWVGPNJF-UHFFFAOYSA-N   P  \n",
       "510  AUZONCFQVSMFAP-UHFFFAOYSA-N   P  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full = pd.read_csv(\"../data/drug_class_identification/all3.csv\")\n",
    "full = full.dropna()\n",
    "full['atc'] = full['atc'].apply(lambda x : x[0])\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(data, full, how=\"inner\").drop(['id','smiles','name','inchi_key'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>780</th>\n",
       "      <th>7849</th>\n",
       "      <th>6193</th>\n",
       "      <th>23</th>\n",
       "      <th>9552</th>\n",
       "      <th>387</th>\n",
       "      <th>10921</th>\n",
       "      <th>10285</th>\n",
       "      <th>533</th>\n",
       "      <th>6194</th>\n",
       "      <th>...</th>\n",
       "      <th>11000</th>\n",
       "      <th>6915</th>\n",
       "      <th>6253</th>\n",
       "      <th>7264</th>\n",
       "      <th>5467</th>\n",
       "      <th>2767</th>\n",
       "      <th>23038</th>\n",
       "      <th>57048</th>\n",
       "      <th>79716</th>\n",
       "      <th>atc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.066358</td>\n",
       "      <td>-1.245058</td>\n",
       "      <td>0.078668</td>\n",
       "      <td>-0.788176</td>\n",
       "      <td>-1.129236</td>\n",
       "      <td>0.407757</td>\n",
       "      <td>0.292397</td>\n",
       "      <td>0.479977</td>\n",
       "      <td>-0.223936</td>\n",
       "      <td>-1.141854</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.784618</td>\n",
       "      <td>-0.982621</td>\n",
       "      <td>-0.670931</td>\n",
       "      <td>0.981703</td>\n",
       "      <td>0.883668</td>\n",
       "      <td>0.202455</td>\n",
       "      <td>0.429206</td>\n",
       "      <td>0.312411</td>\n",
       "      <td>-0.133215</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.066358</td>\n",
       "      <td>-1.245058</td>\n",
       "      <td>0.078668</td>\n",
       "      <td>-0.788176</td>\n",
       "      <td>-1.129236</td>\n",
       "      <td>0.407757</td>\n",
       "      <td>0.292397</td>\n",
       "      <td>0.479977</td>\n",
       "      <td>-0.223936</td>\n",
       "      <td>-1.141854</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.784618</td>\n",
       "      <td>-0.982621</td>\n",
       "      <td>-0.670931</td>\n",
       "      <td>0.981703</td>\n",
       "      <td>0.883668</td>\n",
       "      <td>0.202455</td>\n",
       "      <td>0.429206</td>\n",
       "      <td>0.312411</td>\n",
       "      <td>-0.133215</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.209095</td>\n",
       "      <td>0.176860</td>\n",
       "      <td>-0.720512</td>\n",
       "      <td>-0.793518</td>\n",
       "      <td>0.720299</td>\n",
       "      <td>-0.555583</td>\n",
       "      <td>-0.395229</td>\n",
       "      <td>-1.252304</td>\n",
       "      <td>-2.462850</td>\n",
       "      <td>-0.185532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235278</td>\n",
       "      <td>-0.136517</td>\n",
       "      <td>0.864514</td>\n",
       "      <td>-0.098884</td>\n",
       "      <td>-1.099747</td>\n",
       "      <td>-3.044908</td>\n",
       "      <td>-0.146705</td>\n",
       "      <td>0.942604</td>\n",
       "      <td>0.028090</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.209095</td>\n",
       "      <td>0.176860</td>\n",
       "      <td>-0.720512</td>\n",
       "      <td>-0.793518</td>\n",
       "      <td>0.720299</td>\n",
       "      <td>-0.555583</td>\n",
       "      <td>-0.395229</td>\n",
       "      <td>-1.252304</td>\n",
       "      <td>-2.462850</td>\n",
       "      <td>-0.185532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235278</td>\n",
       "      <td>-0.136517</td>\n",
       "      <td>0.864514</td>\n",
       "      <td>-0.098884</td>\n",
       "      <td>-1.099747</td>\n",
       "      <td>-3.044908</td>\n",
       "      <td>-0.146705</td>\n",
       "      <td>0.942604</td>\n",
       "      <td>0.028090</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.160403</td>\n",
       "      <td>0.857906</td>\n",
       "      <td>-2.114255</td>\n",
       "      <td>0.041883</td>\n",
       "      <td>0.818861</td>\n",
       "      <td>0.302385</td>\n",
       "      <td>-0.586580</td>\n",
       "      <td>-0.774723</td>\n",
       "      <td>1.168153</td>\n",
       "      <td>-1.972200</td>\n",
       "      <td>...</td>\n",
       "      <td>1.197446</td>\n",
       "      <td>0.940610</td>\n",
       "      <td>0.434476</td>\n",
       "      <td>1.187713</td>\n",
       "      <td>-0.335655</td>\n",
       "      <td>0.262674</td>\n",
       "      <td>1.139491</td>\n",
       "      <td>0.858688</td>\n",
       "      <td>1.959727</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 979 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        780      7849      6193        23      9552       387     10921  \\\n",
       "0 -0.066358 -1.245058  0.078668 -0.788176 -1.129236  0.407757  0.292397   \n",
       "1 -0.066358 -1.245058  0.078668 -0.788176 -1.129236  0.407757  0.292397   \n",
       "2 -0.209095  0.176860 -0.720512 -0.793518  0.720299 -0.555583 -0.395229   \n",
       "3 -0.209095  0.176860 -0.720512 -0.793518  0.720299 -0.555583 -0.395229   \n",
       "4  1.160403  0.857906 -2.114255  0.041883  0.818861  0.302385 -0.586580   \n",
       "\n",
       "      10285       533      6194 ...      11000      6915      6253      7264  \\\n",
       "0  0.479977 -0.223936 -1.141854 ...  -0.784618 -0.982621 -0.670931  0.981703   \n",
       "1  0.479977 -0.223936 -1.141854 ...  -0.784618 -0.982621 -0.670931  0.981703   \n",
       "2 -1.252304 -2.462850 -0.185532 ...   0.235278 -0.136517  0.864514 -0.098884   \n",
       "3 -1.252304 -2.462850 -0.185532 ...   0.235278 -0.136517  0.864514 -0.098884   \n",
       "4 -0.774723  1.168153 -1.972200 ...   1.197446  0.940610  0.434476  1.187713   \n",
       "\n",
       "       5467      2767     23038     57048     79716  atc  \n",
       "0  0.883668  0.202455  0.429206  0.312411 -0.133215    D  \n",
       "1  0.883668  0.202455  0.429206  0.312411 -0.133215    G  \n",
       "2 -1.099747 -3.044908 -0.146705  0.942604  0.028090    D  \n",
       "3 -1.099747 -3.044908 -0.146705  0.942604  0.028090    G  \n",
       "4 -0.335655  0.262674  1.139491  0.858688  1.959727    D  \n",
       "\n",
       "[5 rows x 979 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.dropna()\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49373, 978)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = result['atc']\n",
    "X = result.drop(['atc'],axis=1)\n",
    "X = np.asarray(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define our own plot function\n",
    "def scatter(x, y, subtitle=None):\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(y)\n",
    "\n",
    "    # We choose a color palette with seaborn.\n",
    "    palette = np.array(sns.color_palette(\"hls\", 14))\n",
    "\n",
    "    # We create a scatter plot.\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40,\n",
    "                    c=palette[labels.astype(np.int)])\n",
    "    plt.xlim(-25, 25)\n",
    "    plt.ylim(-25, 25)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "\n",
    "    # We add the labels for each digit.\n",
    "    txts = []\n",
    "    for i in range(14):\n",
    "        # Position of each label.\n",
    "        xtext, ytext = trim_mean(x[labels == i, :], axis=0, proportiontocut=0.2)\n",
    "        letter = le.inverse_transform([i])[0]\n",
    "        txt = ax.text(xtext, ytext, str(letter), fontsize=24)\n",
    "        txt.set_path_effects([\n",
    "            PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "            PathEffects.Normal()])\n",
    "        txts.append(txt)\n",
    "        \n",
    "    if subtitle != None:\n",
    "        plt.suptitle(subtitle)\n",
    "        \n",
    "    plt.savefig(subtitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:2831: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.mean(atmp[sl], axis=axis)\n",
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:2831: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.mean(atmp[sl], axis=axis)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test,y_train,y_test = train_test_split(X,y)\n",
    "\n",
    "x_train_flat = x_train.reshape(-1,978)\n",
    "x_test_flat = x_test.reshape(-1,978)\n",
    "\n",
    "tsne = TSNE()\n",
    "train_tsne_embeds = tsne.fit_transform(x_train_flat[:500])\n",
    "scatter(train_tsne_embeds, y_train[:500], \"Samples from Training Data LINCS\")\n",
    "\n",
    "eval_tsne_embeds = tsne.fit_transform(x_test_flat[:500])\n",
    "scatter(eval_tsne_embeds, y_test[:500], \"Samples from Validation Data LINCS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-80f100e6c83c>, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-80f100e6c83c>\"\u001b[0;36m, line \u001b[0;32m24\u001b[0m\n\u001b[0;31m    for i in range(10)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.4):\n",
    "    print('y_pred.shape = ',y_pred)\n",
    "    \n",
    "    total_lenght = y_pred.shape.as_list()[-1]\n",
    "    \n",
    "    anchor = y_pred[:,0:int(total_lenght*1/3)]\n",
    "    positive = y_pred[:,int(total_lenght*1/3):int(total_lenght*2/3)]\n",
    "    negative = y_pred[:,int(total_lenght*2/3):int(total_lenght*3/3)]\n",
    "\n",
    "    # distance between the anchor and the positive\n",
    "    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n",
    "\n",
    "    # distance between the anchor and the negative\n",
    "    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n",
    "\n",
    "    # compute loss\n",
    "    basic_loss = pos_dist-neg_dist+alpha\n",
    "    loss = K.maximum(basic_loss,0.0)\n",
    " \n",
    "    return loss\n",
    "\n",
    "def baseNetwork():    \n",
    "        model = Sequential()\n",
    "        for i in range(10)\n",
    "            model.add(Dense(100, activation='relu'))\n",
    "            model.add(Dropout(0.9))\n",
    "        model.add(Dense(14, activation='softmax'))\n",
    "        return model\n",
    "    \n",
    "anchor_input = Input((978,1, ), name='anchor_input')\n",
    "positive_input = Input((978,1, ), name='positive_input')\n",
    "negative_input = Input((978,1, ), name='negative_input')\n",
    "\n",
    "# Shared embedding layer for positive and negative items\n",
    "Shared_DNN = baseNetwork()\n",
    "\n",
    "\n",
    "encoded_anchor = Shared_DNN(anchor_input)\n",
    "encoded_positive = Shared_DNN(positive_input)\n",
    "encoded_negative = Shared_DNN(negative_input)\n",
    "\n",
    "\n",
    "merged_vector = concatenate([encoded_anchor, encoded_positive, encoded_negative], axis=-1, name='merged_layer')\n",
    "\n",
    "model = Model(inputs=[anchor_input,positive_input, negative_input], outputs=merged_vector)\n",
    "model.compile(loss=triplet_loss, optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateTriplet(x,y,testsize=0.2,ap_pairs=10,an_pairs=10):\n",
    "    data_xy = tuple([x,y])\n",
    "\n",
    "    trainsize = 1-testsize\n",
    "\n",
    "    triplet_train_pairs = []\n",
    "    triplet_test_pairs = []\n",
    "    for data_class in sorted(set(data_xy[1])):\n",
    "\n",
    "        same_class_idx = np.where((data_xy[1] == data_class))[0]\n",
    "        diff_class_idx = np.where(data_xy[1] != data_class)[0]\n",
    "        A_P_pairs = random.sample(list(permutations(same_class_idx,2)),k=ap_pairs) #Generating Anchor-Positive pairs\n",
    "        Neg_idx = random.sample(list(diff_class_idx),k=an_pairs)\n",
    "        \n",
    "\n",
    "        #train\n",
    "        A_P_len = len(A_P_pairs)\n",
    "        Neg_len = len(Neg_idx)\n",
    "        for ap in A_P_pairs[:int(A_P_len*trainsize)]:\n",
    "            Anchor = data_xy[0][ap[0]]\n",
    "            Positive = data_xy[0][ap[1]]\n",
    "            for n in Neg_idx:\n",
    "                Negative = data_xy[0][n]\n",
    "                triplet_train_pairs.append([Anchor,Positive,Negative])               \n",
    "        #test\n",
    "        for ap in A_P_pairs[int(A_P_len*trainsize):]:\n",
    "            Anchor = data_xy[0][ap[0]]\n",
    "            Positive = data_xy[0][ap[1]]\n",
    "            for n in Neg_idx:\n",
    "                Negative = data_xy[0][n]\n",
    "                triplet_test_pairs.append([Anchor,Positive,Negative])    \n",
    "                \n",
    "    return np.array(triplet_train_pairs), np.array(triplet_test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = generateTriplet(X[:50],y[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 94s 585ms/step - loss: 0.4005 - val_loss: 0.4000\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 75s 469ms/step - loss: 0.4000 - val_loss: 0.4000\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 78s 485ms/step - loss: 0.3998 - val_loss: 0.4000\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 74s 460ms/step - loss: 0.3995 - val_loss: 0.4000\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 75s 469ms/step - loss: 0.3994 - val_loss: 0.4000\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 73s 453ms/step - loss: 0.3994 - val_loss: 0.4000\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 73s 456ms/step - loss: 0.3984 - val_loss: 0.3999\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 71s 443ms/step - loss: 0.3982 - val_loss: 0.3999\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 78s 490ms/step - loss: 0.3988 - val_loss: 0.3999\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 88s 552ms/step - loss: 0.3963 - val_loss: 0.3999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a33b5cbe0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Anchor = X_train[:,0,:].reshape(-1,978,1)\n",
    "Positive = X_train[:,1,:].reshape(-1,978,1)\n",
    "Negative = X_train[:,2,:].reshape(-1,978,1)\n",
    "Anchor_test = X_test[:,0,:].reshape(-1,978,1)\n",
    "Positive_test = X_test[:,1,:].reshape(-1,978,1)\n",
    "Negative_test = X_test[:,2,:].reshape(-1,978,1)\n",
    "\n",
    "Y_dummy = np.empty((Anchor.shape[0],300))\n",
    "Y_dummy2 = np.empty((Anchor_test.shape[0],1))\n",
    "\n",
    "model.fit([Anchor,Positive,Negative],y=Y_dummy,validation_data=([Anchor_test,Positive_test,Negative_test],Y_dummy2), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained_model = Model(inputs=anchor_input, outputs=encoded_anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected anchor_input to have 3 dimensions, but got array with shape (100, 978)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-90774780eb79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train_trm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m978\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_test_trm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m978\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_tsne_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_trm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0meval_tsne_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_trm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dweepa/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                              'argument.')\n\u001b[1;32m   1148\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dweepa/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dweepa/anaconda/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected anchor_input to have 3 dimensions, but got array with shape (100, 978)"
     ]
    }
   ],
   "source": [
    "tsne = TSNE()\n",
    "X_train_trm = trained_model.predict(x_train[:100].reshape(-1,978,1))\n",
    "X_test_trm = trained_model.predict(x_test[:100].reshape(-1,978,1))\n",
    "train_tsne_embeds = tsne.fit_transform(X_train_trm)\n",
    "eval_tsne_embeds = tsne.fit_transform(X_test_trm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:2831: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.mean(atmp[sl], axis=axis)\n"
     ]
    }
   ],
   "source": [
    "scatter(train_tsne_embeds, y_train[:500], \"Training Data After TNN\")\n",
    "scatter(eval_tsne_embeds, y_test[:500], \"Validation Data After TNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
