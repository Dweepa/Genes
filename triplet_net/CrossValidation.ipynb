{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Input\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.layers import Layer\n",
    "from tensorflow.python.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# Import custom modules\n",
    "from network import *\n",
    "from data import *\n",
    "\n",
    "dbfile = open('../Data/full', 'rb')\n",
    "data = pickle.load(dbfile)\n",
    "dbfile = open('../Data/location_pert', 'rb')\n",
    "location_pert = pickle.load(dbfile)\n",
    "dbfile = open('../Data/pert2profiles', 'rb')\n",
    "pert2profiles = pickle.load(dbfile)\n",
    "dbfile = open('../Data/test_perts', 'rb')\n",
    "test_pert = pickle.load(dbfile)\n",
    "dbfile = open('../Data/train_perts', 'rb')\n",
    "train_pert = pickle.load(dbfile)\n",
    "dbfile.close()\n",
    "\n",
    "# X_train = generate_data(data,train_pert,100)\n",
    "# X_test = generate_data(data,test_pert,100)\n",
    "\n",
    "# dbfile = open('X_train_triplet_full', 'ab')\n",
    "# pickle.dump(X_train, dbfile)\n",
    "# dbfile.close()\n",
    "\n",
    "\n",
    "#X = pickle.load(open('../Data/X_train_triplet_full', 'rb'))\n",
    "#test = pickle.load(open('../Data/X_test_triplet_full', 'rb'))\n",
    "# y = pickle.load(open('../Data/y_test', 'rb'))\n",
    "\n",
    "# cross validation code WIP\n",
    "all_pert = np.concatenate((train_pert, test_pert))\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Crossvalidation run # 1\n",
      "(1736,) (434,)\n",
      "batch_size:  10\n",
      "10/10\n",
      "\n",
      "batch_size:  10\n",
      "10/10\n",
      "\n",
      "WARNING:tensorflow:From /Users/dweepa/anaconda/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:189: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Epoch\t\t\t+ Dist\t- Dist\t\tTrain\tTest\n",
      "Epoch 0:\t10/10\t0.244\t0.327\t\t85.000\t70.000\n",
      "Epoch 1:\t10/10\t0.372\t0.797\t\t95.000\t55.000\n",
      "Epoch 2:\t10/10\t0.071\t0.798\t\t95.000\t70.000\n",
      "Epoch 3:\t10/10\t0.030\t0.880\t\t95.000\t40.000\n",
      "Epoch 4:\t10/10\t0.021\t0.943\t\t100.000\t40.000\n",
      "Epoch 5:\t10/10\t0.019\t0.996\t\t100.000\t45.000\n",
      "Epoch 6:\t10/10\t0.004\t1.000\t\t100.000\t50.000\n",
      "Epoch 7:\t10/10\t0.002\t0.999\t\t100.000\t50.000\n",
      "Epoch 8:\t10/10\t0.001\t0.999\t\t100.000\t50.000\n",
      "Epoch 9:\t10/10\t0.001\t0.999\t\t100.000\t50.000\n",
      "\n",
      "Crossvalidation run # 2\n",
      "(1736,) (434,)\n",
      "batch_size:  10\n",
      "10/10\n",
      "\n",
      "batch_size:  10\n",
      "10/10\n",
      "\n",
      "Initialized\n",
      "Epoch\t\t\t+ Dist\t- Dist\t\tTrain\tTest\n",
      "Epoch 0:\t10/10\t0.139\t0.142\t\t70.000\t50.000\n",
      "Epoch 1:\t10/10\t0.447\t0.701\t\t90.000\t75.000\n",
      "Epoch 2:\t10/10\t0.199\t0.920\t\t100.000\t65.000\n",
      "Epoch 3:\t10/10\t0.078\t0.927\t\t100.000\t75.000\n",
      "Epoch 4:\t10/10\t0.036\t0.954\t\t100.000\t80.000\n",
      "Epoch 5:\t10/10\t0.058\t0.985\t\t100.000\t80.000\n",
      "Epoch 6:\t10/10\t0.024\t0.962\t\t100.000\t80.000\n",
      "Epoch 7:\t10/10\t0.017\t0.996\t\t100.000\t80.000\n",
      "Epoch 8:\t10/10\t0.015\t0.991\t\t100.000\t80.000\n",
      "Epoch 9:\t10/10\t0.003\t0.998\t\t100.000\t80.000\n",
      "\n",
      "Crossvalidation run # 3\n",
      "(1736,) (434,)\n",
      "batch_size:  10\n",
      "10/10\n",
      "\n",
      "batch_size:  10\n",
      "10/10\n",
      "\n",
      "Initialized\n",
      "Epoch\t\t\t+ Dist\t- Dist\t\tTrain\tTest\n",
      "Epoch 0:\t10/10\t0.307\t0.560\t\t75.000\t45.000\n",
      "Epoch 1:\t10/10\t0.193\t0.606\t\t95.000\t60.000\n",
      "Epoch 2:\t10/10\t0.071\t0.896\t\t100.000\t55.000\n",
      "Epoch 3:\t10/10\t0.006\t0.987\t\t100.000\t60.000\n",
      "Epoch 4:\t10/10\t0.002\t0.991\t\t100.000\t55.000\n",
      "Epoch 5:\t10/10\t0.001\t0.995\t\t100.000\t55.000\n",
      "Epoch 6:\t10/10\t0.001\t0.999\t\t100.000\t55.000\n",
      "Epoch 7:\t10/10\t0.000\t0.999\t\t100.000\t55.000\n",
      "Epoch 8:\t10/10\t0.000\t0.999\t\t100.000\t55.000\n",
      "Epoch 9:\t10/10\t0.000\t1.000\t\t100.000\t55.000\n",
      "\n",
      "Crossvalidation run # 4\n",
      "(1736,) (434,)\n",
      "batch_size:  10\n",
      "10/10\n",
      "\n",
      "batch_size:  10\n",
      "10/10\n",
      "\n",
      "Initialized\n",
      "Epoch\t\t\t+ Dist\t- Dist\t\tTrain\tTest\n",
      "Epoch 0:\t10/10\t0.126\t0.554\t\t75.000\t45.000\n",
      "Epoch 1:\t10/10\t0.181\t0.279\t\t60.000\t50.000\n",
      "Epoch 2:\t10/10\t0.120\t0.506\t\t80.000\t50.000\n",
      "Epoch 3:\t10/10\t0.146\t0.768\t\t80.000\t50.000\n",
      "Epoch 4:\t10/10\t0.151\t0.811\t\t90.000\t50.000\n",
      "Epoch 5:\t10/10\t0.037\t0.878\t\t100.000\t50.000\n",
      "Epoch 6:\t10/10\t0.045\t0.989\t\t100.000\t50.000\n",
      "Epoch 7:\t10/10\t0.009\t0.988\t\t100.000\t50.000\n",
      "Epoch 8:\t10/10\t0.003\t0.993\t\t100.000\t40.000\n",
      "Epoch 9:\t10/10\t0.002\t0.998\t\t100.000\t40.000\n",
      "\n",
      "Crossvalidation run # 5\n",
      "(1736,) (434,)\n",
      "batch_size:  10\n",
      "10/10\n",
      "\n",
      "batch_size:  10\n",
      "10/10\n",
      "\n",
      "Initialized\n",
      "Epoch\t\t\t+ Dist\t- Dist\t\tTrain\tTest\n",
      "Epoch 0:\t10/10\t0.245\t0.418\t\t80.000\t50.000\n",
      "Epoch 1:\t10/10\t0.118\t0.668\t\t80.000\t50.000\n",
      "Epoch 2:\t10/10\t0.107\t0.713\t\t80.000\t50.000\n",
      "Epoch 3:\t10/10\t0.108\t0.764\t\t85.000\t50.000\n",
      "Epoch 4:\t10/10\t0.141\t0.926\t\t95.000\t50.000\n",
      "Epoch 5:\t10/10\t0.106\t0.987\t\t95.000\t50.000\n",
      "Epoch 6:\t10/10\t0.097\t0.971\t\t95.000\t50.000\n",
      "Epoch 7:\t10/10\t0.070\t0.987\t\t100.000\t50.000\n",
      "Epoch 8:\t10/10\t0.013\t0.990\t\t100.000\t55.000\n",
      "Epoch 9:\t10/10\t0.015\t0.997\t\t100.000\t50.000\n",
      "\n",
      "\n",
      "Cross-validation result: Train: \n",
      "5.0\t\t Test:2.75\n"
     ]
    }
   ],
   "source": [
    "# cross validation code WIP\n",
    "all_pert = np.concatenate((train_pert,test_pert))\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "def cross_validate(splitsize):\n",
    "    kf = KFold(n_splits=splitsize)\n",
    "    results = []\n",
    "    c=1\n",
    "    for train_idx, val_idx in kf.split(all_pert):\n",
    "        print(\"\\nCrossvalidation run #\",c)\n",
    "        c+=1\n",
    "        train_perts = all_pert[train_idx]\n",
    "        val_perts = all_pert[val_idx]\n",
    "        print(train_perts.shape,val_perts.shape)\n",
    "        X_train = generate_data(data,train_perts,100)\n",
    "        print(\"\\n\")\n",
    "        X_val = generate_data(data,val_perts,100)\n",
    "        s = siamese(\"cos\",\"net\")\n",
    "        epochs=10\n",
    "        print(\"\\n\")\n",
    "        embeddings, trained, pred, p_loss, n_loss, train_acc_l, test_acc_l = run_network(s, epochs, X_train, X_val)\n",
    "        \n",
    "        p = np.sum(trained[0][2]<=0.5)\n",
    "        n = np.sum(trained[0][3]>0.5)\n",
    "        train_acc = ((p+n)/len(X_train[0])/2)\n",
    "\n",
    "        p = np.sum(pred[0][2]<=0.5)\n",
    "        n = np.sum(pred[0][3]>0.5)\n",
    "        val_acc = ((p+n)/len(X_val[0])/2)\n",
    "        \n",
    "        accuracy = (train_acc, val_acc)\n",
    "        results.append(accuracy)\n",
    "    return results\n",
    "\n",
    "result = cross_validate(5)\n",
    "test_res=0\n",
    "train_res=0\n",
    "for i in result:\n",
    "    test_res+=i[1]\n",
    "    train_res+=i[0]\n",
    "print (\"\\n\\nCross-validation result: Train: \\n%s\\t\\t Test:%s\" % (train_res,test_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
