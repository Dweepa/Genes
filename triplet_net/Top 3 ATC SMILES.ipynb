{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import sys\n",
    "import matplotlib.pyplot as plt1 \n",
    "import numpy as np\n",
    "from IPython.display import Audio, display\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.layers import Input, Conv2D, Lambda, Dense, Flatten,MaxPooling2D, concatenate, Conv1D,Conv2D, Flatten, Reshape, Embedding, GRU, SpatialDropout1D, LSTM, Dropout, BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "from itertools import permutations\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "from scipy.stats import trim_mean\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.read_csv(\"../data/drug_class_identification/all3.csv\")\n",
    "full = full.dropna()\n",
    "full['atc'] = full['atc'].apply(lambda x : x[0])\n",
    "full = full[full.atc.isin(['C','L','N'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full[\"smiles\"]\n",
    "y = full['atc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getVocabulary(sample):\n",
    "    vocabulary = set()\n",
    "    for word in sample:\n",
    "        for character in word:\n",
    "            vocabulary.add(character)\n",
    "    return (vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "characters = getVocabulary(X)\n",
    "token_index = dict(zip(characters, range(1, len(characters) + 1)))\n",
    "\n",
    "samples = X.tolist()\n",
    "max_length = 70\n",
    "results = np.zeros((len(samples), max_length, max(token_index.values()) + 1))\n",
    "for i, sample in enumerate(samples):\n",
    "    for j, character in enumerate(sample[:max_length]):\n",
    "        index = token_index.get(character)\n",
    "        results[i, j, index] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(422, 70, 30)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.asarray(results)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define our own plot function\n",
    "def scatter(x, y, subtitle=None):\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(y)\n",
    "\n",
    "    # We choose a color palette with seaborn.\n",
    "    palette = np.array(sns.color_palette(\"hls\", 3))\n",
    "\n",
    "    # We create a scatter plot.\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40,\n",
    "                    c=palette[labels.astype(np.int)])\n",
    "    plt.xlim(-25, 25)\n",
    "    plt.ylim(-25, 25)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "\n",
    "    # We add the labels for each digit.\n",
    "    txts = []\n",
    "    for i in range(3):\n",
    "        # Position of each label.\n",
    "        xtext, ytext = trim_mean(x[labels == i, :], axis=0, proportiontocut=0.2)\n",
    "        letter = le.inverse_transform([i])[0]\n",
    "        txt = ax.text(xtext, ytext, str(letter), fontsize=24)\n",
    "        txt.set_path_effects([\n",
    "            PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "            PathEffects.Normal()])\n",
    "        txts.append(txt)\n",
    "        \n",
    "    if subtitle != None:\n",
    "        plt.suptitle(subtitle)\n",
    "        \n",
    "    plt.savefig(subtitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(316, 70, 30)\n",
      "(316, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:2831: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.mean(atmp[sl], axis=axis)\n",
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:2831: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.mean(atmp[sl], axis=axis)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test,y_train,y_test = train_test_split(X,y)\n",
    "print(x_train.shape)\n",
    "x_train_flat = np.asarray([sum(x_train[0]) for i in x_train]) #.reshape(-1,70*30)\n",
    "x_test_flat = np.asarray([sum(x_test[0]) for i in x_test])\n",
    "\n",
    "print(x_train_flat.shape)\n",
    "tsne = TSNE()\n",
    "train_tsne_embeds = tsne.fit_transform(x_train_flat)\n",
    "scatter(train_tsne_embeds, y_train, \"Samples from Training Data\")\n",
    "\n",
    "eval_tsne_embeds = tsne.fit_transform(x_test_flat)\n",
    "scatter(eval_tsne_embeds, y_test, \"Samples from Validation Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.18742365e-01,  7.39266813e-01],\n",
       "       [ 3.18880349e-01,  7.39538133e-01],\n",
       "       [ 3.18888098e-01,  7.39061296e-01],\n",
       "       [ 3.18613231e-01,  7.39048660e-01],\n",
       "       [ 3.18862349e-01,  7.39367843e-01],\n",
       "       [ 3.18880320e-01,  7.39538133e-01],\n",
       "       [ 3.18862379e-01,  7.39367843e-01],\n",
       "       [ 3.18862230e-01,  7.39367723e-01],\n",
       "       [ 3.18627924e-01,  7.39044905e-01],\n",
       "       [ 3.18627864e-01,  7.39044905e-01],\n",
       "       [ 3.18862259e-01,  7.39367783e-01],\n",
       "       [ 3.18880379e-01,  7.39538133e-01],\n",
       "       [ 3.18880320e-01,  7.39538133e-01],\n",
       "       [ 3.18880439e-01,  7.39538133e-01],\n",
       "       [ 3.19099575e-01,  7.39297867e-01],\n",
       "       [ 3.18627834e-01,  7.39044964e-01],\n",
       "       [ 3.18627834e-01,  7.39044905e-01],\n",
       "       [ 3.18627834e-01,  7.39045024e-01],\n",
       "       [ 3.18427145e-01,  7.39295840e-01],\n",
       "       [ 3.18742305e-01,  7.39266813e-01],\n",
       "       [ 3.18880320e-01,  7.39538133e-01],\n",
       "       [ 3.18880349e-01,  7.39538133e-01],\n",
       "       [ 3.18613231e-01,  7.39048660e-01],\n",
       "       [ 3.18613261e-01,  7.39048600e-01],\n",
       "       [ 3.18862349e-01,  7.39367783e-01],\n",
       "       [ 3.18427116e-01,  7.39295781e-01],\n",
       "       [ 3.18427116e-01,  7.39295840e-01],\n",
       "       [ 3.18880379e-01,  7.39538133e-01],\n",
       "       [ 3.18427056e-01,  7.39295840e-01],\n",
       "       [ 3.18613231e-01,  7.39048660e-01],\n",
       "       [ 3.18862379e-01,  7.39367783e-01],\n",
       "       [ 3.18697333e-01,  7.39329100e-01],\n",
       "       [ 3.18862230e-01,  7.39367723e-01],\n",
       "       [ 3.18862379e-01,  7.39367783e-01],\n",
       "       [ 3.18697363e-01,  7.39329159e-01],\n",
       "       [ 3.18880320e-01,  7.39538133e-01],\n",
       "       [ 3.18613231e-01,  7.39048600e-01],\n",
       "       [ 3.18627864e-01,  7.39044905e-01],\n",
       "       [ 3.18862230e-01,  7.39367783e-01],\n",
       "       [ 3.18880290e-01,  7.39538074e-01],\n",
       "       [ 3.18427145e-01,  7.39295721e-01],\n",
       "       [ 3.18862349e-01,  7.39367783e-01],\n",
       "       [ 3.18627834e-01,  7.39044905e-01],\n",
       "       [ 3.18551093e-01,  7.39077747e-01],\n",
       "       [ 3.18697304e-01,  7.39329100e-01],\n",
       "       [ 3.18627894e-01,  7.39044905e-01],\n",
       "       [ 3.18697363e-01,  7.39329159e-01],\n",
       "       [ 3.18613231e-01,  7.39048660e-01],\n",
       "       [ 3.18427145e-01,  7.39295721e-01],\n",
       "       [ 3.18613231e-01,  7.39048660e-01],\n",
       "       [ 3.18697333e-01,  7.39329040e-01],\n",
       "       [ 3.20653051e-01,  7.39950418e-01],\n",
       "       [ 3.18427116e-01,  7.39295781e-01],\n",
       "       [ 3.18742305e-01,  7.39266813e-01],\n",
       "       [ 3.18627864e-01,  7.39044905e-01],\n",
       "       [ 3.18427145e-01,  7.39295721e-01],\n",
       "       [ 3.18862259e-01,  7.39367843e-01],\n",
       "       [ 3.18742305e-01,  7.39266813e-01],\n",
       "       [ 3.18880379e-01,  7.39538133e-01],\n",
       "       [ 3.18862259e-01,  7.39367783e-01],\n",
       "       [ 3.18862230e-01,  7.39367783e-01],\n",
       "       [ 3.18613231e-01,  7.39048660e-01],\n",
       "       [ 3.18697244e-01,  7.39329100e-01],\n",
       "       [ 3.18697363e-01,  7.39329159e-01],\n",
       "       [ 3.18862379e-01,  7.39367783e-01],\n",
       "       [ 3.18862349e-01,  7.39367783e-01],\n",
       "       [ 3.18627805e-01,  7.39044845e-01],\n",
       "       [ 3.18427145e-01,  7.39295959e-01],\n",
       "       [ 3.18697333e-01,  7.39329100e-01],\n",
       "       [ 3.18627894e-01,  7.39044905e-01],\n",
       "       [ 3.18627894e-01,  7.39044905e-01],\n",
       "       [ 3.18427145e-01,  7.39295840e-01],\n",
       "       [ 3.18627894e-01,  7.39044905e-01],\n",
       "       [ 3.18862319e-01,  7.39367783e-01],\n",
       "       [ 3.18697363e-01,  7.39329159e-01],\n",
       "       [ 3.18862319e-01,  7.39367783e-01],\n",
       "       [ 3.18862259e-01,  7.39367783e-01],\n",
       "       [ 3.18862349e-01,  7.39367843e-01],\n",
       "       [ 3.18880320e-01,  7.39538252e-01],\n",
       "       [ 3.18697274e-01,  7.39329040e-01],\n",
       "       [ 3.18627834e-01,  7.39045024e-01],\n",
       "       [ 3.18880498e-01,  7.39538193e-01],\n",
       "       [ 3.18427145e-01,  7.39295900e-01],\n",
       "       [ 3.18427145e-01,  7.39295900e-01],\n",
       "       [ 3.18627834e-01,  7.39044905e-01],\n",
       "       [ 3.18427145e-01,  7.39295840e-01],\n",
       "       [ 3.18697274e-01,  7.39329040e-01],\n",
       "       [ 3.18880379e-01,  7.39538193e-01],\n",
       "       [ 3.18627864e-01,  7.39044905e-01],\n",
       "       [ 3.18427145e-01,  7.39295721e-01],\n",
       "       [-7.86841929e-01,  2.10049653e+00],\n",
       "       [-5.31179726e-01,  1.21245313e+00],\n",
       "       [ 7.38618433e-01,  1.61517310e+00],\n",
       "       [ 1.34561062e-01,  1.72661936e+00],\n",
       "       [-8.70098352e-01,  2.03741717e+00],\n",
       "       [ 1.84646010e+00, -2.03152820e-01],\n",
       "       [ 5.92837453e-01,  1.67341709e+00],\n",
       "       [ 6.80962384e-01,  2.34157944e+00],\n",
       "       [-5.36118150e-01,  1.20918763e+00],\n",
       "       [ 1.14022958e+00,  2.16745305e+00],\n",
       "       [-4.42124873e-01,  1.46769178e+00],\n",
       "       [-6.30308688e-01,  8.61861885e-01],\n",
       "       [ 1.90218404e-01,  2.05916405e+00],\n",
       "       [-1.51544094e-01,  1.58643699e+00],\n",
       "       [ 9.08734381e-01, -7.80353069e-01],\n",
       "       [-1.19320989e+00,  3.25810313e-01],\n",
       "       [ 6.90054119e-01,  2.33784580e+00],\n",
       "       [ 1.16242659e+00,  3.12252015e-01],\n",
       "       [ 1.70798731e+00,  1.53686666e+00],\n",
       "       [ 1.14082384e+00,  2.54449040e-01],\n",
       "       [ 1.79455268e+00,  1.73192427e-01],\n",
       "       [-2.84597486e-01,  2.11491548e-02],\n",
       "       [ 3.52000564e-01,  1.66949189e+00],\n",
       "       [ 1.91249120e+00,  6.09272778e-01],\n",
       "       [-1.46910548e-01,  1.58940089e+00],\n",
       "       [ 1.44113064e+00, -4.06323910e-01],\n",
       "       [ 8.16059634e-02, -8.87576163e-01],\n",
       "       [-1.62667781e-01,  2.31349683e+00],\n",
       "       [ 4.83180195e-01, -9.48774040e-01],\n",
       "       [-2.07943767e-01, -8.21076572e-01],\n",
       "       [-1.27629459e+00,  2.67210722e-01],\n",
       "       [ 1.88932288e+00,  1.17692006e+00],\n",
       "       [ 1.85385680e+00,  7.63537169e-01],\n",
       "       [ 1.27203012e+00,  9.98109758e-01],\n",
       "       [ 1.14083278e+00,  2.54426420e-01],\n",
       "       [-5.89047730e-01, -5.37138700e-01],\n",
       "       [ 7.75344551e-01, -8.95465612e-02],\n",
       "       [ 7.32615352e-01, -1.69487551e-01],\n",
       "       [ 1.22974503e+00,  4.34847951e-01],\n",
       "       [-1.31584203e+00,  1.19235086e+00],\n",
       "       [ 1.92454576e+00,  5.01642644e-01],\n",
       "       [-6.31494224e-01,  8.76684070e-01],\n",
       "       [ 7.38621235e-01,  1.61517131e+00],\n",
       "       [-6.13646150e-01,  9.76322055e-01],\n",
       "       [ 3.88122559e-01, -1.79223448e-01],\n",
       "       [ 9.72197056e-01,  1.46068442e+00],\n",
       "       [-3.43277931e-01, -7.99931645e-01],\n",
       "       [ 8.95405054e-01, -7.70025134e-01],\n",
       "       [ 1.80736184e+00,  2.75416851e-01],\n",
       "       [ 1.92454135e+00,  5.01632810e-01],\n",
       "       [-1.05769694e+00,  2.90938541e-02],\n",
       "       [-7.63737619e-01, -5.06974339e-01],\n",
       "       [-3.24065417e-01,  6.71071708e-02],\n",
       "       [-8.26410055e-02,  2.36683035e+00],\n",
       "       [ 4.02255952e-01, -1.84461087e-01],\n",
       "       [ 1.08247840e+00,  1.34160352e+00],\n",
       "       [-9.37283039e-01,  3.04677576e-01],\n",
       "       [ 1.21194124e+00,  2.12596154e+00],\n",
       "       [ 1.56003058e+00,  1.86392200e+00],\n",
       "       [ 7.75338769e-01, -8.95491391e-02],\n",
       "       [-3.01914752e-01,  3.63815092e-02],\n",
       "       [-2.74587125e-02, -1.37444317e-01],\n",
       "       [ 1.93389237e+00,  1.09101152e+00],\n",
       "       [-3.39096487e-01,  8.26437622e-02],\n",
       "       [-5.65244913e-01,  3.83724481e-01],\n",
       "       [-1.22633791e+00,  6.08942032e-01],\n",
       "       [ 3.18427116e-01,  7.39295721e-01],\n",
       "       [ 1.92129779e+00,  1.17923212e+00],\n",
       "       [ 1.75053930e+00,  2.34526768e-03],\n",
       "       [ 1.92454088e+00,  5.01634896e-01],\n",
       "       [-1.51541412e-01,  1.58643591e+00],\n",
       "       [ 1.27050984e+00,  9.82043862e-01],\n",
       "       [ 1.25722563e+00, -5.50720751e-01],\n",
       "       [ 1.94443202e+00, -7.27187917e-02],\n",
       "       [ 1.27050865e+00,  9.82044339e-01],\n",
       "       [-1.57637268e-01,  1.58665967e+00],\n",
       "       [ 5.74736118e-01,  1.69298422e+00],\n",
       "       [ 8.16634148e-02, -8.87305677e-01],\n",
       "       [-2.80383348e-01,  1.56159854e+00],\n",
       "       [-6.69665337e-01, -6.36752605e-01],\n",
       "       [ 1.27050912e+00,  9.82044280e-01],\n",
       "       [-2.56610923e-02, -2.03844056e-01],\n",
       "       [-5.67348361e-01, -5.86824238e-01],\n",
       "       [ 5.27636111e-01,  1.71165133e+00],\n",
       "       [-5.65243363e-01,  3.83720368e-01],\n",
       "       [ 1.27748895e+00,  9.15985286e-01],\n",
       "       [-5.32745540e-01,  1.20449042e+00],\n",
       "       [-6.04475200e-01,  7.90216923e-01],\n",
       "       [ 7.75354445e-01, -8.95417631e-02],\n",
       "       [ 9.66177523e-01,  1.46510136e+00],\n",
       "       [ 1.17489791e+00,  2.15499687e+00],\n",
       "       [ 7.87720859e-01,  2.33826613e+00],\n",
       "       [-5.52134991e-01,  3.05197626e-01],\n",
       "       [-5.32745957e-01,  1.20448065e+00],\n",
       "       [ 6.29138172e-01, -8.71412039e-01],\n",
       "       [-1.30868530e+00,  7.05952168e-01],\n",
       "       [ 4.75266665e-01, -8.93457115e-01],\n",
       "       [-5.69730043e-01,  3.95236343e-01],\n",
       "       [-1.28999317e+00,  6.99081779e-01],\n",
       "       [ 7.75339842e-01, -8.95492509e-02],\n",
       "       [-4.97436002e-02, -7.94586480e-01],\n",
       "       [ 3.86750013e-01, -1.78681344e-01],\n",
       "       [-1.29936397e+00,  1.00383425e+00],\n",
       "       [-5.73458731e-01,  1.05978596e+00],\n",
       "       [ 1.91232219e-01,  1.68045664e+00],\n",
       "       [ 1.08798862e+00,  1.33092797e+00],\n",
       "       [ 9.72548008e-01,  1.46010065e+00],\n",
       "       [ 3.52002233e-01,  1.66949105e+00],\n",
       "       [-1.51866585e-01,  1.58664834e+00],\n",
       "       [-2.59129554e-01,  1.57253754e+00],\n",
       "       [ 1.92454040e+00,  5.01634181e-01],\n",
       "       [-1.17279744e+00,  1.50899351e+00],\n",
       "       [ 1.13622153e+00,  2.35090837e-01],\n",
       "       [-5.36119819e-01,  1.20918417e+00],\n",
       "       [-1.23006177e+00,  3.95335317e-01],\n",
       "       [ 9.66175377e-01,  1.46510339e+00],\n",
       "       [-2.56630313e-02, -2.03822598e-01],\n",
       "       [-1.26743102e+00,  2.83665776e-01],\n",
       "       [-5.94331622e-01,  4.80345756e-01],\n",
       "       [ 1.35054302e+00, -4.95730162e-01],\n",
       "       [-9.62229609e-01, -1.91080987e-01],\n",
       "       [-3.42756659e-01,  8.20204839e-02],\n",
       "       [ 1.08799148e+00,  1.33092511e+00],\n",
       "       [-6.30310297e-01,  8.61860394e-01],\n",
       "       [ 8.94498944e-01, -2.94061825e-02],\n",
       "       [-1.26750576e+00,  1.03806233e+00],\n",
       "       [-1.17672837e+00,  1.56778479e+00],\n",
       "       [ 3.85778397e-01, -1.85870022e-01],\n",
       "       [-1.28729761e+00,  1.07046425e+00],\n",
       "       [-8.02086055e-01,  1.91225219e+00],\n",
       "       [-6.93263710e-01, -5.89358866e-01],\n",
       "       [ 1.20963645e+00,  3.99631977e-01],\n",
       "       [ 2.67540127e-01, -8.41197670e-01],\n",
       "       [ 3.48232733e-03, -2.13948742e-01],\n",
       "       [ 1.21488857e+00,  3.74019533e-01],\n",
       "       [ 4.01427537e-01, -1.86247423e-01],\n",
       "       [ 1.91231564e-01,  1.68045700e+00],\n",
       "       [-8.09746206e-01,  1.91425657e+00],\n",
       "       [-2.20823288e-01,  2.24249196e+00],\n",
       "       [-5.69731712e-01,  3.95235628e-01],\n",
       "       [ 1.17489195e+00,  2.15499926e+00],\n",
       "       [ 1.23567140e+00,  7.27775991e-01],\n",
       "       [-5.32748997e-01,  1.20448267e+00],\n",
       "       [ 1.88799846e+00,  1.29644835e+00],\n",
       "       [-3.42753083e-01,  8.20186064e-02],\n",
       "       [ 8.95330846e-01, -7.70046592e-01],\n",
       "       [-1.33931041e+00,  1.16807711e+00],\n",
       "       [ 1.27333498e+00,  9.46289361e-01],\n",
       "       [-2.56661568e-02, -2.03828141e-01],\n",
       "       [ 1.77442205e+00,  1.65632188e+00],\n",
       "       [ 3.58276278e-01,  2.38349056e+00],\n",
       "       [ 7.38615930e-01,  1.61517680e+00],\n",
       "       [ 4.01427299e-01, -1.86245665e-01],\n",
       "       [-1.88970029e-01,  2.30833387e+00],\n",
       "       [ 1.21147227e+00,  3.77101898e-01],\n",
       "       [-6.14479601e-01,  8.12178671e-01],\n",
       "       [-1.12807059e+00,  8.01633447e-02],\n",
       "       [ 1.27203226e+00,  9.98108864e-01],\n",
       "       [ 1.84158301e+00, -1.57658160e-01],\n",
       "       [-1.12919025e-01,  2.33822179e+00],\n",
       "       [ 9.66824234e-01,  1.46734798e+00],\n",
       "       [-2.35654816e-01,  1.57540381e+00],\n",
       "       [-6.02078021e-01,  5.07569432e-01],\n",
       "       [ 2.86010265e-01,  2.29699445e+00],\n",
       "       [ 1.72728729e+00,  1.51240075e+00],\n",
       "       [ 5.59167206e-01,  1.67820024e+00],\n",
       "       [-7.71182835e-01, -4.53966171e-01],\n",
       "       [ 1.42868149e+00, -4.13331181e-01],\n",
       "       [-1.96326245e-02, -1.38294533e-01],\n",
       "       [ 3.96339238e-01, -1.84840232e-01],\n",
       "       [ 1.15248418e+00,  2.15988564e+00],\n",
       "       [-1.22401202e-02, -2.01752722e-01],\n",
       "       [ 1.54523087e+00,  1.88585019e+00],\n",
       "       [-1.29749060e+00,  1.16272032e+00],\n",
       "       [-5.46799004e-01,  3.13222051e-01],\n",
       "       [ 1.24525559e+00,  7.12628186e-01],\n",
       "       [ 6.93226695e-01,  2.33677077e+00],\n",
       "       [ 1.89637437e-01, -8.38339090e-01],\n",
       "       [ 1.44231021e+00, -5.42494237e-01],\n",
       "       [ 1.27203083e+00,  9.98111486e-01],\n",
       "       [-6.15733266e-01,  5.23756087e-01],\n",
       "       [ 1.26953113e+00,  1.10008106e-01],\n",
       "       [-1.54927194e-01,  1.57489347e+00],\n",
       "       [ 9.09381330e-01, -7.82118857e-01],\n",
       "       [ 1.52866805e+00, -5.74494898e-01],\n",
       "       [ 1.07967508e+00,  1.33595586e+00],\n",
       "       [-3.42745662e-01,  8.20094347e-02],\n",
       "       [-3.42756510e-01,  8.20223093e-02],\n",
       "       [ 1.51373589e+00,  1.90616250e+00],\n",
       "       [ 9.72325087e-01,  1.46036077e+00],\n",
       "       [-1.96333155e-02, -1.38295993e-01],\n",
       "       [-1.13115907e+00, -8.69110450e-02],\n",
       "       [-1.08649455e-01, -7.59872139e-01],\n",
       "       [ 1.85802102e+00,  7.67387390e-01],\n",
       "       [ 3.58218431e-01,  2.38435578e+00],\n",
       "       [ 1.91077387e+00,  1.18499053e+00],\n",
       "       [ 6.91817820e-01,  2.33767271e+00],\n",
       "       [ 3.75021100e-01,  1.68277276e+00],\n",
       "       [ 1.75644588e+00,  1.69056761e+00],\n",
       "       [-5.70382714e-01,  1.04122877e+00],\n",
       "       [-1.10071778e+00,  1.78162622e+00],\n",
       "       [ 1.06111872e+00,  1.40367103e+00],\n",
       "       [ 3.52003098e-01,  1.66949224e+00],\n",
       "       [-1.63468987e-01,  2.27217770e+00],\n",
       "       [ 6.24688327e-01,  1.65162432e+00],\n",
       "       [-5.36121130e-01,  1.20917845e+00],\n",
       "       [-6.34063542e-01,  8.77567232e-01],\n",
       "       [ 1.13617361e+00,  2.35053018e-01],\n",
       "       [ 7.89608002e-01, -8.46594423e-02],\n",
       "       [-1.11195183e+00,  1.73123622e+00],\n",
       "       [ 7.75494277e-01, -8.94743428e-02],\n",
       "       [ 1.20964301e+00,  3.99634659e-01],\n",
       "       [-5.81168592e-01,  2.31829071e+00],\n",
       "       [-9.16612744e-01, -2.40763173e-01],\n",
       "       [-7.48751611e-02,  1.66395462e+00],\n",
       "       [ 1.24525595e+00,  7.12628245e-01],\n",
       "       [ 1.03145599e+00,  6.47424906e-02],\n",
       "       [ 7.75341213e-01, -8.95495191e-02],\n",
       "       [-3.97682488e-01,  1.52875483e+00],\n",
       "       [ 9.40165997e-01, -7.91698158e-01],\n",
       "       [ 1.57350346e-01, -6.69512272e-01],\n",
       "       [ 1.20964456e+00,  3.99638772e-01],\n",
       "       [-6.74534917e-01,  2.18306279e+00],\n",
       "       [-9.58172798e-01, -2.24278823e-01],\n",
       "       [ 8.11179042e-01, -7.51269385e-02],\n",
       "       [ 3.18697304e-01,  7.39329100e-01]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tsne_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  4.  0.  0.  0.  0.  0.  0.  0.  0.  3.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0. 15.  0.  0.  1.  0.  0.  0.  0.  0.  3.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  2.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  3.,  0.,\n",
       "        0.,  0.,  0.,  4.,  2.,  0.,  0., 10.,  0.,  0.,  1.,  0.,  0.,\n",
       "        2.,  0.,  0.,  3.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sum(x_train[0]))\n",
    "sum(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred.shape =  Tensor(\"merged_layer/concat:0\", shape=(?, 9), dtype=float32)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor_input (InputLayer)       (None, 70, 30, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_input (InputLayer)     (None, 70, 30, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_input (InputLayer)     (None, 70, 30, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 3)            42463       anchor_input[0][0]               \n",
      "                                                                 positive_input[0][0]             \n",
      "                                                                 negative_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "merged_layer (Concatenate)      (None, 9)            0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "                                                                 sequential_1[3][0]               \n",
      "==================================================================================================\n",
      "Total params: 42,463\n",
      "Trainable params: 42,423\n",
      "Non-trainable params: 40\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.4):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss function\n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor data\n",
    "            positive -- the encodings for the positive data (similar to anchor)\n",
    "            negative -- the encodings for the negative data (different from anchor)\n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    print('y_pred.shape = ',y_pred)\n",
    "    \n",
    "    total_lenght = y_pred.shape.as_list()[-1]\n",
    "    \n",
    "    anchor = y_pred[:,0:int(total_lenght*1/3)]\n",
    "    positive = y_pred[:,int(total_lenght*1/3):int(total_lenght*2/3)]\n",
    "    negative = y_pred[:,int(total_lenght*2/3):int(total_lenght*3/3)]\n",
    "\n",
    "    # distance between the anchor and the positive\n",
    "    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n",
    "\n",
    "    # distance between the anchor and the negative\n",
    "    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n",
    "\n",
    "    # compute loss\n",
    "    basic_loss = pos_dist-neg_dist+alpha\n",
    "    loss = K.maximum(basic_loss,0.0)\n",
    " \n",
    "    return loss\n",
    "\n",
    "def baseNetwork():    \n",
    "        model = Sequential()\n",
    "        model.add(Reshape((70, 30), input_shape=(1004,None, None)))\n",
    "        model.add(Conv1D(20,10,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv1D(20,5,activation='relu'))\n",
    "        model.add(Conv1D(20,3,activation='relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(30, activation='relu'))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(3, activation='softmax'))\n",
    "        return model\n",
    "    \n",
    "anchor_input = Input((70,30,1, ), name='anchor_input')\n",
    "positive_input = Input((70,30,1, ), name='positive_input')\n",
    "negative_input = Input((70,30,1, ), name='negative_input')\n",
    "\n",
    "# Shared embedding layer for positive and negative items\n",
    "Shared_DNN = baseNetwork()\n",
    "\n",
    "\n",
    "encoded_anchor = Shared_DNN(anchor_input)\n",
    "encoded_positive = Shared_DNN(positive_input)\n",
    "encoded_negative = Shared_DNN(negative_input)\n",
    "\n",
    "\n",
    "merged_vector = concatenate([encoded_anchor, encoded_positive, encoded_negative], axis=-1, name='merged_layer')\n",
    "\n",
    "model = Model(inputs=[anchor_input,positive_input, negative_input], outputs=merged_vector)\n",
    "model.compile(loss=triplet_loss, optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateTriplet(x,y,testsize=0.2,ap_pairs=10,an_pairs=10):\n",
    "    data_xy = tuple([x,y])\n",
    "\n",
    "    trainsize = 1-testsize\n",
    "\n",
    "    triplet_train_pairs = []\n",
    "    triplet_test_pairs = []\n",
    "    for data_class in sorted(set(data_xy[1])):\n",
    "\n",
    "        same_class_idx = np.where((data_xy[1] == data_class))[0]\n",
    "        diff_class_idx = np.where(data_xy[1] != data_class)[0]\n",
    "        A_P_pairs = random.sample(list(permutations(same_class_idx,2)),k=ap_pairs) #Generating Anchor-Positive pairs\n",
    "        Neg_idx = random.sample(list(diff_class_idx),k=an_pairs)\n",
    "        \n",
    "\n",
    "        #train\n",
    "        A_P_len = len(A_P_pairs)\n",
    "        Neg_len = len(Neg_idx)\n",
    "        for ap in A_P_pairs[:int(A_P_len*trainsize)]:\n",
    "            Anchor = data_xy[0][ap[0]]\n",
    "            Positive = data_xy[0][ap[1]]\n",
    "            for n in Neg_idx:\n",
    "                Negative = data_xy[0][n]\n",
    "                triplet_train_pairs.append([Anchor,Positive,Negative])               \n",
    "        #test\n",
    "        for ap in A_P_pairs[int(A_P_len*trainsize):]:\n",
    "            Anchor = data_xy[0][ap[0]]\n",
    "            Positive = data_xy[0][ap[1]]\n",
    "            for n in Neg_idx:\n",
    "                Negative = data_xy[0][n]\n",
    "                triplet_test_pairs.append([Anchor,Positive,Negative])    \n",
    "                \n",
    "    return np.array(triplet_train_pairs), np.array(triplet_test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test = generateTriplet(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/50\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 0.3821 - val_loss: 0.3368\n",
      "Epoch 2/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.2751 - val_loss: 0.2619\n",
      "Epoch 3/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.2072 - val_loss: 0.2035\n",
      "Epoch 4/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.1671 - val_loss: 0.2106\n",
      "Epoch 5/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.1305 - val_loss: 0.1914\n",
      "Epoch 6/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.1306 - val_loss: 0.1795\n",
      "Epoch 7/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.1009 - val_loss: 0.1754\n",
      "Epoch 8/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0811 - val_loss: 0.1686\n",
      "Epoch 9/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0708 - val_loss: 0.1529\n",
      "Epoch 10/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0535 - val_loss: 0.1505\n",
      "Epoch 11/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0561 - val_loss: 0.1281\n",
      "Epoch 12/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0552 - val_loss: 0.1361\n",
      "Epoch 13/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0435 - val_loss: 0.1465\n",
      "Epoch 14/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0500 - val_loss: 0.1959\n",
      "Epoch 15/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0442 - val_loss: 0.2522\n",
      "Epoch 16/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0437 - val_loss: 0.3032\n",
      "Epoch 17/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.2139\n",
      "Epoch 18/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.2116\n",
      "Epoch 19/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.1716\n",
      "Epoch 20/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0337 - val_loss: 0.1698\n",
      "Epoch 21/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0390 - val_loss: 0.2080\n",
      "Epoch 22/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0369 - val_loss: 0.2570\n",
      "Epoch 23/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0354 - val_loss: 0.2980\n",
      "Epoch 24/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0391 - val_loss: 0.3152\n",
      "Epoch 25/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.2956\n",
      "Epoch 26/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0337 - val_loss: 0.2860\n",
      "Epoch 27/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.2711\n",
      "Epoch 28/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0343 - val_loss: 0.2862\n",
      "Epoch 29/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0341 - val_loss: 0.2875\n",
      "Epoch 30/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.2856\n",
      "Epoch 31/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0281 - val_loss: 0.2843\n",
      "Epoch 32/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0271 - val_loss: 0.3018\n",
      "Epoch 33/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0288 - val_loss: 0.3149\n",
      "Epoch 34/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0270 - val_loss: 0.3151\n",
      "Epoch 35/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0257 - val_loss: 0.3321\n",
      "Epoch 36/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0274 - val_loss: 0.3410\n",
      "Epoch 37/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0255 - val_loss: 0.3628\n",
      "Epoch 38/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0246 - val_loss: 0.2889\n",
      "Epoch 39/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.2523\n",
      "Epoch 40/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0250 - val_loss: 0.2711\n",
      "Epoch 41/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0310 - val_loss: 0.2735\n",
      "Epoch 42/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0269 - val_loss: 0.3297\n",
      "Epoch 43/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0295 - val_loss: 0.2995\n",
      "Epoch 44/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0238 - val_loss: 0.2860\n",
      "Epoch 45/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0232 - val_loss: 0.2707\n",
      "Epoch 46/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0220 - val_loss: 0.2632\n",
      "Epoch 47/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0230 - val_loss: 0.2870\n",
      "Epoch 48/50\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0279 - val_loss: 0.2922\n",
      "Epoch 49/50\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 0.0319 - val_loss: 0.3188\n",
      "Epoch 50/50\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 0.0274 - val_loss: 0.2961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a266256d8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Anchor = X_train[:,0,:].reshape(-1,70,30,1)\n",
    "Positive = X_train[:,1,:].reshape(-1,70,30,1)\n",
    "Negative = X_train[:,2,:].reshape(-1,70,30,1)\n",
    "Anchor_test = X_test[:,0,:].reshape(-1,70,30,1)\n",
    "Positive_test = X_test[:,1,:].reshape(-1,70,30,1)\n",
    "Negative_test = X_test[:,2,:].reshape(-1,70,30,1)\n",
    "\n",
    "Y_dummy = np.empty((Anchor.shape[0],300))\n",
    "Y_dummy2 = np.empty((Anchor_test.shape[0],1))\n",
    "\n",
    "model.fit([Anchor,Positive,Negative],y=Y_dummy,validation_data=([Anchor_test,Positive_test,Negative_test],Y_dummy2), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained_model = Model(inputs=anchor_input, outputs=encoded_anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/sklearn/neighbors/base.py:316: RuntimeWarning: invalid value encountered in sqrt\n",
      "  result = np.sqrt(dist[sample_range, neigh_ind]), neigh_ind\n"
     ]
    }
   ],
   "source": [
    "tsne = TSNE()\n",
    "X_train_trm = trained_model.predict(x_train.reshape(-1,70,30,1))\n",
    "X_test_trm = trained_model.predict(x_test.reshape(-1,70,30,1))\n",
    "train_tsne_embeds = tsne.fit_transform(X_train_trm)\n",
    "eval_tsne_embeds = tsne.fit_transform(X_test_trm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:2831: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.mean(atmp[sl], axis=axis)\n"
     ]
    }
   ],
   "source": [
    "scatter(train_tsne_embeds, y_train, \"Training Data After TNN\")\n",
    "scatter(eval_tsne_embeds, y_test, \"Validation Data After TNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 316 samples, validate on 106 samples\n",
      "Epoch 1/10\n",
      "316/316 [==============================] - 1s 2ms/step - loss: 1.0951 - acc: 0.3639 - val_loss: 1.0393 - val_acc: 0.3679\n",
      "Epoch 2/10\n",
      "316/316 [==============================] - 0s 134us/step - loss: 1.0926 - acc: 0.3608 - val_loss: 1.0376 - val_acc: 0.3585\n",
      "Epoch 3/10\n",
      "316/316 [==============================] - 0s 120us/step - loss: 1.0899 - acc: 0.3544 - val_loss: 1.0361 - val_acc: 0.3679\n",
      "Epoch 4/10\n",
      "316/316 [==============================] - 0s 195us/step - loss: 1.0881 - acc: 0.3608 - val_loss: 1.0347 - val_acc: 0.3774\n",
      "Epoch 5/10\n",
      "316/316 [==============================] - 0s 145us/step - loss: 1.0859 - acc: 0.3481 - val_loss: 1.0334 - val_acc: 0.3679\n",
      "Epoch 6/10\n",
      "316/316 [==============================] - 0s 170us/step - loss: 1.0842 - acc: 0.3418 - val_loss: 1.0322 - val_acc: 0.3679\n",
      "Epoch 7/10\n",
      "316/316 [==============================] - 0s 93us/step - loss: 1.0822 - acc: 0.3639 - val_loss: 1.0312 - val_acc: 0.3774\n",
      "Epoch 8/10\n",
      "316/316 [==============================] - 0s 66us/step - loss: 1.0806 - acc: 0.3829 - val_loss: 1.0301 - val_acc: 0.3868\n",
      "Epoch 9/10\n",
      "316/316 [==============================] - 0s 471us/step - loss: 1.0790 - acc: 0.4082 - val_loss: 1.0291 - val_acc: 0.4151\n",
      "Epoch 10/10\n",
      "316/316 [==============================] - 0s 84us/step - loss: 1.0773 - acc: 0.4114 - val_loss: 1.0283 - val_acc: 0.4057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2b829710>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_trm = trained_model.predict(x_train.reshape(-1,70,30,1))\n",
    "X_test_trm = trained_model.predict(x_test.reshape(-1,70,30,1))\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "Classifier_input = Input((3,))\n",
    "Classifier_output = Dense(3, activation='softmax')(Classifier_input)\n",
    "Classifier_model = Model(Classifier_input, Classifier_output)\n",
    "\n",
    "\n",
    "Classifier_model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "Classifier_model.fit(X_train_trm,y_train, validation_data=(X_test_trm,y_test),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
